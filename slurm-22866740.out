
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/scratch_tmp/grp/grv_shi/k21220263/MTPSL/nyu_mtl_xtc.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels_weights = torch.load('{}onelabel.pth'.format(opt.labelroot))['labels_weights'].float().cuda()
Parameter Space: ABS: 45176549.0, REL: 1.8084

LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR ROOT_MSE | NORMAL_LOSS MEAN MED <11.25 <22.5 <30

lr at 0th epoch is 0.0001 for optimizer
current performance: -50.6746, best performance: -100.0000
Epoch: 0000 | TRAIN: 2.0238 0.0662 0.3295 | 0.9957 0.9957 0.4799 | 0.3734 47.7543 46.4608 0.0330 0.1308 0.2304 TEST: 1.8246 0.0880 0.3922 | 1.0833 1.0645 1.4806 | 0.3347 44.4368 49.4876 4.3584 16.9423 29.2335, TEACHER: 0.0909 0.4018
lr at 1th epoch is 0.0001 for optimizer
current performance: -44.2432, best performance: -50.6746
Epoch: 0001 | TRAIN: 1.8102 0.0971 0.3822 | 0.8823 0.8823 0.4213 | 0.3373 44.7042 42.7404 0.0431 0.1722 0.2912 TEST: 1.7675 0.0934 0.3967 | 0.9604 0.9418 1.3359 | 0.3319 44.0366 49.2952 4.8266 18.9013 30.6192, TEACHER: 0.0967 0.3941
lr at 2th epoch is 0.0001 for optimizer
current performance: -38.9577, best performance: -44.2432
Epoch: 0002 | TRAIN: 1.7738 0.1055 0.3894 | 0.8613 0.8613 0.4300 | 0.3305 44.1020 42.3139 0.0459 0.1833 0.3050 TEST: 1.6877 0.1008 0.4184 | 0.8731 0.8595 1.1638 | 0.3233 43.3206 48.6077 5.0263 19.8434 32.2436, TEACHER: 0.0985 0.4225
lr at 3th epoch is 0.0001 for optimizer
current performance: -37.9493, best performance: -38.9577
Epoch: 0003 | TRAIN: 1.7354 0.1170 0.4051 | 0.8643 0.8643 0.4038 | 0.3268 43.5808 41.4301 0.0541 0.2017 0.3198 TEST: 1.6875 0.1014 0.4169 | 0.8538 0.8386 1.1594 | 0.3237 43.2966 48.6511 5.1983 19.9364 31.8568, TEACHER: 0.0984 0.4172
lr at 4th epoch is 0.0001 for optimizer
current performance: -36.6087, best performance: -37.9493
Epoch: 0004 | TRAIN: 1.7233 0.1207 0.4079 | 0.8265 0.8265 0.4051 | 0.3230 43.3101 41.1374 0.0523 0.2041 0.3230 TEST: 1.7072 0.1010 0.4151 | 0.8461 0.8292 1.1703 | 0.3201 42.4156 48.4751 8.2472 24.1548 34.7747, TEACHER: 0.1016 0.4104
lr at 5th epoch is 0.0001 for optimizer
current performance: -36.9964, best performance: -36.6087
Epoch: 0005 | TRAIN: 1.7083 0.1287 0.4148 | 0.8497 0.8497 0.4108 | 0.3182 42.7286 40.6214 0.0660 0.2209 0.3341 TEST: 1.6774 0.1093 0.4260 | 0.8738 0.8561 1.2118 | 0.3211 42.6679 48.5686 7.6212 23.2505 34.0395, TEACHER: 0.1087 0.4305
lr at 6th epoch is 0.0001 for optimizer
current performance: -37.0231, best performance: -36.6087
Epoch: 0006 | TRAIN: 1.6928 0.1297 0.4189 | 0.8310 0.8310 0.4047 | 0.3176 42.6512 40.6122 0.0666 0.2221 0.3362 TEST: 1.7042 0.1102 0.4159 | 0.8945 0.8761 1.2456 | 0.3137 42.0164 47.9599 7.6015 23.8130 35.5043, TEACHER: 0.1096 0.4182
lr at 7th epoch is 0.0001 for optimizer
current performance: -35.1362, best performance: -36.6087
Epoch: 0007 | TRAIN: 1.6837 0.1314 0.4223 | 0.8162 0.8162 0.3881 | 0.3181 42.5937 40.4984 0.0721 0.2281 0.3399 TEST: 1.6723 0.1208 0.4353 | 0.8784 0.8625 1.2001 | 0.3108 42.0667 47.6318 7.0340 22.7198 34.0160, TEACHER: 0.1211 0.4364
lr at 8th epoch is 0.0001 for optimizer
current performance: -36.2774, best performance: -35.1362
Epoch: 0008 | TRAIN: 1.6769 0.1379 0.4258 | 0.8039 0.8039 0.3821 | 0.3165 42.4250 40.2452 0.0753 0.2304 0.3413 TEST: 1.6978 0.1096 0.4018 | 0.8650 0.8484 1.1854 | 0.3282 42.3591 49.3828 11.4148 27.0314 37.0306, TEACHER: 0.1094 0.4130
lr at 9th epoch is 0.0001 for optimizer
current performance: -31.7856, best performance: -35.1362
Epoch: 0009 | TRAIN: 1.6682 0.1396 0.4282 | 0.8245 0.8245 0.4070 | 0.3145 42.3266 40.1784 0.0723 0.2282 0.3419 TEST: 1.5889 0.1309 0.4516 | 0.8649 0.8472 1.2065 | 0.3017 40.8030 46.9961 9.9926 26.1340 37.1348, TEACHER: 0.1233 0.4523
lr at 10th epoch is 0.0001 for optimizer
current performance: -35.4408, best performance: -31.7856
Epoch: 0010 | TRAIN: 2.1273 0.1707 0.4228 | 0.8283 0.8283 0.3975 | 0.3220 42.8074 40.9507 0.0784 0.2301 0.3363 TEST: 2.1929 0.1044 0.4421 | 0.8237 0.8086 1.1187 | 0.3173 42.5506 48.2443 5.8285 22.8568 34.2979, TEACHER: 0.1043 0.4420
lr at 11th epoch is 0.0001 for optimizer
current performance: -35.8065, best performance: -31.7856
Epoch: 0011 | TRAIN: 2.1585 0.1703 0.4151 | 0.8330 0.8330 0.4040 | 0.3213 43.1315 41.4665 0.0614 0.2108 0.3179 TEST: 2.1882 0.1040 0.4296 | 0.8273 0.8112 1.1309 | 0.3199 42.7392 48.3311 7.5947 22.7040 32.7502, TEACHER: 0.1040 0.4300
lr at 12th epoch is 0.0001 for optimizer
current performance: -38.6583, best performance: -31.7856
Epoch: 0012 | TRAIN: 2.1513 0.1760 0.4224 | 0.8437 0.8437 0.4070 | 0.3177 42.5528 40.6218 0.0735 0.2310 0.3383 TEST: 1.9329 0.1062 0.4279 | 0.9049 0.8883 1.2492 | 0.3199 42.5593 48.3917 8.5057 23.2257 33.3622, TEACHER: 0.1062 0.4275
lr at 13th epoch is 0.0001 for optimizer
current performance: -38.6422, best performance: -31.7856
Epoch: 0013 | TRAIN: 2.1232 0.1784 0.4284 | 0.8388 0.8388 0.3962 | 0.3169 42.4770 40.6160 0.0747 0.2325 0.3384 TEST: 2.1034 0.1079 0.4393 | 0.9253 0.9069 1.2938 | 0.3145 42.0105 47.9930 8.6403 24.5551 34.9460, TEACHER: 0.1081 0.4390
lr at 14th epoch is 0.0001 for optimizer
current performance: -34.1590, best performance: -31.7856
Epoch: 0014 | TRAIN: 2.1061 0.1824 0.4350 | 0.8267 0.8267 0.4035 | 0.3157 42.3026 40.4933 0.0820 0.2356 0.3405 TEST: 2.1282 0.1122 0.4393 | 0.8356 0.8228 1.1038 | 0.3106 41.7454 47.6550 8.9093 24.3992 34.7477, TEACHER: 0.1122 0.4389
lr at 15th epoch is 0.0001 for optimizer
current performance: -33.8417, best performance: -31.7856
Epoch: 0015 | TRAIN: 2.1348 0.1793 0.4307 | 0.8374 0.8374 0.4065 | 0.3125 42.1011 40.0616 0.0738 0.2395 0.3472 TEST: 2.2056 0.1083 0.4452 | 0.8312 0.8159 1.1295 | 0.3082 41.2778 47.5898 9.6880 26.0285 37.0269, TEACHER: 0.1082 0.4451
lr at 16th epoch is 0.0001 for optimizer
current performance: -41.7065, best performance: -31.7856
Epoch: 0016 | TRAIN: 2.1198 0.1818 0.4327 | 0.8086 0.8086 0.3895 | 0.3139 42.1005 40.0498 0.0851 0.2387 0.3457 TEST: 1.9735 0.1100 0.4504 | 1.0119 0.9955 1.3625 | 0.3088 41.5649 47.5487 7.7245 25.3866 36.5366, TEACHER: 0.1101 0.4508
lr at 17th epoch is 0.0001 for optimizer
current performance: -37.6737, best performance: -31.7856
Epoch: 0017 | TRAIN: 2.1157 0.1827 0.4365 | 0.8078 0.8078 0.4095 | 0.3129 42.1444 39.9150 0.0753 0.2353 0.3460 TEST: 1.9894 0.1154 0.4562 | 0.9387 0.9214 1.3020 | 0.3071 41.4316 47.3835 9.7969 24.3981 34.7055, TEACHER: 0.1153 0.4562
lr at 18th epoch is 0.0001 for optimizer
current performance: -32.6934, best performance: -31.7856
Epoch: 0018 | TRAIN: 2.1228 0.1813 0.4372 | 0.8151 0.8151 0.3933 | 0.3117 42.0080 39.9556 0.0792 0.2386 0.3471 TEST: 2.0598 0.1152 0.4542 | 0.8318 0.8148 1.1584 | 0.3058 41.0744 47.3625 10.5964 25.7039 36.5114, TEACHER: 0.1151 0.4541
lr at 19th epoch is 0.0001 for optimizer
current performance: -36.5052, best performance: -31.7856
Epoch: 0019 | TRAIN: 2.0897 0.1841 0.4410 | 0.7928 0.7928 0.3708 | 0.3101 41.7368 39.5316 0.0875 0.2456 0.3550 TEST: 2.0275 0.1125 0.4488 | 0.8962 0.8795 1.2530 | 0.3095 41.6862 47.5727 9.0081 23.8078 34.4360, TEACHER: 0.1125 0.4490
lr at 20th epoch is 0.0001 for optimizer
current performance: -37.1533, best performance: -31.7856
Epoch: 0020 | TRAIN: 2.0947 0.1863 0.4441 | 0.8167 0.8167 0.3850 | 0.3092 41.5430 39.4547 0.0975 0.2515 0.3577 TEST: 1.9476 0.1116 0.4547 | 0.9147 0.8968 1.2653 | 0.3077 41.4925 47.4493 8.1385 25.1164 36.0172, TEACHER: 0.1116 0.4549
lr at 21th epoch is 0.0001 for optimizer
current performance: -34.5386, best performance: -31.7856
Epoch: 0021 | TRAIN: 2.1175 0.1834 0.4398 | 0.8002 0.8002 0.3897 | 0.3109 41.8621 39.8814 0.0868 0.2403 0.3488 TEST: 2.1355 0.1127 0.4387 | 0.8500 0.8390 1.1180 | 0.3114 41.5114 47.8186 10.1600 25.3962 36.2325, TEACHER: 0.1128 0.4390
lr at 22th epoch is 0.0001 for optimizer
current performance: -32.7586, best performance: -31.7856
Epoch: 0022 | TRAIN: 2.0934 0.1862 0.4402 | 0.8099 0.8099 0.3947 | 0.3103 41.8167 39.7080 0.0826 0.2436 0.3531 TEST: 2.1214 0.1152 0.4520 | 0.8085 0.7928 1.1141 | 0.3110 41.9879 47.6751 7.1615 23.1087 34.2818, TEACHER: 0.1152 0.4523
lr at 23th epoch is 0.0001 for optimizer
current performance: -36.6514, best performance: -31.7856
Epoch: 0023 | TRAIN: 2.0822 0.1877 0.4473 | 0.7885 0.7885 0.3858 | 0.3045 41.1106 38.9871 0.1008 0.2572 0.3665 TEST: 2.0125 0.1099 0.4405 | 0.8864 0.8692 1.2349 | 0.3095 41.9220 47.5138 7.7023 22.9536 34.0442, TEACHER: 0.1099 0.4405
lr at 24th epoch is 0.0001 for optimizer
current performance: -36.4341, best performance: -31.7856
Epoch: 0024 | TRAIN: 2.0561 0.1894 0.4524 | 0.7829 0.7829 0.3829 | 0.3052 41.2801 38.9998 0.0924 0.2528 0.3633 TEST: 2.0286 0.1135 0.4552 | 0.9165 0.8996 1.2600 | 0.3023 40.9467 46.9881 10.2179 25.0068 35.9275, TEACHER: 0.1135 0.4552
lr at 25th epoch is 0.0001 for optimizer
current performance: -31.4018, best performance: -31.7856
Epoch: 0025 | TRAIN: 2.0654 0.1902 0.4503 | 0.7993 0.7993 0.3733 | 0.3037 41.0808 38.7686 0.0983 0.2569 0.3664 TEST: 1.9922 0.1154 0.4508 | 0.7860 0.7737 1.0519 | 0.3060 41.5411 47.2564 7.5324 24.2701 35.5381, TEACHER: 0.1154 0.4509
lr at 26th epoch is 0.0001 for optimizer
current performance: -32.7840, best performance: -31.4018
Epoch: 0026 | TRAIN: 2.0299 0.1935 0.4608 | 0.7954 0.7954 0.3737 | 0.3056 41.2403 38.9810 0.0961 0.2558 0.3659 TEST: 2.1075 0.1186 0.4546 | 0.8315 0.8150 1.1624 | 0.3057 41.5416 47.2548 7.6107 23.9303 35.1641, TEACHER: 0.1186 0.4544
lr at 27th epoch is 0.0001 for optimizer
current performance: -32.7587, best performance: -31.4018
Epoch: 0027 | TRAIN: 2.0616 0.1895 0.4528 | 0.7790 0.7790 0.3747 | 0.3028 40.9788 38.6163 0.0997 0.2594 0.3688 TEST: 2.0772 0.1175 0.4561 | 0.8375 0.8234 1.1296 | 0.3025 41.0639 47.0172 9.3297 25.0935 35.7291, TEACHER: 0.1175 0.4565
lr at 28th epoch is 0.0001 for optimizer
current performance: -29.0255, best performance: -31.4018
Epoch: 0028 | TRAIN: 2.0335 0.1914 0.4577 | 0.7846 0.7846 0.3753 | 0.3045 41.2939 39.1165 0.0922 0.2478 0.3584 TEST: 2.1087 0.1202 0.4650 | 0.7751 0.7610 1.0733 | 0.3002 40.4455 46.8876 12.3363 27.2313 37.2791, TEACHER: 0.1203 0.4648
lr at 29th epoch is 0.0001 for optimizer
current performance: -29.5953, best performance: -29.0255
Epoch: 0029 | TRAIN: 2.0550 0.1912 0.4556 | 0.7792 0.7792 0.3732 | 0.3025 41.0043 38.6217 0.0961 0.2572 0.3684 TEST: 2.0454 0.1204 0.4709 | 0.7967 0.7816 1.1087 | 0.2976 40.1674 46.7337 12.0835 28.0972 38.6397, TEACHER: 0.1202 0.4710
lr at 30th epoch is 0.0001 for optimizer
current performance: -32.3446, best performance: -29.0255
Epoch: 0030 | TRAIN: 2.0480 0.1935 0.4560 | 0.7729 0.7729 0.3795 | 0.3042 41.1937 38.9435 0.0930 0.2537 0.3642 TEST: 2.0663 0.1181 0.4526 | 0.8396 0.8247 1.1742 | 0.3024 40.7087 47.0641 11.3109 26.3371 37.0345, TEACHER: 0.1181 0.4528
lr at 31th epoch is 0.0001 for optimizer
current performance: -37.0414, best performance: -29.0255
Epoch: 0031 | TRAIN: 2.0488 0.1959 0.4587 | 0.7650 0.7650 0.3707 | 0.3035 41.0844 38.8500 0.0992 0.2547 0.3639 TEST: 2.0823 0.1146 0.4490 | 0.9179 0.9009 1.2853 | 0.3100 41.5786 47.6298 9.6576 24.8642 35.2874, TEACHER: 0.1146 0.4490
lr at 32th epoch is 0.0001 for optimizer
current performance: -33.9473, best performance: -29.0255
Epoch: 0032 | TRAIN: 2.0342 0.1964 0.4676 | 0.7916 0.7916 0.3704 | 0.3010 40.7567 38.4570 0.1046 0.2636 0.3735 TEST: 1.8912 0.1193 0.4690 | 0.8821 0.8655 1.2190 | 0.2988 40.7044 46.7191 9.5461 25.8467 36.9687, TEACHER: 0.1193 0.4690
lr at 33th epoch is 0.0001 for optimizer
current performance: -34.4988, best performance: -29.0255
Epoch: 0033 | TRAIN: 2.0417 0.1978 0.4632 | 0.7851 0.7851 0.3763 | 0.3030 40.9880 38.6243 0.0990 0.2601 0.3694 TEST: 1.8554 0.1185 0.4727 | 0.9034 0.8865 1.2471 | 0.2957 40.2934 46.4922 10.5386 26.9987 37.8701, TEACHER: 0.1185 0.4727
lr at 34th epoch is 0.0001 for optimizer
current performance: -33.9637, best performance: -29.0255
Epoch: 0034 | TRAIN: 2.0313 0.1986 0.4672 | 0.7686 0.7686 0.3697 | 0.3046 41.1011 39.0389 0.1022 0.2588 0.3662 TEST: 2.1228 0.1167 0.4532 | 0.8787 0.8623 1.2268 | 0.3017 40.5419 47.0491 12.3744 27.0606 37.1635, TEACHER: 0.1167 0.4531
lr at 35th epoch is 0.0001 for optimizer
current performance: -33.5911, best performance: -29.0255
Epoch: 0035 | TRAIN: 2.0182 0.1954 0.4646 | 0.7821 0.7821 0.3837 | 0.3025 41.0295 38.7141 0.0954 0.2548 0.3671 TEST: 1.9313 0.1215 0.4662 | 0.8970 0.8800 1.2397 | 0.2946 40.0777 46.4217 11.5611 27.2522 37.9654, TEACHER: 0.1215 0.4661
lr at 36th epoch is 0.0001 for optimizer
current performance: -31.5890, best performance: -29.0255
Epoch: 0036 | TRAIN: 2.0318 0.1967 0.4654 | 0.7691 0.7691 0.3665 | 0.3006 40.7296 38.4324 0.1063 0.2637 0.3723 TEST: 1.8622 0.1240 0.4768 | 0.8661 0.8505 1.2192 | 0.2912 39.6959 46.1692 11.8793 28.4971 39.3354, TEACHER: 0.1239 0.4768
lr at 37th epoch is 0.0001 for optimizer
current performance: -33.5327, best performance: -29.0255
Epoch: 0037 | TRAIN: 2.0146 0.1980 0.4627 | 0.7628 0.7628 0.3656 | 0.3007 40.7666 38.5276 0.1039 0.2622 0.3716 TEST: 2.0967 0.1207 0.4590 | 0.8742 0.8563 1.2242 | 0.3010 40.8483 46.8872 10.6726 25.1890 35.7613, TEACHER: 0.1196 0.4588
lr at 38th epoch is 0.0001 for optimizer
current performance: -28.7645, best performance: -29.0255
Epoch: 0038 | TRAIN: 2.0060 0.1965 0.4648 | 0.7711 0.7711 0.3689 | 0.3018 40.8879 38.6819 0.1032 0.2592 0.3678 TEST: 2.1133 0.1218 0.4659 | 0.7648 0.7541 1.0419 | 0.3017 40.6651 46.9732 11.8215 26.6711 36.7689, TEACHER: 0.1219 0.4660
lr at 39th epoch is 0.0001 for optimizer
current performance: -28.8281, best performance: -28.7645
Epoch: 0039 | TRAIN: 2.0367 0.1954 0.4643 | 0.7558 0.7558 0.3621 | 0.3010 40.8486 38.4680 0.1011 0.2589 0.3690 TEST: 1.9664 0.1223 0.4753 | 0.7914 0.7756 1.1231 | 0.2958 39.9316 46.5640 13.1181 28.2294 38.5223, TEACHER: 0.1222 0.4752
lr at 40th epoch is 0.0001 for optimizer
current performance: -28.4034, best performance: -28.7645
Epoch: 0040 | TRAIN: 1.9769 0.2017 0.4729 | 0.7449 0.7449 0.3616 | 0.2994 40.6087 38.3128 0.1073 0.2658 0.3756 TEST: 2.0129 0.1214 0.4774 | 0.7866 0.7766 1.0655 | 0.2916 39.4105 46.2601 14.1026 29.8608 39.9602, TEACHER: 0.1214 0.4773
lr at 41th epoch is 0.0001 for optimizer
current performance: -27.9703, best performance: -28.4034
Epoch: 0041 | TRAIN: 1.9756 0.2028 0.4766 | 0.7571 0.7571 0.3676 | 0.2971 40.3890 37.9959 0.1115 0.2685 0.3781 TEST: 1.9720 0.1247 0.4700 | 0.7809 0.7659 1.0968 | 0.2928 39.8175 46.3130 12.1924 28.0479 38.8168, TEACHER: 0.1247 0.4699
lr at 42th epoch is 0.0001 for optimizer
current performance: -31.6910, best performance: -27.9703
Epoch: 0042 | TRAIN: 1.9872 0.2020 0.4738 | 0.7645 0.7645 0.3672 | 0.3004 40.8094 38.4165 0.0990 0.2603 0.3715 TEST: 1.9222 0.1234 0.4720 | 0.8597 0.8436 1.1990 | 0.2915 39.9968 46.1457 10.2303 26.7453 38.3592, TEACHER: 0.1234 0.4720
lr at 43th epoch is 0.0001 for optimizer
current performance: -31.6716, best performance: -27.9703
Epoch: 0043 | TRAIN: 1.9755 0.2016 0.4802 | 0.7416 0.7416 0.3531 | 0.2970 40.5358 38.1266 0.1014 0.2620 0.3739 TEST: 1.9996 0.1243 0.4742 | 0.8576 0.8426 1.1730 | 0.2943 40.1140 46.3669 11.4445 26.9744 37.6836, TEACHER: 0.1243 0.4743
lr at 44th epoch is 0.0001 for optimizer
current performance: -28.5493, best performance: -27.9703
Epoch: 0044 | TRAIN: 1.9883 0.2005 0.4765 | 0.7586 0.7586 0.3668 | 0.2982 40.5510 38.2832 0.1059 0.2649 0.3748 TEST: 1.9332 0.1218 0.4746 | 0.7726 0.7569 1.0694 | 0.2946 40.3576 46.3752 9.7072 25.9041 37.3708, TEACHER: 0.1216 0.4748
lr at 45th epoch is 0.0001 for optimizer
current performance: -32.8921, best performance: -27.9703
Epoch: 0045 | TRAIN: 1.9495 0.2070 0.4840 | 0.7444 0.7444 0.3547 | 0.2967 40.4718 38.0044 0.1015 0.2649 0.3774 TEST: 1.9229 0.1253 0.4823 | 0.8997 0.8834 1.2500 | 0.2924 39.7380 46.2797 12.4009 28.4284 39.1079, TEACHER: 0.1252 0.4823
lr at 46th epoch is 0.0001 for optimizer
current performance: -30.5996, best performance: -27.9703
Epoch: 0046 | TRAIN: 1.9529 0.2033 0.4806 | 0.7560 0.7560 0.3613 | 0.2945 40.1545 37.5658 0.1128 0.2728 0.3828 TEST: 2.0939 0.1230 0.4670 | 0.8289 0.8137 1.1394 | 0.2929 40.1249 46.2376 10.9304 26.3711 37.2424, TEACHER: 0.1230 0.4674
lr at 47th epoch is 0.0001 for optimizer
current performance: -28.1226, best performance: -27.9703
Epoch: 0047 | TRAIN: 1.9645 0.2029 0.4822 | 0.7554 0.7554 0.3529 | 0.2973 40.5411 38.1045 0.1015 0.2620 0.3752 TEST: 1.9525 0.1258 0.4790 | 0.7797 0.7641 1.0969 | 0.2941 40.1522 46.3531 10.9738 26.8431 37.7552, TEACHER: 0.1259 0.4792
lr at 48th epoch is 0.0001 for optimizer
current performance: -27.5626, best performance: -27.9703
Epoch: 0048 | TRAIN: 1.9763 0.2052 0.4804 | 0.7452 0.7452 0.3614 | 0.2965 40.3730 38.0367 0.1092 0.2680 0.3784 TEST: 1.8484 0.1269 0.4805 | 0.7684 0.7547 1.0677 | 0.2926 40.1349 46.2216 10.3148 26.4118 37.6955, TEACHER: 0.1267 0.4803
lr at 49th epoch is 0.0001 for optimizer
current performance: -26.8733, best performance: -27.5626
Epoch: 0049 | TRAIN: 1.9348 0.2037 0.4891 | 0.7496 0.7496 0.3623 | 0.2954 40.2863 37.8392 0.1076 0.2702 0.3808 TEST: 1.9647 0.1268 0.4857 | 0.7601 0.7456 1.0632 | 0.2899 39.8642 46.0123 10.8535 26.9887 38.0614, TEACHER: 0.1269 0.4857
lr at 50th epoch is 0.0001 for optimizer
current performance: -28.8495, best performance: -26.8733
Epoch: 0050 | TRAIN: 1.9579 0.2050 0.4854 | 0.7401 0.7401 0.3539 | 0.2937 40.1134 37.7334 0.1115 0.2715 0.3829 TEST: 2.0703 0.1256 0.4751 | 0.8066 0.7913 1.1181 | 0.2904 39.7247 46.0965 11.9792 27.8540 38.5461, TEACHER: 0.1256 0.4750
lr at 51th epoch is 0.0001 for optimizer
current performance: -26.8263, best performance: -26.8733
Epoch: 0051 | TRAIN: 1.9533 0.2047 0.4849 | 0.7308 0.7308 0.3535 | 0.2924 40.0313 37.8536 0.1114 0.2723 0.3838 TEST: 2.0426 0.1253 0.4741 | 0.7596 0.7469 1.0552 | 0.2909 39.5962 46.1212 12.9923 28.4371 38.8906, TEACHER: 0.1252 0.4741
lr at 52th epoch is 0.0001 for optimizer
current performance: -28.3576, best performance: -26.8263
Epoch: 0052 | TRAIN: 1.9724 0.2053 0.4843 | 0.7561 0.7561 0.3590 | 0.2968 40.3542 37.8695 0.1101 0.2711 0.3820 TEST: 1.8275 0.1291 0.4883 | 0.8040 0.7905 1.1091 | 0.2901 39.7070 46.0709 11.2179 28.2550 39.3230, TEACHER: 0.1283 0.4883
lr at 53th epoch is 0.0001 for optimizer
current performance: -26.9241, best performance: -26.8263
Epoch: 0053 | TRAIN: 1.9297 0.2049 0.4889 | 0.7371 0.7371 0.3496 | 0.2941 40.1210 37.7917 0.1132 0.2745 0.3830 TEST: 1.9740 0.1265 0.4770 | 0.7521 0.7419 1.0124 | 0.2906 40.0134 46.0441 9.8628 26.6734 38.0493, TEACHER: 0.1265 0.4772
lr at 54th epoch is 0.0001 for optimizer
current performance: -27.6273, best performance: -26.8263
Epoch: 0054 | TRAIN: 1.9564 0.2058 0.4901 | 0.7308 0.7308 0.3485 | 0.2936 40.2122 37.6824 0.1047 0.2684 0.3806 TEST: 1.9055 0.1266 0.4837 | 0.7831 0.7681 1.1055 | 0.2907 39.6413 46.0963 12.4765 28.3033 38.9328, TEACHER: 0.1266 0.4837
lr at 55th epoch is 0.0001 for optimizer
current performance: -36.7671, best performance: -26.8263
Epoch: 0055 | TRAIN: 1.9444 0.2091 0.4892 | 0.7351 0.7351 0.3536 | 0.2928 40.0034 37.5655 0.1134 0.2749 0.3865 TEST: 1.9847 0.1244 0.4774 | 0.9704 0.9556 1.3238 | 0.2958 40.3228 46.4892 10.7992 26.4793 37.3225, TEACHER: 0.1244 0.4776
lr at 56th epoch is 0.0001 for optimizer
current performance: -27.5659, best performance: -26.8263
Epoch: 0056 | TRAIN: 1.9307 0.2078 0.4915 | 0.7185 0.7185 0.3355 | 0.2932 40.0939 37.6670 0.1107 0.2713 0.3828 TEST: 2.0571 0.1306 0.4910 | 0.7939 0.7821 1.1052 | 0.2890 39.5008 45.9702 12.4765 28.4282 39.2369, TEACHER: 0.1305 0.4911
lr at 57th epoch is 0.0001 for optimizer
current performance: -27.2026, best performance: -26.8263
Epoch: 0057 | TRAIN: 1.9223 0.2147 0.4976 | 0.7308 0.7308 0.3469 | 0.2918 40.0108 37.4592 0.1085 0.2713 0.3847 TEST: 1.9377 0.1299 0.4886 | 0.7829 0.7732 1.0703 | 0.2868 39.4359 45.7640 12.1015 27.9990 38.9199, TEACHER: 0.1299 0.4887
lr at 58th epoch is 0.0001 for optimizer
current performance: -27.9651, best performance: -26.8263
Epoch: 0058 | TRAIN: 1.9238 0.2082 0.4936 | 0.7338 0.7338 0.3431 | 0.2924 40.0300 37.5521 0.1092 0.2720 0.3844 TEST: 1.9959 0.1260 0.4761 | 0.7760 0.7628 1.0728 | 0.2918 40.0816 46.1648 10.5333 26.4188 37.5452, TEACHER: 0.1260 0.4765
lr at 59th epoch is 0.0001 for optimizer
current performance: -28.7692, best performance: -26.8263
Epoch: 0059 | TRAIN: 1.8987 0.2133 0.4993 | 0.7309 0.7309 0.3460 | 0.2918 39.9467 37.4607 0.1128 0.2746 0.3855 TEST: 1.9339 0.1276 0.4816 | 0.8164 0.8020 1.1392 | 0.2907 39.4619 46.1667 13.1757 29.6467 39.9655, TEACHER: 0.1276 0.4815
lr at 60th epoch is 0.0001 for optimizer
current performance: -29.9989, best performance: -26.8263
Epoch: 0060 | TRAIN: 1.9104 0.2148 0.4990 | 0.7265 0.7265 0.3474 | 0.2894 39.6687 37.1688 0.1200 0.2806 0.3913 TEST: 2.0206 0.1269 0.4842 | 0.8356 0.8206 1.1480 | 0.2891 39.7659 45.9160 11.3042 27.1242 37.9970, TEACHER: 0.1268 0.4843
lr at 61th epoch is 0.0001 for optimizer
current performance: -26.2504, best performance: -26.8263
Epoch: 0061 | TRAIN: 1.9127 0.2147 0.5010 | 0.7287 0.7287 0.3371 | 0.2883 39.5847 37.0417 0.1174 0.2820 0.3941 TEST: 1.9566 0.1337 0.4981 | 0.7691 0.7570 1.0617 | 0.2884 39.6412 45.9072 11.1816 27.7695 38.8479, TEACHER: 0.1337 0.4982
lr at 62th epoch is 0.0001 for optimizer
current performance: -25.0892, best performance: -26.2504
Epoch: 0062 | TRAIN: 1.8937 0.2157 0.5038 | 0.7224 0.7224 0.3473 | 0.2882 39.6307 37.0559 0.1151 0.2790 0.3916 TEST: 1.8113 0.1319 0.4881 | 0.7486 0.7362 1.0346 | 0.2854 39.1976 45.6651 12.5519 29.0491 39.8112, TEACHER: 0.1308 0.4878
lr at 63th epoch is 0.0001 for optimizer
current performance: -29.4290, best performance: -25.0892
Epoch: 0063 | TRAIN: 1.9013 0.2168 0.5027 | 0.7158 0.7158 0.3452 | 0.2910 39.8242 37.4434 0.1173 0.2764 0.3870 TEST: 1.9449 0.1313 0.4936 | 0.8419 0.8269 1.1696 | 0.2866 39.5122 45.7357 11.4560 27.6428 38.7237, TEACHER: 0.1313 0.4935
lr at 64th epoch is 0.0001 for optimizer
current performance: -28.1478, best performance: -25.0892
Epoch: 0064 | TRAIN: 1.8905 0.2135 0.5036 | 0.7253 0.7253 0.3374 | 0.2868 39.5061 36.9269 0.1169 0.2796 0.3922 TEST: 2.0265 0.1287 0.4894 | 0.8079 0.7940 1.1226 | 0.2884 39.3456 45.9491 12.8457 29.1692 39.8587, TEACHER: 0.1288 0.4893
lr at 65th epoch is 0.0001 for optimizer
current performance: -26.0960, best performance: -25.0892
Epoch: 0065 | TRAIN: 1.9007 0.2122 0.5041 | 0.7154 0.7154 0.3357 | 0.2881 39.5549 36.9019 0.1174 0.2828 0.3944 TEST: 1.9695 0.1301 0.4847 | 0.7632 0.7517 1.0491 | 0.2853 39.2930 45.6593 12.1920 28.2115 39.3109, TEACHER: 0.1302 0.4845
lr at 66th epoch is 0.0001 for optimizer
current performance: -24.5185, best performance: -25.0892
Epoch: 0066 | TRAIN: 1.9326 0.2186 0.5002 | 0.7092 0.7092 0.3332 | 0.2865 39.4607 36.8879 0.1163 0.2828 0.3950 TEST: 1.8274 0.1308 0.4906 | 0.7378 0.7245 1.0248 | 0.2850 39.0205 45.6902 13.0878 29.7439 40.6135, TEACHER: 0.1288 0.4896
lr at 67th epoch is 0.0001 for optimizer
current performance: -25.1230, best performance: -24.5185
Epoch: 0067 | TRAIN: 1.9234 0.2138 0.5003 | 0.7120 0.7120 0.3424 | 0.2889 39.6554 37.0996 0.1158 0.2817 0.3926 TEST: 2.0852 0.1273 0.4835 | 0.7297 0.7165 1.0135 | 0.2888 39.4750 45.9698 12.5400 28.6234 39.3580, TEACHER: 0.1274 0.4836
lr at 68th epoch is 0.0001 for optimizer
current performance: -24.0245, best performance: -24.5185
Epoch: 0068 | TRAIN: 1.8600 0.2184 0.5113 | 0.7180 0.7180 0.3400 | 0.2850 39.2769 36.6021 0.1201 0.2874 0.3991 TEST: 2.0744 0.1306 0.4875 | 0.7332 0.7197 1.0254 | 0.2824 38.7365 45.4950 13.5447 30.4410 41.3264, TEACHER: 0.1307 0.4875
lr at 69th epoch is 0.0001 for optimizer
current performance: -24.5479, best performance: -24.0245
Epoch: 0069 | TRAIN: 1.9071 0.2146 0.5053 | 0.7167 0.7167 0.3429 | 0.2853 39.3071 36.6342 0.1195 0.2861 0.3988 TEST: 1.9169 0.1306 0.4909 | 0.7440 0.7297 1.0479 | 0.2803 38.8175 45.2405 11.9716 29.2855 40.7248, TEACHER: 0.1306 0.4908
lr at 70th epoch is 0.0001 for optimizer
current performance: -26.1169, best performance: -24.0245
Epoch: 0070 | TRAIN: 1.8916 0.2130 0.5029 | 0.7111 0.7111 0.3418 | 0.2874 39.4804 36.8208 0.1169 0.2856 0.3978 TEST: 1.8873 0.1325 0.4935 | 0.7829 0.7725 1.0785 | 0.2794 38.7845 45.1617 11.6865 29.2469 40.7711, TEACHER: 0.1317 0.4933
lr at 71th epoch is 0.0001 for optimizer
current performance: -22.7729, best performance: -24.0245
Epoch: 0071 | TRAIN: 1.8861 0.2156 0.5031 | 0.7022 0.7022 0.3242 | 0.2870 39.4932 36.8507 0.1152 0.2818 0.3965 TEST: 1.9631 0.1326 0.4982 | 0.7164 0.7035 1.0072 | 0.2776 38.4667 45.0429 13.2415 30.1508 41.2277, TEACHER: 0.1328 0.4986
lr at 72th epoch is 0.0001 for optimizer
current performance: -26.2623, best performance: -22.7729
Epoch: 0072 | TRAIN: 1.8981 0.2128 0.5053 | 0.7170 0.7170 0.3350 | 0.2843 39.1795 36.5954 0.1230 0.2893 0.4012 TEST: 2.0734 0.1306 0.4871 | 0.7668 0.7554 1.0390 | 0.2871 39.3621 45.8229 12.2354 28.5741 39.5260, TEACHER: 0.1310 0.4872
lr at 73th epoch is 0.0001 for optimizer
current performance: -25.6221, best performance: -22.7729
Epoch: 0073 | TRAIN: 1.8878 0.2152 0.5092 | 0.7011 0.7011 0.3330 | 0.2809 38.9120 36.0491 0.1217 0.2917 0.4056 TEST: 1.7977 0.1351 0.5024 | 0.7881 0.7757 1.1055 | 0.2759 38.5082 44.8981 11.5992 29.6545 41.5142, TEACHER: 0.1341 0.5020
lr at 74th epoch is 0.0001 for optimizer
current performance: -22.8420, best performance: -22.7729
Epoch: 0074 | TRAIN: 1.8517 0.2181 0.5146 | 0.6950 0.6950 0.3299 | 0.2804 38.8834 35.9498 0.1202 0.2927 0.4078 TEST: 1.9292 0.1322 0.5024 | 0.7262 0.7144 1.0060 | 0.2755 38.0603 44.9117 14.8570 31.4247 42.1417, TEACHER: 0.1323 0.5025
lr at 75th epoch is 0.0001 for optimizer
current performance: -27.2177, best performance: -22.7729
Epoch: 0075 | TRAIN: 1.8854 0.2177 0.5112 | 0.6824 0.6824 0.3187 | 0.2808 38.9156 36.2125 0.1211 0.2908 0.4064 TEST: 1.9539 0.1356 0.4984 | 0.8327 0.8209 1.1416 | 0.2759 38.2515 44.9257 13.3872 31.0456 42.1587, TEACHER: 0.1337 0.4980
lr at 76th epoch is 0.0001 for optimizer
current performance: -23.4986, best performance: -22.7729
Epoch: 0076 | TRAIN: 1.8836 0.2167 0.5106 | 0.7032 0.7032 0.3296 | 0.2820 39.0476 36.1749 0.1177 0.2892 0.4042 TEST: 1.8930 0.1300 0.4994 | 0.7312 0.7208 0.9999 | 0.2775 38.1472 45.1151 14.7780 31.9166 42.6837, TEACHER: 0.1296 0.4993
lr at 77th epoch is 0.0001 for optimizer
current performance: -25.5001, best performance: -22.7729
Epoch: 0077 | TRAIN: 1.8634 0.2170 0.5129 | 0.6935 0.6935 0.3255 | 0.2802 38.7871 35.8606 0.1255 0.2955 0.4094 TEST: 1.9767 0.1341 0.4981 | 0.7808 0.7739 1.0505 | 0.2736 38.3623 44.6479 12.0197 29.5554 41.1327, TEACHER: 0.1344 0.4981
lr at 78th epoch is 0.0001 for optimizer
current performance: -24.8928, best performance: -22.7729
Epoch: 0078 | TRAIN: 1.8511 0.2192 0.5180 | 0.6970 0.6970 0.3228 | 0.2800 38.8572 35.8665 0.1195 0.2926 0.4085 TEST: 1.9040 0.1338 0.5014 | 0.7643 0.7580 1.0286 | 0.2755 38.3985 44.8495 12.3312 29.9089 41.6235, TEACHER: 0.1337 0.5012
lr at 79th epoch is 0.0001 for optimizer
current performance: -23.1228, best performance: -22.7729
Epoch: 0079 | TRAIN: 1.8632 0.2171 0.5125 | 0.6761 0.6761 0.3243 | 0.2795 38.7532 35.8626 0.1235 0.2954 0.4109 TEST: 2.0670 0.1319 0.4984 | 0.7269 0.7166 0.9912 | 0.2746 38.1974 44.7926 13.1978 30.6708 42.1319, TEACHER: 0.1321 0.4984
lr at 80th epoch is 0.0001 for optimizer
current performance: -20.7286, best performance: -22.7729
Epoch: 0080 | TRAIN: 1.9026 0.2168 0.5097 | 0.6846 0.6846 0.3149 | 0.2787 38.7505 35.9664 0.1211 0.2924 0.4086 TEST: 1.8005 0.1413 0.5090 | 0.7094 0.6997 0.9693 | 0.2683 37.7749 44.2374 12.6173 31.2363 42.8565, TEACHER: 0.1376 0.5078
lr at 81th epoch is 0.0001 for optimizer
current performance: -22.8577, best performance: -20.7286
Epoch: 0081 | TRAIN: 1.8682 0.2168 0.5120 | 0.6787 0.6787 0.3267 | 0.2783 38.6843 35.7791 0.1214 0.2957 0.4115 TEST: 2.0638 0.1300 0.5018 | 0.7164 0.7036 1.0074 | 0.2738 38.2411 44.7255 12.2127 30.4981 42.2382, TEACHER: 0.1301 0.5018
lr at 82th epoch is 0.0001 for optimizer
current performance: -24.4751, best performance: -20.7286
Epoch: 0082 | TRAIN: 1.8642 0.2191 0.5147 | 0.6913 0.6913 0.3261 | 0.2740 38.3166 35.4589 0.1248 0.2995 0.4166 TEST: 1.9622 0.1336 0.5028 | 0.7779 0.7672 1.0384 | 0.2673 37.6344 44.1338 13.5441 31.1354 42.6038, TEACHER: 0.1338 0.5030
lr at 83th epoch is 0.0001 for optimizer
current performance: -25.7201, best performance: -20.7286
Epoch: 0083 | TRAIN: 1.8479 0.2233 0.5214 | 0.6919 0.6919 0.3242 | 0.2753 38.4829 35.8932 0.1236 0.2949 0.4102 TEST: 1.9537 0.1336 0.5004 | 0.7999 0.7885 1.1093 | 0.2723 37.9361 44.5757 13.6733 31.2073 42.5843, TEACHER: 0.1346 0.5008
lr at 84th epoch is 0.0001 for optimizer
current performance: -24.6159, best performance: -20.7286
Epoch: 0084 | TRAIN: 1.8471 0.2210 0.5181 | 0.6758 0.6758 0.3195 | 0.2719 38.1010 35.3383 0.1279 0.3031 0.4212 TEST: 1.9190 0.1392 0.5029 | 0.8095 0.7963 1.1013 | 0.2638 37.2777 43.8086 13.6186 31.6546 43.6282, TEACHER: 0.1368 0.5022
lr at 85th epoch is 0.0001 for optimizer
current performance: -21.0454, best performance: -20.7286
Epoch: 0085 | TRAIN: 1.8508 0.2204 0.5188 | 0.6800 0.6800 0.3230 | 0.2700 37.9136 35.0055 0.1298 0.3057 0.4239 TEST: 1.9903 0.1351 0.4977 | 0.7149 0.7041 0.9905 | 0.2613 37.1788 43.5945 12.8207 31.8275 43.9096, TEACHER: 0.1342 0.4974
lr at 86th epoch is 0.0001 for optimizer
current performance: -21.7061, best performance: -20.7286
Epoch: 0086 | TRAIN: 1.8521 0.2207 0.5221 | 0.6588 0.6588 0.3126 | 0.2699 37.9861 34.9658 0.1229 0.3053 0.4249 TEST: 1.9620 0.1322 0.4980 | 0.7194 0.7088 0.9986 | 0.2647 37.2591 43.9484 14.1630 32.3723 43.8275, TEACHER: 0.1319 0.4978
lr at 87th epoch is 0.0001 for optimizer
current performance: -21.1133, best performance: -20.7286
Epoch: 0087 | TRAIN: 1.8411 0.2211 0.5222 | 0.6814 0.6814 0.3198 | 0.2722 38.1348 35.1992 0.1262 0.3037 0.4212 TEST: 1.8783 0.1371 0.5087 | 0.7265 0.7158 1.0020 | 0.2618 37.0108 43.6749 14.1447 32.5114 44.3263, TEACHER: 0.1373 0.5089
lr at 88th epoch is 0.0001 for optimizer
current performance: -26.8268, best performance: -20.7286
Epoch: 0088 | TRAIN: 1.8005 0.2210 0.5273 | 0.6563 0.6563 0.3135 | 0.2672 37.6537 34.6010 0.1306 0.3122 0.4310 TEST: 2.0310 0.1356 0.5026 | 0.8419 0.8287 1.1659 | 0.2666 37.5969 44.0485 13.0730 31.0697 42.8838, TEACHER: 0.1370 0.5032
lr at 89th epoch is 0.0001 for optimizer
current performance: -19.9443, best performance: -20.7286
Epoch: 0089 | TRAIN: 1.8581 0.2169 0.5209 | 0.6637 0.6637 0.3144 | 0.2680 37.7576 34.7323 0.1297 0.3101 0.4283 TEST: 1.9917 0.1365 0.5054 | 0.7064 0.6969 0.9649 | 0.2554 36.6291 43.0370 13.6562 32.3997 44.4272, TEACHER: 0.1369 0.5054
lr at 90th epoch is 0.0001 for optimizer
current performance: -19.8482, best performance: -19.9443
Epoch: 0090 | TRAIN: 1.8195 0.2224 0.5289 | 0.6386 0.6386 0.3007 | 0.2671 37.7206 34.7656 0.1272 0.3088 0.4281 TEST: 1.9721 0.1420 0.5063 | 0.7182 0.7069 0.9931 | 0.2569 36.7829 43.1727 13.6036 32.1485 44.1343, TEACHER: 0.1423 0.5068
lr at 91th epoch is 0.0001 for optimizer
current performance: -23.1442, best performance: -19.8482
Epoch: 0091 | TRAIN: 1.8302 0.2207 0.5295 | 0.6683 0.6683 0.3120 | 0.2663 37.6926 34.7538 0.1265 0.3057 0.4263 TEST: 2.0132 0.1350 0.4964 | 0.7597 0.7516 1.0237 | 0.2632 37.2040 43.7571 13.7311 32.0193 43.7299, TEACHER: 0.1351 0.4963
lr at 92th epoch is 0.0001 for optimizer
current performance: -18.0933, best performance: -19.8482
Epoch: 0092 | TRAIN: 1.8439 0.2190 0.5290 | 0.6743 0.6743 0.3272 | 0.2674 37.7424 34.6920 0.1262 0.3083 0.4286 TEST: 1.8827 0.1461 0.5074 | 0.6884 0.6771 0.9555 | 0.2578 36.8345 43.2727 13.5794 32.3856 44.1900, TEACHER: 0.1438 0.5067
lr at 93th epoch is 0.0001 for optimizer
current performance: -20.1067, best performance: -18.0933
Epoch: 0093 | TRAIN: 1.8377 0.2223 0.5257 | 0.6533 0.6533 0.3116 | 0.2643 37.5479 34.6058 0.1256 0.3073 0.4289 TEST: 1.9302 0.1372 0.5012 | 0.7161 0.7043 0.9926 | 0.2553 36.5626 42.9985 14.2061 32.6216 44.3918, TEACHER: 0.1378 0.5012
lr at 94th epoch is 0.0001 for optimizer
current performance: -20.8032, best performance: -18.0933
Epoch: 0094 | TRAIN: 1.8441 0.2174 0.5252 | 0.6491 0.6491 0.3032 | 0.2644 37.4991 34.5308 0.1293 0.3103 0.4298 TEST: 1.9611 0.1408 0.5072 | 0.7376 0.7250 1.0257 | 0.2563 36.7991 43.1040 13.5483 31.7915 43.7243, TEACHER: 0.1418 0.5076
lr at 95th epoch is 0.0001 for optimizer
current performance: -21.4677, best performance: -18.0933
Epoch: 0095 | TRAIN: 1.8390 0.2208 0.5251 | 0.6531 0.6531 0.3102 | 0.2626 37.3000 34.2855 0.1315 0.3159 0.4359 TEST: 1.9120 0.1475 0.5156 | 0.7760 0.7655 1.0709 | 0.2542 36.5933 42.9039 13.3199 32.3739 44.3897, TEACHER: 0.1467 0.5152
lr at 96th epoch is 0.0001 for optimizer
current performance: -19.1186, best performance: -18.0933
Epoch: 0096 | TRAIN: 1.8584 0.2183 0.5238 | 0.6596 0.6596 0.3240 | 0.2624 37.3127 34.3193 0.1303 0.3135 0.4346 TEST: 1.9478 0.1451 0.5034 | 0.7059 0.6983 0.9532 | 0.2592 36.8148 43.4095 14.8162 32.6462 44.0479, TEACHER: 0.1452 0.5033
lr at 97th epoch is 0.0001 for optimizer
current performance: -18.0410, best performance: -18.0933
Epoch: 0097 | TRAIN: 1.8255 0.2194 0.5328 | 0.6529 0.6529 0.3072 | 0.2630 37.3430 34.4087 0.1302 0.3142 0.4347 TEST: 1.9745 0.1550 0.5107 | 0.7279 0.7197 0.9807 | 0.2505 36.1544 42.5966 14.4682 33.2831 45.2056, TEACHER: 0.1532 0.5104
lr at 98th epoch is 0.0001 for optimizer
current performance: -18.8176, best performance: -18.0410
Epoch: 0098 | TRAIN: 1.8121 0.2247 0.5320 | 0.6460 0.6460 0.3104 | 0.2605 37.1236 34.1184 0.1337 0.3182 0.4376 TEST: 1.8636 0.1487 0.5123 | 0.7289 0.7208 0.9791 | 0.2497 36.0780 42.5027 14.4947 33.3717 45.3214, TEACHER: 0.1471 0.5116
lr at 99th epoch is 0.0001 for optimizer
current performance: -18.9173, best performance: -18.0410
Epoch: 0099 | TRAIN: 1.8231 0.2184 0.5355 | 0.6571 0.6571 0.3125 | 0.2622 37.2781 34.3044 0.1315 0.3158 0.4356 TEST: 2.1068 0.1449 0.4957 | 0.7084 0.6970 0.9733 | 0.2533 36.6557 42.8254 12.4344 31.7298 44.2127, TEACHER: 0.1459 0.4960
lr at 100th epoch is 5e-05 for optimizer
current performance: -16.9336, best performance: -18.0410
Epoch: 0100 | TRAIN: 1.8074 0.2253 0.5399 | 0.6175 0.6175 0.2994 | 0.2581 36.9174 33.8177 0.1324 0.3213 0.4431 TEST: 1.9143 0.1532 0.5121 | 0.7091 0.6979 0.9836 | 0.2465 35.7960 42.2661 14.8705 33.8907 45.8252, TEACHER: 0.1528 0.5120
lr at 101th epoch is 5e-05 for optimizer
current performance: -15.8380, best performance: -16.9336
Epoch: 0101 | TRAIN: 1.7729 0.2281 0.5514 | 0.6141 0.6141 0.2913 | 0.2535 36.4474 33.3691 0.1400 0.3295 0.4509 TEST: 1.8848 0.1633 0.5162 | 0.7070 0.6962 0.9782 | 0.2469 36.0306 42.2470 13.0523 32.8896 45.4801, TEACHER: 0.1633 0.5163
lr at 102th epoch is 5e-05 for optimizer
current performance: -15.6709, best performance: -15.8380
Epoch: 0102 | TRAIN: 1.7962 0.2288 0.5466 | 0.6048 0.6048 0.2855 | 0.2549 36.5680 33.5082 0.1403 0.3279 0.4485 TEST: 1.8657 0.1625 0.5188 | 0.7074 0.6966 0.9799 | 0.2442 35.7669 41.9989 13.8755 33.2242 45.6245, TEACHER: 0.1630 0.5188
lr at 103th epoch is 5e-05 for optimizer
current performance: -15.2425, best performance: -15.6709
Epoch: 0103 | TRAIN: 1.7789 0.2252 0.5506 | 0.5994 0.5994 0.2817 | 0.2533 36.4971 33.4375 0.1376 0.3259 0.4485 TEST: 2.0379 0.1640 0.5150 | 0.6941 0.6846 0.9647 | 0.2483 36.0234 42.4042 14.1790 33.4084 45.4232, TEACHER: 0.1626 0.5147
lr at 104th epoch is 5e-05 for optimizer
current performance: -14.0428, best performance: -15.2425
Epoch: 0104 | TRAIN: 1.7878 0.2292 0.5504 | 0.6029 0.6029 0.2864 | 0.2542 36.5306 33.4190 0.1391 0.3279 0.4491 TEST: 1.9981 0.1707 0.5241 | 0.6901 0.6796 0.9460 | 0.2474 35.9127 42.3327 14.4092 33.6274 45.6451, TEACHER: 0.1706 0.5240
lr at 105th epoch is 5e-05 for optimizer
current performance: -16.2151, best performance: -14.0428
Epoch: 0105 | TRAIN: 1.7782 0.2248 0.5516 | 0.6065 0.6065 0.2911 | 0.2512 36.2567 33.1154 0.1414 0.3322 0.4548 TEST: 1.9522 0.1624 0.5117 | 0.7182 0.7095 0.9769 | 0.2457 35.7465 42.1520 14.5397 33.7966 45.9888, TEACHER: 0.1619 0.5114
lr at 106th epoch is 5e-05 for optimizer
current performance: -14.1238, best performance: -14.0428
Epoch: 0106 | TRAIN: 1.7678 0.2220 0.5542 | 0.6112 0.6112 0.2906 | 0.2546 36.5520 33.3817 0.1394 0.3266 0.4489 TEST: 2.0621 0.1702 0.5189 | 0.6971 0.6860 0.9751 | 0.2440 35.6782 41.9858 14.3438 33.5563 45.8601, TEACHER: 0.1709 0.5192
lr at 107th epoch is 5e-05 for optimizer
current performance: -13.4433, best performance: -14.0428
Epoch: 0107 | TRAIN: 1.8146 0.2212 0.5497 | 0.5890 0.5890 0.2816 | 0.2536 36.4740 33.2411 0.1394 0.3279 0.4510 TEST: 2.0115 0.1785 0.5263 | 0.7035 0.6925 0.9768 | 0.2447 35.7636 42.0204 14.0432 33.3191 45.7029, TEACHER: 0.1788 0.5264
lr at 108th epoch is 5e-05 for optimizer
current performance: -11.7942, best performance: -13.4433
Epoch: 0108 | TRAIN: 1.7935 0.2314 0.5548 | 0.5859 0.5859 0.2775 | 0.2533 36.4730 33.3644 0.1383 0.3264 0.4495 TEST: 1.9016 0.1847 0.5233 | 0.6874 0.6775 0.9434 | 0.2444 35.5807 42.0568 15.1877 34.2842 46.1751, TEACHER: 0.1844 0.5244
lr at 109th epoch is 5e-05 for optimizer
current performance: -14.6681, best performance: -11.7942
Epoch: 0109 | TRAIN: 1.7785 0.2271 0.5531 | 0.5932 0.5932 0.2804 | 0.2536 36.4533 33.2681 0.1397 0.3291 0.4515 TEST: 1.9771 0.1784 0.5269 | 0.7279 0.7201 0.9845 | 0.2445 35.7883 42.0145 13.9188 33.2879 45.5143, TEACHER: 0.1780 0.5266
lr at 110th epoch is 5e-05 for optimizer
current performance: -16.8434, best performance: -11.7942
Epoch: 0110 | TRAIN: 1.7698 0.2284 0.5593 | 0.5866 0.5866 0.2800 | 0.2518 36.3426 33.2247 0.1400 0.3291 0.4508 TEST: 2.0483 0.1688 0.5180 | 0.7483 0.7391 1.0235 | 0.2489 35.8980 42.5008 14.9988 34.1661 46.1235, TEACHER: 0.1684 0.5179
lr at 111th epoch is 5e-05 for optimizer
current performance: -12.3525, best performance: -11.7942
Epoch: 0111 | TRAIN: 1.7884 0.2277 0.5584 | 0.5948 0.5948 0.2784 | 0.2521 36.3200 33.1526 0.1422 0.3313 0.4531 TEST: 2.0941 0.1772 0.5279 | 0.6802 0.6727 0.9283 | 0.2426 35.4073 41.8736 15.3035 34.4853 46.5241, TEACHER: 0.1777 0.5280
lr at 112th epoch is 5e-05 for optimizer
current performance: -13.1081, best performance: -11.7942
Epoch: 0112 | TRAIN: 1.7773 0.2270 0.5586 | 0.5919 0.5919 0.2774 | 0.2499 36.1144 32.8664 0.1435 0.3339 0.4570 TEST: 2.0208 0.1748 0.5197 | 0.6879 0.6780 0.9429 | 0.2439 35.6011 41.9699 14.8433 33.8805 45.9664, TEACHER: 0.1743 0.5195
lr at 113th epoch is 5e-05 for optimizer
current performance: -12.4816, best performance: -11.7942
Epoch: 0113 | TRAIN: 1.7948 0.2192 0.5573 | 0.5970 0.5970 0.2816 | 0.2516 36.3035 33.1479 0.1407 0.3304 0.4528 TEST: 2.1716 0.1784 0.5200 | 0.6807 0.6721 0.9300 | 0.2450 35.6793 42.1064 14.8011 33.9634 45.9482, TEACHER: 0.1786 0.5200
lr at 114th epoch is 5e-05 for optimizer
current performance: -16.1738, best performance: -11.7942
Epoch: 0114 | TRAIN: 1.8180 0.2220 0.5539 | 0.5954 0.5954 0.2776 | 0.2516 36.2980 33.0749 0.1398 0.3313 0.4538 TEST: 1.9665 0.1811 0.5306 | 0.7838 0.7714 1.0789 | 0.2437 35.4496 42.0023 15.3549 34.5504 46.6391, TEACHER: 0.1817 0.5307
lr at 115th epoch is 5e-05 for optimizer
current performance: -11.6178, best performance: -11.7942
Epoch: 0115 | TRAIN: 1.7742 0.2249 0.5638 | 0.5845 0.5845 0.2826 | 0.2532 36.3676 33.1808 0.1426 0.3328 0.4545 TEST: 2.0416 0.1819 0.5267 | 0.6795 0.6679 0.9477 | 0.2430 35.4654 41.9124 15.1766 34.4267 46.3442, TEACHER: 0.1826 0.5269
lr at 116th epoch is 5e-05 for optimizer
current performance: -13.9887, best performance: -11.6178
Epoch: 0116 | TRAIN: 1.8047 0.2306 0.5609 | 0.5753 0.5753 0.2791 | 0.2539 36.4670 33.3725 0.1413 0.3294 0.4508 TEST: 1.9215 0.1810 0.5265 | 0.7364 0.7251 1.0258 | 0.2406 35.2781 41.7146 15.0533 34.4798 46.7804, TEACHER: 0.1793 0.5257
lr at 117th epoch is 5e-05 for optimizer
current performance: -11.8980, best performance: -11.6178
Epoch: 0117 | TRAIN: 1.8191 0.2215 0.5556 | 0.5953 0.5953 0.2787 | 0.2515 36.2599 33.0853 0.1429 0.3319 0.4539 TEST: 2.0516 0.1804 0.5240 | 0.6816 0.6725 0.9372 | 0.2419 35.3713 41.7951 15.3067 34.3672 46.3700, TEACHER: 0.1794 0.5235
lr at 118th epoch is 5e-05 for optimizer
current performance: -12.5923, best performance: -11.6178
Epoch: 0118 | TRAIN: 1.8064 0.2222 0.5662 | 0.5838 0.5838 0.2745 | 0.2532 36.4590 33.3084 0.1384 0.3275 0.4501 TEST: 2.0412 0.1828 0.5261 | 0.7108 0.7000 0.9824 | 0.2407 35.1992 41.7327 15.5830 35.0163 46.9868, TEACHER: 0.1828 0.5262
lr at 119th epoch is 5e-05 for optimizer
current performance: -11.3130, best performance: -11.6178
Epoch: 0119 | TRAIN: 1.8173 0.2231 0.5608 | 0.5901 0.5901 0.2783 | 0.2533 36.3362 33.1447 0.1456 0.3340 0.4549 TEST: 1.9794 0.1872 0.5357 | 0.6924 0.6824 0.9624 | 0.2408 35.2444 41.7385 15.3978 34.7841 46.8393, TEACHER: 0.1865 0.5354
lr at 120th epoch is 5e-05 for optimizer
current performance: -11.9226, best performance: -11.3130
Epoch: 0120 | TRAIN: 1.7958 0.2245 0.5657 | 0.5925 0.5925 0.2761 | 0.2517 36.2579 33.0796 0.1435 0.3332 0.4550 TEST: 2.0818 0.1793 0.5267 | 0.6762 0.6670 0.9313 | 0.2420 35.4795 41.8130 14.7819 33.8923 46.0833, TEACHER: 0.1792 0.5265
lr at 121th epoch is 5e-05 for optimizer
current performance: -11.5973, best performance: -11.3130
Epoch: 0121 | TRAIN: 1.8057 0.2230 0.5681 | 0.5884 0.5884 0.2795 | 0.2495 36.1031 32.9641 0.1439 0.3319 0.4552 TEST: 2.2302 0.1825 0.5258 | 0.6846 0.6758 0.9339 | 0.2407 35.2097 41.7328 15.5784 34.8492 46.9242, TEACHER: 0.1839 0.5263
lr at 122th epoch is 5e-05 for optimizer
current performance: -13.1572, best performance: -11.3130
Epoch: 0122 | TRAIN: 1.7775 0.2289 0.5728 | 0.5817 0.5817 0.2754 | 0.2512 36.2182 32.9747 0.1425 0.3342 0.4561 TEST: 2.0078 0.1873 0.5281 | 0.7339 0.7217 1.0244 | 0.2430 35.3848 41.9608 15.5225 34.7235 46.7419, TEACHER: 0.1881 0.5283
lr at 123th epoch is 5e-05 for optimizer
current performance: -11.6322, best performance: -11.3130
Epoch: 0123 | TRAIN: 1.8302 0.2226 0.5661 | 0.5801 0.5801 0.2736 | 0.2520 36.2840 33.0371 0.1424 0.3331 0.4551 TEST: 2.0229 0.1948 0.5247 | 0.7096 0.6988 0.9835 | 0.2450 35.7644 42.0706 14.2552 33.6306 45.7554, TEACHER: 0.1944 0.5247
lr at 124th epoch is 5e-05 for optimizer
current performance: -10.9721, best performance: -11.3130
Epoch: 0124 | TRAIN: 1.8231 0.2169 0.5645 | 0.5826 0.5826 0.2736 | 0.2513 36.2664 33.0607 0.1406 0.3310 0.4541 TEST: 2.1097 0.1895 0.5195 | 0.6895 0.6775 0.9598 | 0.2424 35.3924 41.8887 15.3380 34.5423 46.5533, TEACHER: 0.1894 0.5190
lr at 125th epoch is 5e-05 for optimizer
current performance: -12.5641, best performance: -10.9721
Epoch: 0125 | TRAIN: 1.8423 0.2228 0.5696 | 0.5871 0.5871 0.2756 | 0.2530 36.3991 33.2341 0.1406 0.3304 0.4520 TEST: 2.0772 0.1864 0.5327 | 0.7165 0.7048 0.9953 | 0.2413 35.4044 41.7643 14.7145 34.2457 46.4143, TEACHER: 0.1869 0.5328
lr at 126th epoch is 5e-05 for optimizer
current performance: -9.7405, best performance: -10.9721
Epoch: 0126 | TRAIN: 1.8286 0.2232 0.5674 | 0.5870 0.5870 0.2787 | 0.2511 36.1489 32.9133 0.1474 0.3365 0.4574 TEST: 1.9341 0.2004 0.5352 | 0.6910 0.6809 0.9458 | 0.2432 35.3985 41.9661 15.4848 34.8481 46.7044, TEACHER: 0.1998 0.5349
lr at 127th epoch is 5e-05 for optimizer
current performance: -10.2804, best performance: -9.7405
Epoch: 0127 | TRAIN: 1.7828 0.2205 0.5758 | 0.5722 0.5722 0.2731 | 0.2499 36.0756 32.8883 0.1468 0.3362 0.4576 TEST: 2.0383 0.1947 0.5310 | 0.6929 0.6823 0.9527 | 0.2409 35.1776 41.7694 15.7752 35.1119 47.1021, TEACHER: 0.1948 0.5311
lr at 128th epoch is 5e-05 for optimizer
current performance: -11.6270, best performance: -9.7405
Epoch: 0128 | TRAIN: 1.8303 0.2235 0.5711 | 0.5776 0.5776 0.2755 | 0.2495 35.9923 32.7421 0.1489 0.3386 0.4601 TEST: 2.2725 0.1855 0.5273 | 0.6963 0.6855 0.9684 | 0.2426 35.2034 41.9494 16.3421 35.5200 47.3236, TEACHER: 0.1856 0.5274
lr at 129th epoch is 5e-05 for optimizer
current performance: -16.4810, best performance: -9.7405
Epoch: 0129 | TRAIN: 1.8451 0.2226 0.5720 | 0.5802 0.5802 0.2756 | 0.2518 36.2796 32.9929 0.1411 0.3329 0.4557 TEST: 2.1138 0.1914 0.5234 | 0.8112 0.8009 1.1089 | 0.2452 35.7729 42.1165 14.2457 33.4890 45.7869, TEACHER: 0.1913 0.5233
lr at 130th epoch is 5e-05 for optimizer
current performance: -16.8734, best performance: -9.7405
Epoch: 0130 | TRAIN: 1.8351 0.2204 0.5725 | 0.6045 0.6045 0.2867 | 0.2521 36.2321 32.9088 0.1463 0.3357 0.4563 TEST: 2.1071 0.1872 0.5254 | 0.8159 0.8037 1.1274 | 0.2427 35.5345 41.8735 14.3761 33.9370 46.3135, TEACHER: 0.1882 0.5257
lr at 131th epoch is 5e-05 for optimizer
current performance: -11.3724, best performance: -9.7405
Epoch: 0131 | TRAIN: 1.8227 0.2222 0.5757 | 0.5877 0.5877 0.2785 | 0.2516 36.2890 33.2134 0.1421 0.3309 0.4522 TEST: 2.1961 0.1800 0.5268 | 0.6682 0.6596 0.9106 | 0.2411 35.3515 41.7234 15.0248 34.2827 46.4139, TEACHER: 0.1804 0.5268
lr at 132th epoch is 5e-05 for optimizer
current performance: -9.7326, best performance: -9.7405
Epoch: 0132 | TRAIN: 1.8077 0.2220 0.5782 | 0.5759 0.5759 0.2745 | 0.2495 35.9936 32.7288 0.1484 0.3397 0.4608 TEST: 2.1896 0.1950 0.5357 | 0.6808 0.6712 0.9382 | 0.2401 35.1478 41.6993 15.4882 35.1177 47.2067, TEACHER: 0.1949 0.5356
lr at 133th epoch is 5e-05 for optimizer
current performance: -10.0641, best performance: -9.7326
Epoch: 0133 | TRAIN: 1.8234 0.2279 0.5823 | 0.5756 0.5756 0.2674 | 0.2473 35.8017 32.3686 0.1485 0.3419 0.4649 TEST: 2.1206 0.1983 0.5312 | 0.6956 0.6859 0.9460 | 0.2423 35.2523 41.9115 16.0344 35.2930 47.1194, TEACHER: 0.1984 0.5314
lr at 134th epoch is 5e-05 for optimizer
current performance: -10.5994, best performance: -9.7326
Epoch: 0134 | TRAIN: 1.8400 0.2268 0.5794 | 0.5834 0.5834 0.2689 | 0.2487 35.9590 32.6623 0.1466 0.3380 0.4611 TEST: 2.0019 0.2040 0.5325 | 0.7234 0.7116 1.0084 | 0.2430 35.3918 41.9532 15.3056 34.7751 46.8303, TEACHER: 0.2031 0.5322
lr at 135th epoch is 5e-05 for optimizer
current performance: -10.0898, best performance: -9.7326
Epoch: 0135 | TRAIN: 1.8391 0.2237 0.5787 | 0.5757 0.5757 0.2737 | 0.2540 36.3941 33.0391 0.1441 0.3339 0.4550 TEST: 2.0226 0.1982 0.5343 | 0.6900 0.6807 0.9430 | 0.2418 35.4733 41.7918 14.5090 33.9742 46.2091, TEACHER: 0.1980 0.5343
lr at 136th epoch is 5e-05 for optimizer
current performance: -9.4742, best performance: -9.7326
Epoch: 0136 | TRAIN: 1.8178 0.2256 0.5826 | 0.5699 0.5699 0.2728 | 0.2526 36.3513 33.0524 0.1403 0.3313 0.4545 TEST: 1.9475 0.2054 0.5344 | 0.6944 0.6840 0.9549 | 0.2453 35.6201 42.1739 14.7856 34.5169 46.5498, TEACHER: 0.2050 0.5346
lr at 137th epoch is 5e-05 for optimizer
current performance: -14.3191, best performance: -9.4742
Epoch: 0137 | TRAIN: 1.8344 0.2256 0.5827 | 0.5708 0.5708 0.2698 | 0.2482 35.9647 32.5693 0.1435 0.3372 0.4611 TEST: 2.2161 0.1910 0.5239 | 0.7681 0.7567 1.0592 | 0.2442 35.4988 42.0717 15.1679 34.6496 46.7267, TEACHER: 0.1915 0.5242
lr at 138th epoch is 5e-05 for optimizer
current performance: -10.6841, best performance: -9.4742
Epoch: 0138 | TRAIN: 1.8348 0.2245 0.5833 | 0.5777 0.5777 0.2720 | 0.2517 36.3420 33.2181 0.1386 0.3287 0.4516 TEST: 2.2261 0.1988 0.5290 | 0.7033 0.6952 0.9589 | 0.2432 35.5101 41.9880 14.9536 34.3473 46.3585, TEACHER: 0.1980 0.5288
lr at 139th epoch is 5e-05 for optimizer
current performance: -9.5449, best performance: -9.4742
Epoch: 0139 | TRAIN: 1.8666 0.2243 0.5855 | 0.5869 0.5869 0.2718 | 0.2492 36.0420 32.7906 0.1447 0.3367 0.4584 TEST: 2.0388 0.1968 0.5350 | 0.6839 0.6745 0.9422 | 0.2393 35.0619 41.6208 15.7531 35.2291 47.3219, TEACHER: 0.1963 0.5349
lr at 140th epoch is 5e-05 for optimizer
current performance: -11.5537, best performance: -9.4742
Epoch: 0140 | TRAIN: 1.8008 0.2291 0.5891 | 0.5733 0.5733 0.2697 | 0.2491 36.0320 32.8282 0.1445 0.3366 0.4589 TEST: 2.1514 0.1955 0.5335 | 0.7236 0.7129 1.0055 | 0.2401 35.2273 41.6627 15.3377 34.5392 46.6443, TEACHER: 0.1952 0.5334
lr at 141th epoch is 5e-05 for optimizer
current performance: -11.1885, best performance: -9.4742
Epoch: 0141 | TRAIN: 1.8406 0.2296 0.5847 | 0.5653 0.5653 0.2633 | 0.2499 36.1477 32.9619 0.1417 0.3324 0.4561 TEST: 2.1733 0.1962 0.5298 | 0.7094 0.7000 0.9647 | 0.2422 35.4792 41.8321 14.4980 33.9433 46.2217, TEACHER: 0.1964 0.5298
lr at 142th epoch is 5e-05 for optimizer
current performance: -9.0715, best performance: -9.4742
Epoch: 0142 | TRAIN: 1.8648 0.2233 0.5832 | 0.5810 0.5810 0.2739 | 0.2502 36.1210 32.8518 0.1437 0.3352 0.4569 TEST: 2.2076 0.1996 0.5373 | 0.6734 0.6641 0.9187 | 0.2415 35.3634 41.7945 15.1958 34.4627 46.4597, TEACHER: 0.1989 0.5370
lr at 143th epoch is 5e-05 for optimizer
current performance: -12.6580, best performance: -9.0715
Epoch: 0143 | TRAIN: 1.8423 0.2276 0.5883 | 0.5727 0.5727 0.2735 | 0.2516 36.2076 32.9201 0.1445 0.3357 0.4575 TEST: 2.1924 0.1955 0.5298 | 0.7516 0.7399 1.0481 | 0.2418 35.1676 41.8736 16.2758 35.4555 47.2782, TEACHER: 0.1962 0.5301
lr at 144th epoch is 5e-05 for optimizer
current performance: -12.6661, best performance: -9.0715
Epoch: 0144 | TRAIN: 1.8210 0.2246 0.5882 | 0.5685 0.5685 0.2713 | 0.2525 36.2752 33.0230 0.1448 0.3341 0.4563 TEST: 2.2209 0.1917 0.5303 | 0.7447 0.7324 1.0285 | 0.2379 35.0274 41.4554 15.5341 34.9112 47.0566, TEACHER: 0.1917 0.5302
lr at 145th epoch is 5e-05 for optimizer
current performance: -8.9364, best performance: -9.0715
Epoch: 0145 | TRAIN: 1.8848 0.2274 0.5854 | 0.5750 0.5750 0.2657 | 0.2502 36.0828 32.8479 0.1470 0.3368 0.4579 TEST: 2.0196 0.2047 0.5340 | 0.6801 0.6711 0.9323 | 0.2436 35.5576 41.9877 14.6923 34.1140 46.2831, TEACHER: 0.2040 0.5338
lr at 146th epoch is 5e-05 for optimizer
current performance: -8.1822, best performance: -8.9364
Epoch: 0146 | TRAIN: 1.8653 0.2275 0.5881 | 0.5624 0.5624 0.2671 | 0.2493 36.0064 32.7262 0.1468 0.3375 0.4595 TEST: 2.0757 0.2058 0.5357 | 0.6903 0.6785 0.9582 | 0.2361 34.7078 41.3387 16.3057 36.0369 48.0108, TEACHER: 0.2048 0.5354
lr at 147th epoch is 5e-05 for optimizer
current performance: -10.3067, best performance: -8.1822
Epoch: 0147 | TRAIN: 1.8841 0.2255 0.5882 | 0.5737 0.5737 0.2674 | 0.2491 36.0516 32.6804 0.1430 0.3352 0.4587 TEST: 2.0746 0.1972 0.5311 | 0.6982 0.6873 0.9597 | 0.2411 35.2977 41.7581 15.3894 34.5874 46.5425, TEACHER: 0.1964 0.5308
lr at 148th epoch is 5e-05 for optimizer
current performance: -13.1892, best performance: -8.1822
Epoch: 0148 | TRAIN: 1.8482 0.2300 0.5973 | 0.5791 0.5791 0.2671 | 0.2485 35.9212 32.5526 0.1473 0.3395 0.4626 TEST: 2.1786 0.1953 0.5312 | 0.7510 0.7410 1.0331 | 0.2423 35.5838 41.8160 14.2929 33.2941 45.6761, TEACHER: 0.1956 0.5313
lr at 149th epoch is 5e-05 for optimizer
current performance: -11.0965, best performance: -8.1822
Epoch: 0149 | TRAIN: 1.8900 0.2246 0.5896 | 0.5783 0.5783 0.2707 | 0.2483 35.9374 32.6330 0.1460 0.3376 0.4609 TEST: 2.1214 0.1962 0.5330 | 0.7209 0.7096 0.9948 | 0.2383 35.0232 41.5031 15.4918 35.0662 47.2520, TEACHER: 0.1965 0.5331
lr at 150th epoch is 5e-05 for optimizer
current performance: -12.8235, best performance: -8.1822
Epoch: 0150 | TRAIN: 1.8796 0.2284 0.5959 | 0.5715 0.5715 0.2731 | 0.2483 35.8445 32.4549 0.1511 0.3429 0.4649 TEST: 2.2778 0.1894 0.5202 | 0.7318 0.7221 0.9906 | 0.2414 35.3073 41.7928 15.2146 34.5058 46.7289, TEACHER: 0.1899 0.5202
lr at 151th epoch is 5e-05 for optimizer
current performance: -11.5633, best performance: -8.1822
Epoch: 0151 | TRAIN: 1.8818 0.2293 0.5933 | 0.5696 0.5696 0.2664 | 0.2494 36.0219 32.7853 0.1459 0.3372 0.4599 TEST: 2.2853 0.1931 0.5321 | 0.7225 0.7115 1.0077 | 0.2390 35.0169 41.5982 15.7369 35.4658 47.4980, TEACHER: 0.1935 0.5322
lr at 152th epoch is 5e-05 for optimizer
current performance: -9.6624, best performance: -8.1822
Epoch: 0152 | TRAIN: 1.9182 0.2244 0.5923 | 0.5741 0.5741 0.2729 | 0.2485 35.8503 32.3390 0.1486 0.3445 0.4674 TEST: 2.1893 0.1998 0.5346 | 0.6950 0.6855 0.9518 | 0.2406 35.0852 41.7852 16.1373 35.7154 47.4962, TEACHER: 0.2008 0.5349
lr at 153th epoch is 5e-05 for optimizer
current performance: -9.6819, best performance: -8.1822
Epoch: 0153 | TRAIN: 1.9201 0.2280 0.5947 | 0.5847 0.5847 0.2713 | 0.2501 36.0716 32.7701 0.1454 0.3380 0.4602 TEST: 2.2637 0.1987 0.5347 | 0.6953 0.6851 0.9573 | 0.2386 34.9867 41.5361 15.8605 35.3450 47.3854, TEACHER: 0.1987 0.5348
lr at 154th epoch is 5e-05 for optimizer
current performance: -9.3305, best performance: -8.1822
Epoch: 0154 | TRAIN: 1.9187 0.2277 0.5980 | 0.5633 0.5633 0.2674 | 0.2492 36.0262 32.6861 0.1454 0.3372 0.4596 TEST: 2.1689 0.2057 0.5341 | 0.6920 0.6843 0.9317 | 0.2456 35.5054 42.2293 15.8831 34.9349 46.7312, TEACHER: 0.2053 0.5342
lr at 155th epoch is 5e-05 for optimizer
current performance: -10.7449, best performance: -8.1822
Epoch: 0155 | TRAIN: 1.9054 0.2237 0.5946 | 0.5798 0.5798 0.2745 | 0.2490 35.9495 32.5402 0.1470 0.3407 0.4627 TEST: 2.3805 0.2019 0.5342 | 0.7286 0.7193 1.0027 | 0.2382 34.9782 41.5397 15.7556 35.2795 47.4097, TEACHER: 0.2016 0.5343
lr at 156th epoch is 5e-05 for optimizer
current performance: -8.5634, best performance: -8.1822
Epoch: 0156 | TRAIN: 1.9115 0.2314 0.5997 | 0.5689 0.5689 0.2593 | 0.2467 35.7549 32.4386 0.1502 0.3427 0.4644 TEST: 2.2668 0.2032 0.5278 | 0.6901 0.6789 0.9574 | 0.2360 34.7344 41.3505 16.2393 35.8976 47.9609, TEACHER: 0.2036 0.5282
lr at 157th epoch is 5e-05 for optimizer
current performance: -11.4766, best performance: -8.1822
Epoch: 0157 | TRAIN: 1.9162 0.2349 0.6031 | 0.5710 0.5710 0.2691 | 0.2454 35.6473 32.1975 0.1477 0.3454 0.4689 TEST: 2.3593 0.1973 0.5216 | 0.7333 0.7230 1.0192 | 0.2393 34.9739 41.6509 16.2629 35.7768 47.6398, TEACHER: 0.1979 0.5219
lr at 158th epoch is 5e-05 for optimizer
current performance: -10.5874, best performance: -8.1822
Epoch: 0158 | TRAIN: 1.9222 0.2335 0.5976 | 0.5622 0.5622 0.2663 | 0.2497 35.9734 32.6169 0.1498 0.3415 0.4624 TEST: 2.1637 0.2027 0.5329 | 0.7301 0.7178 1.0144 | 0.2380 34.9864 41.4714 15.7371 35.1449 47.1592, TEACHER: 0.2023 0.5332
lr at 159th epoch is 5e-05 for optimizer
current performance: -9.2420, best performance: -8.1822
Epoch: 0159 | TRAIN: 1.9295 0.2319 0.6001 | 0.5632 0.5632 0.2641 | 0.2478 35.8445 32.3841 0.1476 0.3418 0.4651 TEST: 2.4428 0.1990 0.5328 | 0.6884 0.6780 0.9467 | 0.2377 34.8981 41.4754 15.8716 35.6361 47.7244, TEACHER: 0.1991 0.5329
lr at 160th epoch is 5e-05 for optimizer
current performance: -8.9690, best performance: -8.1822
Epoch: 0160 | TRAIN: 1.9344 0.2356 0.6013 | 0.5573 0.5573 0.2624 | 0.2504 36.0064 32.4618 0.1493 0.3432 0.4645 TEST: 2.2391 0.2037 0.5399 | 0.6960 0.6853 0.9739 | 0.2385 34.9175 41.5675 16.0305 35.7838 47.7954, TEACHER: 0.2041 0.5402
lr at 161th epoch is 5e-05 for optimizer
current performance: -7.2612, best performance: -8.1822
Epoch: 0161 | TRAIN: 1.9060 0.2348 0.6099 | 0.5718 0.5718 0.2608 | 0.2469 35.7687 32.2961 0.1479 0.3441 0.4668 TEST: 2.3721 0.2113 0.5331 | 0.6738 0.6640 0.9230 | 0.2385 35.0773 41.5195 15.1555 34.8316 47.0969, TEACHER: 0.2108 0.5330
lr at 162th epoch is 5e-05 for optimizer
current performance: -8.3386, best performance: -7.2612
Epoch: 0162 | TRAIN: 1.9415 0.2354 0.6050 | 0.5597 0.5597 0.2619 | 0.2471 35.7738 32.2833 0.1491 0.3427 0.4660 TEST: 2.3312 0.2008 0.5350 | 0.6771 0.6668 0.9355 | 0.2352 34.7356 41.2060 16.0453 35.4629 47.5679, TEACHER: 0.2002 0.5348
lr at 163th epoch is 5e-05 for optimizer
current performance: -9.3104, best performance: -7.2612
Epoch: 0163 | TRAIN: 1.9505 0.2327 0.6008 | 0.5601 0.5601 0.2632 | 0.2470 35.7037 32.1888 0.1530 0.3458 0.4679 TEST: 2.2291 0.2151 0.5345 | 0.7344 0.7225 1.0144 | 0.2393 35.0869 41.6167 15.2611 35.2171 47.3797, TEACHER: 0.2148 0.5342
lr at 164th epoch is 5e-05 for optimizer
current performance: -12.1344, best performance: -7.2612
Epoch: 0164 | TRAIN: 1.9665 0.2340 0.6039 | 0.5662 0.5662 0.2640 | 0.2484 35.9366 32.5988 0.1449 0.3401 0.4624 TEST: 2.2694 0.1987 0.5296 | 0.7537 0.7429 1.0438 | 0.2391 34.9521 41.6470 16.0158 35.8705 47.9304, TEACHER: 0.1984 0.5301
lr at 165th epoch is 5e-05 for optimizer
current performance: -7.6672, best performance: -7.2612
Epoch: 0165 | TRAIN: 1.9491 0.2277 0.6021 | 0.5715 0.5715 0.2697 | 0.2514 36.1209 32.6268 0.1464 0.3394 0.4620 TEST: 2.3518 0.2073 0.5308 | 0.6742 0.6640 0.9293 | 0.2382 34.9794 41.5411 15.6108 35.6670 47.6430, TEACHER: 0.2070 0.5308
lr at 166th epoch is 5e-05 for optimizer
current performance: -8.9797, best performance: -7.2612
Epoch: 0166 | TRAIN: 1.9347 0.2357 0.6108 | 0.5609 0.5609 0.2650 | 0.2465 35.6933 32.2980 0.1526 0.3453 0.4664 TEST: 2.4549 0.2018 0.5342 | 0.6964 0.6852 0.9671 | 0.2366 34.7117 41.4132 16.5633 36.1845 48.1425, TEACHER: 0.2017 0.5343
lr at 167th epoch is 5e-05 for optimizer
current performance: -8.3325, best performance: -7.2612
Epoch: 0167 | TRAIN: 1.9854 0.2352 0.6097 | 0.5625 0.5625 0.2627 | 0.2475 35.7851 32.3558 0.1507 0.3426 0.4656 TEST: 2.4046 0.1993 0.5368 | 0.6772 0.6654 0.9411 | 0.2343 34.6046 41.1477 16.2728 36.0266 48.0273, TEACHER: 0.1987 0.5365
lr at 168th epoch is 5e-05 for optimizer
current performance: -7.5532, best performance: -7.2612
Epoch: 0168 | TRAIN: 1.9914 0.2348 0.6064 | 0.5523 0.5523 0.2536 | 0.2467 35.6981 32.2323 0.1509 0.3456 0.4683 TEST: 2.4654 0.2110 0.5336 | 0.6816 0.6716 0.9439 | 0.2386 35.0120 41.5583 15.6987 35.3521 47.4177, TEACHER: 0.2109 0.5338
lr at 169th epoch is 5e-05 for optimizer
current performance: -8.7708, best performance: -7.2612
Epoch: 0169 | TRAIN: 1.9835 0.2366 0.6112 | 0.5606 0.5606 0.2615 | 0.2475 35.8058 32.4499 0.1501 0.3425 0.4646 TEST: 2.2174 0.2066 0.5360 | 0.7053 0.6941 0.9668 | 0.2367 34.7213 41.4367 16.4075 36.2670 48.2307, TEACHER: 0.2068 0.5362
lr at 170th epoch is 5e-05 for optimizer
current performance: -10.7928, best performance: -7.2612
Epoch: 0170 | TRAIN: 2.0373 0.2391 0.6062 | 0.5595 0.5595 0.2645 | 0.2481 35.7766 32.2349 0.1527 0.3465 0.4683 TEST: 2.6014 0.2028 0.5321 | 0.7294 0.7175 1.0145 | 0.2411 35.1955 41.8108 15.4542 35.2507 47.3019, TEACHER: 0.2023 0.5319
lr at 171th epoch is 5e-05 for optimizer
current performance: -9.2287, best performance: -7.2612
Epoch: 0171 | TRAIN: 1.9522 0.2390 0.6138 | 0.5710 0.5710 0.2686 | 0.2496 35.9369 32.4758 0.1502 0.3431 0.4648 TEST: 2.5623 0.1967 0.5299 | 0.6816 0.6724 0.9285 | 0.2372 34.8457 41.4416 16.2440 35.7219 47.6336, TEACHER: 0.1970 0.5300
lr at 172th epoch is 5e-05 for optimizer
current performance: -9.6822, best performance: -7.2612
Epoch: 0172 | TRAIN: 2.0000 0.2424 0.6158 | 0.5581 0.5581 0.2601 | 0.2485 35.8836 32.5525 0.1485 0.3428 0.4649 TEST: 2.4840 0.2003 0.5353 | 0.6985 0.6894 0.9685 | 0.2376 35.0037 41.4344 15.4344 34.8944 47.1782, TEACHER: 0.2003 0.5352
lr at 173th epoch is 5e-05 for optimizer
current performance: -8.1248, best performance: -7.2612
Epoch: 0173 | TRAIN: 2.0226 0.2408 0.6071 | 0.5559 0.5559 0.2590 | 0.2474 35.8229 32.4863 0.1482 0.3418 0.4642 TEST: 2.6756 0.1994 0.5273 | 0.6698 0.6602 0.9206 | 0.2349 34.6351 41.2268 16.2001 35.9353 48.1116, TEACHER: 0.1993 0.5273
lr at 174th epoch is 5e-05 for optimizer
current performance: -8.7990, best performance: -7.2612
Epoch: 0174 | TRAIN: 2.0771 0.2364 0.6115 | 0.5630 0.5630 0.2613 | 0.2463 35.7480 32.4585 0.1485 0.3415 0.4639 TEST: 2.3007 0.2086 0.5306 | 0.7161 0.7049 0.9975 | 0.2343 34.5594 41.1661 16.4531 36.2016 48.2605, TEACHER: 0.2082 0.5309
lr at 175th epoch is 5e-05 for optimizer
current performance: -7.9497, best performance: -7.2612
Epoch: 0175 | TRAIN: 2.0014 0.2408 0.6153 | 0.5655 0.5655 0.2645 | 0.2439 35.3937 31.8374 0.1568 0.3523 0.4744 TEST: 2.5900 0.1969 0.5311 | 0.6626 0.6532 0.9045 | 0.2335 34.4673 41.0649 16.7722 36.4102 48.3157, TEACHER: 0.1975 0.5312
lr at 176th epoch is 5e-05 for optimizer
current performance: -7.6776, best performance: -7.2612
Epoch: 0176 | TRAIN: 2.0246 0.2421 0.6127 | 0.5640 0.5640 0.2629 | 0.2473 35.7190 32.2450 0.1521 0.3476 0.4692 TEST: 2.5968 0.2060 0.5359 | 0.6817 0.6718 0.9374 | 0.2345 34.5410 41.1826 16.6386 36.2946 48.2992, TEACHER: 0.2062 0.5360
lr at 177th epoch is 5e-05 for optimizer
current performance: -5.9261, best performance: -7.2612
Epoch: 0177 | TRAIN: 2.0559 0.2360 0.6102 | 0.5539 0.5539 0.2595 | 0.2458 35.6582 32.1041 0.1483 0.3453 0.4695 TEST: 2.4261 0.2141 0.5362 | 0.6569 0.6458 0.9151 | 0.2373 34.9027 41.4209 15.6212 35.5384 47.6405, TEACHER: 0.2137 0.5363
lr at 178th epoch is 5e-05 for optimizer
current performance: -9.9830, best performance: -5.9261
Epoch: 0178 | TRAIN: 2.0145 0.2412 0.6152 | 0.5605 0.5605 0.2612 | 0.2467 35.6872 32.2063 0.1514 0.3470 0.4691 TEST: 2.4050 0.2007 0.5261 | 0.7186 0.7064 0.9985 | 0.2347 34.6556 41.2137 16.0675 35.8812 48.0329, TEACHER: 0.2009 0.5262
lr at 179th epoch is 5e-05 for optimizer
current performance: -10.5578, best performance: -5.9261
Epoch: 0179 | TRAIN: 2.0237 0.2408 0.6139 | 0.5533 0.5533 0.2601 | 0.2473 35.8262 32.4003 0.1458 0.3422 0.4656 TEST: 2.7971 0.1927 0.5306 | 0.7057 0.6951 0.9776 | 0.2363 34.6991 41.3815 16.4465 36.1816 48.1494, TEACHER: 0.1927 0.5305
lr at 180th epoch is 5e-05 for optimizer
current performance: -8.5211, best performance: -5.9261
Epoch: 0180 | TRAIN: 2.0316 0.2473 0.6216 | 0.5573 0.5573 0.2576 | 0.2444 35.5650 32.0955 0.1488 0.3454 0.4695 TEST: 2.4475 0.2143 0.5424 | 0.7251 0.7139 1.0055 | 0.2348 34.6221 41.2292 16.0270 36.1331 48.3340, TEACHER: 0.2142 0.5425
lr at 181th epoch is 5e-05 for optimizer
current performance: -9.7295, best performance: -5.9261
Epoch: 0181 | TRAIN: 2.0119 0.2435 0.6197 | 0.5606 0.5606 0.2630 | 0.2466 35.7386 32.2342 0.1477 0.3432 0.4669 TEST: 2.4974 0.2030 0.5313 | 0.7106 0.6994 0.9783 | 0.2378 34.9710 41.4899 15.4967 35.2774 47.4760, TEACHER: 0.2028 0.5314
lr at 182th epoch is 5e-05 for optimizer
current performance: -7.0129, best performance: -5.9261
Epoch: 0182 | TRAIN: 2.0211 0.2411 0.6187 | 0.5605 0.5605 0.2618 | 0.2462 35.6977 32.2393 0.1484 0.3442 0.4683 TEST: 2.1792 0.2146 0.5356 | 0.6782 0.6679 0.9342 | 0.2395 35.0776 41.6640 15.8934 35.1116 47.0847, TEACHER: 0.2139 0.5357
lr at 183th epoch is 5e-05 for optimizer
current performance: -9.5747, best performance: -5.9261
Epoch: 0183 | TRAIN: 2.0823 0.2455 0.6204 | 0.5707 0.5707 0.2682 | 0.2432 35.3957 31.8225 0.1528 0.3502 0.4741 TEST: 2.4799 0.2025 0.5303 | 0.7060 0.6957 0.9765 | 0.2379 34.9123 41.5164 15.7371 35.6620 47.8306, TEACHER: 0.2022 0.5303
lr at 184th epoch is 5e-05 for optimizer
current performance: -8.2132, best performance: -5.9261
Epoch: 0184 | TRAIN: 2.0873 0.2435 0.6208 | 0.5574 0.5574 0.2543 | 0.2457 35.6180 32.0888 0.1506 0.3466 0.4706 TEST: 2.3464 0.1998 0.5422 | 0.6762 0.6663 0.9364 | 0.2327 34.5205 41.0036 16.0358 35.8164 48.1051, TEACHER: 0.2003 0.5426
lr at 185th epoch is 5e-05 for optimizer
current performance: -9.4552, best performance: -5.9261
Epoch: 0185 | TRAIN: 2.0533 0.2461 0.6203 | 0.5631 0.5631 0.2656 | 0.2413 35.2876 31.8405 0.1506 0.3491 0.4742 TEST: 2.6702 0.2034 0.5334 | 0.6961 0.6875 0.9565 | 0.2413 35.2307 41.8140 15.4794 35.2080 47.2419, TEACHER: 0.2031 0.5333
lr at 186th epoch is 5e-05 for optimizer
current performance: -7.9385, best performance: -5.9261
Epoch: 0186 | TRAIN: 2.0192 0.2473 0.6197 | 0.5646 0.5646 0.2615 | 0.2447 35.4713 31.8890 0.1553 0.3510 0.4735 TEST: 2.4968 0.2070 0.5404 | 0.6933 0.6830 0.9631 | 0.2344 34.4528 41.2246 16.9874 36.8136 48.7153, TEACHER: 0.2072 0.5405
lr at 187th epoch is 5e-05 for optimizer
current performance: -10.4664, best performance: -5.9261
Epoch: 0187 | TRAIN: 2.0829 0.2515 0.6229 | 0.5586 0.5586 0.2558 | 0.2444 35.5136 32.0630 0.1509 0.3482 0.4716 TEST: 2.7944 0.2024 0.5354 | 0.7371 0.7257 1.0178 | 0.2340 34.5360 41.1375 16.4229 36.1616 48.2536, TEACHER: 0.2022 0.5354
lr at 188th epoch is 5e-05 for optimizer
current performance: -9.7340, best performance: -5.9261
Epoch: 0188 | TRAIN: 2.0992 0.2411 0.6169 | 0.5505 0.5505 0.2582 | 0.2431 35.3997 31.8372 0.1509 0.3512 0.4746 TEST: 2.6864 0.1998 0.5350 | 0.7097 0.6986 0.9868 | 0.2358 34.6362 41.3437 16.5662 36.3255 48.2895, TEACHER: 0.1997 0.5349
lr at 189th epoch is 5e-05 for optimizer
current performance: -8.3474, best performance: -5.9261
Epoch: 0189 | TRAIN: 2.1061 0.2468 0.6197 | 0.5469 0.5469 0.2523 | 0.2437 35.4411 31.8870 0.1528 0.3493 0.4725 TEST: 2.2653 0.2183 0.5321 | 0.7266 0.7147 1.0019 | 0.2374 34.8839 41.4452 15.8000 35.5185 47.6404, TEACHER: 0.2178 0.5320
lr at 190th epoch is 5e-05 for optimizer
current performance: -8.3821, best performance: -5.9261
Epoch: 0190 | TRAIN: 2.1355 0.2492 0.6229 | 0.5528 0.5528 0.2567 | 0.2454 35.5908 32.0742 0.1516 0.3473 0.4700 TEST: 2.6170 0.2065 0.5228 | 0.6920 0.6814 0.9479 | 0.2362 34.8652 41.3130 15.4867 35.3476 47.4900, TEACHER: 0.2057 0.5235
lr at 191th epoch is 5e-05 for optimizer
current performance: -10.7603, best performance: -5.9261
Epoch: 0191 | TRAIN: 2.1261 0.2437 0.6170 | 0.5556 0.5556 0.2651 | 0.2450 35.5660 32.0999 0.1514 0.3471 0.4702 TEST: 2.7225 0.2001 0.5321 | 0.7397 0.7299 1.0168 | 0.2331 34.3791 41.0784 16.8060 36.6704 48.7398, TEACHER: 0.2004 0.5322
lr at 192th epoch is 5e-05 for optimizer
current performance: -11.3011, best performance: -5.9261
Epoch: 0192 | TRAIN: 2.0862 0.2476 0.6190 | 0.5546 0.5546 0.2624 | 0.2468 35.7220 32.2602 0.1502 0.3460 0.4681 TEST: 2.7125 0.1917 0.5197 | 0.7228 0.7111 1.0121 | 0.2360 34.6361 41.3388 16.6036 36.3934 48.3663, TEACHER: 0.1923 0.5198
lr at 193th epoch is 5e-05 for optimizer
current performance: -6.9493, best performance: -5.9261
Epoch: 0193 | TRAIN: 2.1283 0.2468 0.6242 | 0.5457 0.5457 0.2536 | 0.2413 35.2524 31.6599 0.1518 0.3517 0.4762 TEST: 2.5099 0.2052 0.5395 | 0.6589 0.6502 0.8962 | 0.2356 34.6344 41.3334 16.5598 36.3403 48.3051, TEACHER: 0.2049 0.5395
lr at 194th epoch is 5e-05 for optimizer
current performance: -7.8973, best performance: -5.9261
Epoch: 0194 | TRAIN: 2.1371 0.2460 0.6175 | 0.5522 0.5522 0.2589 | 0.2420 35.3036 31.8195 0.1537 0.3506 0.4744 TEST: 2.7497 0.2019 0.5260 | 0.6805 0.6712 0.9212 | 0.2317 34.2872 40.9506 16.7298 36.9413 48.8918, TEACHER: 0.2019 0.5262
lr at 195th epoch is 5e-05 for optimizer
current performance: -8.7473, best performance: -5.9261
Epoch: 0195 | TRAIN: 2.1352 0.2489 0.6256 | 0.5619 0.5619 0.2576 | 0.2436 35.4341 31.8787 0.1517 0.3505 0.4736 TEST: 2.5920 0.2053 0.5340 | 0.7026 0.6932 0.9657 | 0.2348 34.5834 41.2365 16.3803 36.3347 48.3637, TEACHER: 0.2054 0.5341
lr at 196th epoch is 5e-05 for optimizer
current performance: -7.4613, best performance: -5.9261
Epoch: 0196 | TRAIN: 2.1361 0.2547 0.6251 | 0.5610 0.5610 0.2629 | 0.2435 35.4500 31.9226 0.1503 0.3489 0.4730 TEST: 2.5271 0.1999 0.5325 | 0.6596 0.6501 0.9005 | 0.2333 34.4860 41.0839 16.3063 36.4649 48.4714, TEACHER: 0.1999 0.5325
lr at 197th epoch is 5e-05 for optimizer
current performance: -9.9967, best performance: -5.9261
Epoch: 0197 | TRAIN: 2.1464 0.2513 0.6224 | 0.5658 0.5658 0.2624 | 0.2436 35.3983 31.7725 0.1529 0.3522 0.4760 TEST: 2.7166 0.1919 0.5221 | 0.6879 0.6774 0.9533 | 0.2346 34.7899 41.1562 15.2003 34.9752 47.4682, TEACHER: 0.1922 0.5222
lr at 198th epoch is 5e-05 for optimizer
current performance: -8.4268, best performance: -5.9261
Epoch: 0198 | TRAIN: 2.0973 0.2536 0.6297 | 0.5572 0.5572 0.2588 | 0.2402 35.1446 31.6099 0.1550 0.3530 0.4766 TEST: 2.7440 0.2018 0.5344 | 0.6850 0.6755 0.9424 | 0.2342 34.5880 41.1586 16.1059 35.9911 48.1771, TEACHER: 0.2020 0.5345
lr at 199th epoch is 5e-05 for optimizer
current performance: -9.4720, best performance: -5.9261
Epoch: 0199 | TRAIN: 2.0897 0.2454 0.6214 | 0.5597 0.5597 0.2615 | 0.2447 35.5390 32.0140 0.1499 0.3491 0.4716 TEST: 2.5527 0.2004 0.5245 | 0.7097 0.6989 0.9623 | 0.2327 34.4616 41.0079 16.4834 36.2162 48.1947, TEACHER: 0.2005 0.5245
lr at 200th epoch is 2.5e-05 for optimizer
current performance: -6.3907, best performance: -5.9261
Epoch: 0200 | TRAIN: 2.1851 0.2608 0.6288 | 0.5398 0.5398 0.2482 | 0.2374 34.8638 31.2625 0.1582 0.3589 0.4829 TEST: 2.5746 0.2136 0.5421 | 0.6871 0.6764 0.9507 | 0.2295 34.0775 40.7298 16.9661 37.1303 49.2498, TEACHER: 0.2136 0.5421
lr at 201th epoch is 2.5e-05 for optimizer
current performance: -8.8601, best performance: -5.9261
Epoch: 0201 | TRAIN: 2.1731 0.2584 0.6364 | 0.5472 0.5472 0.2520 | 0.2367 34.7990 31.1791 0.1582 0.3595 0.4849 TEST: 2.6006 0.2005 0.5360 | 0.7052 0.6936 0.9743 | 0.2299 34.1192 40.7843 16.8500 37.1395 49.2410, TEACHER: 0.2005 0.5360
lr at 202th epoch is 2.5e-05 for optimizer
current performance: -8.2676, best performance: -5.9261
Epoch: 0202 | TRAIN: 2.2396 0.2562 0.6325 | 0.5307 0.5307 0.2471 | 0.2389 35.0245 31.4207 0.1552 0.3558 0.4800 TEST: 2.8089 0.2041 0.5330 | 0.6960 0.6857 0.9632 | 0.2317 34.3067 40.9592 16.5752 36.6516 48.8421, TEACHER: 0.2046 0.5334
lr at 203th epoch is 2.5e-05 for optimizer
current performance: -7.6583, best performance: -5.9261
Epoch: 0203 | TRAIN: 2.2250 0.2571 0.6342 | 0.5429 0.5429 0.2544 | 0.2396 35.0221 31.3341 0.1577 0.3583 0.4820 TEST: 2.7940 0.1965 0.5298 | 0.6668 0.6567 0.9217 | 0.2279 34.0117 40.5626 16.7890 36.8931 49.1426, TEACHER: 0.1964 0.5298
lr at 204th epoch is 2.5e-05 for optimizer
current performance: -6.0058, best performance: -5.9261
Epoch: 0204 | TRAIN: 2.2064 0.2687 0.6412 | 0.5349 0.5349 0.2496 | 0.2379 34.8326 31.0182 0.1608 0.3621 0.4863 TEST: 2.8255 0.2111 0.5387 | 0.6652 0.6563 0.9056 | 0.2317 34.2222 40.9572 17.2298 37.1012 49.0220, TEACHER: 0.2110 0.5387
lr at 205th epoch is 2.5e-05 for optimizer
current performance: -7.3251, best performance: -5.9261
Epoch: 0205 | TRAIN: 2.2341 0.2644 0.6355 | 0.5440 0.5440 0.2452 | 0.2388 34.9690 31.3443 0.1581 0.3575 0.4819 TEST: 2.8461 0.2074 0.5353 | 0.6892 0.6781 0.9554 | 0.2296 34.1338 40.7253 16.8418 36.8302 48.9388, TEACHER: 0.2073 0.5353
lr at 206th epoch is 2.5e-05 for optimizer
current performance: -6.2208, best performance: -5.9261
Epoch: 0206 | TRAIN: 2.2412 0.2618 0.6384 | 0.5334 0.5334 0.2443 | 0.2388 34.9841 31.3504 0.1575 0.3569 0.4809 TEST: 2.5850 0.2118 0.5400 | 0.6778 0.6674 0.9404 | 0.2287 34.0695 40.6465 16.8104 36.9095 49.0631, TEACHER: 0.2117 0.5399
lr at 207th epoch is 2.5e-05 for optimizer
current performance: -6.8582, best performance: -5.9261
Epoch: 0207 | TRAIN: 2.2316 0.2647 0.6439 | 0.5395 0.5395 0.2484 | 0.2385 34.9124 31.1572 0.1590 0.3596 0.4839 TEST: 2.5151 0.2097 0.5360 | 0.6818 0.6710 0.9467 | 0.2298 34.2559 40.7298 16.0094 36.4721 48.7699, TEACHER: 0.2096 0.5359
lr at 208th epoch is 2.5e-05 for optimizer
current performance: -8.5071, best performance: -5.9261
Epoch: 0208 | TRAIN: 2.2693 0.2555 0.6332 | 0.5301 0.5301 0.2484 | 0.2396 35.0178 31.2922 0.1570 0.3580 0.4823 TEST: 2.7304 0.1974 0.5321 | 0.6890 0.6779 0.9513 | 0.2283 34.0604 40.6037 16.4255 36.8275 49.1965, TEACHER: 0.1978 0.5323
lr at 209th epoch is 2.5e-05 for optimizer
current performance: -8.1768, best performance: -5.9261
Epoch: 0209 | TRAIN: 2.2410 0.2617 0.6356 | 0.5454 0.5454 0.2497 | 0.2365 34.7717 31.0462 0.1574 0.3611 0.4863 TEST: 2.8458 0.2046 0.5373 | 0.7014 0.6909 0.9731 | 0.2292 34.0826 40.6982 16.6527 37.0877 49.3215, TEACHER: 0.2049 0.5375
lr at 210th epoch is 2.5e-05 for optimizer
current performance: -6.8341, best performance: -5.9261
Epoch: 0210 | TRAIN: 2.2248 0.2621 0.6377 | 0.5362 0.5362 0.2506 | 0.2399 35.0560 31.4184 0.1574 0.3573 0.4808 TEST: 2.8704 0.2018 0.5360 | 0.6656 0.6552 0.9201 | 0.2272 33.9414 40.5009 16.8340 37.0569 49.3295, TEACHER: 0.2020 0.5361
lr at 211th epoch is 2.5e-05 for optimizer
current performance: -6.4372, best performance: -5.9261
Epoch: 0211 | TRAIN: 2.2495 0.2613 0.6397 | 0.5344 0.5344 0.2475 | 0.2385 34.9700 31.3738 0.1559 0.3573 0.4816 TEST: 2.7560 0.2101 0.5409 | 0.6760 0.6660 0.9369 | 0.2296 34.1118 40.7318 16.7586 37.0384 49.2269, TEACHER: 0.2099 0.5408
lr at 212th epoch is 2.5e-05 for optimizer
current performance: -6.1594, best performance: -5.9261
Epoch: 0212 | TRAIN: 2.2454 0.2571 0.6329 | 0.5282 0.5282 0.2458 | 0.2421 35.2478 31.5168 0.1540 0.3552 0.4794 TEST: 2.5001 0.2190 0.5401 | 0.7019 0.6905 0.9707 | 0.2292 33.9452 40.7462 17.3177 37.7831 49.8687, TEACHER: 0.2188 0.5401
lr at 213th epoch is 2.5e-05 for optimizer
current performance: -7.8781, best performance: -5.9261
Epoch: 0213 | TRAIN: 2.2208 0.2704 0.6427 | 0.5210 0.5210 0.2390 | 0.2344 34.5159 30.6297 0.1631 0.3679 0.4928 TEST: 2.9023 0.1929 0.5281 | 0.6682 0.6576 0.9308 | 0.2255 33.7702 40.3415 17.0816 37.4492 49.6631, TEACHER: 0.1932 0.5282
lr at 214th epoch is 2.5e-05 for optimizer
current performance: -7.0770, best performance: -5.9261
Epoch: 0214 | TRAIN: 2.2701 0.2642 0.6388 | 0.5260 0.5260 0.2471 | 0.2372 34.8208 31.2148 0.1596 0.3599 0.4836 TEST: 3.0590 0.1992 0.5323 | 0.6589 0.6484 0.9130 | 0.2303 34.1327 40.8301 16.9676 37.1543 49.3123, TEACHER: 0.1988 0.5322
lr at 215th epoch is 2.5e-05 for optimizer
current performance: -7.5908, best performance: -5.9261
Epoch: 0215 | TRAIN: 2.2975 0.2640 0.6386 | 0.5336 0.5336 0.2475 | 0.2374 34.8502 31.0898 0.1568 0.3610 0.4857 TEST: 2.6586 0.2061 0.5343 | 0.6905 0.6803 0.9544 | 0.2299 34.1362 40.7873 16.9086 36.9827 49.0928, TEACHER: 0.2057 0.5342
lr at 216th epoch is 2.5e-05 for optimizer
current performance: -8.9390, best performance: -5.9261
Epoch: 0216 | TRAIN: 2.3400 0.2601 0.6394 | 0.5235 0.5235 0.2421 | 0.2386 34.9078 31.1573 0.1587 0.3612 0.4852 TEST: 2.7519 0.2054 0.5360 | 0.7164 0.7065 0.9713 | 0.2307 34.2556 40.8484 16.2337 36.7713 49.0601, TEACHER: 0.2035 0.5360
lr at 217th epoch is 2.5e-05 for optimizer
current performance: -7.7419, best performance: -5.9261
Epoch: 0217 | TRAIN: 2.2693 0.2679 0.6469 | 0.5215 0.5215 0.2414 | 0.2381 34.9328 31.2303 0.1556 0.3580 0.4831 TEST: 2.8307 0.2000 0.5351 | 0.6826 0.6706 0.9491 | 0.2269 33.9507 40.4522 16.5221 37.0004 49.3273, TEACHER: 0.1999 0.5351
lr at 218th epoch is 2.5e-05 for optimizer
current performance: -6.7060, best performance: -5.9261
Epoch: 0218 | TRAIN: 2.3319 0.2628 0.6374 | 0.5278 0.5278 0.2450 | 0.2400 35.0453 31.3874 0.1581 0.3575 0.4821 TEST: 2.7720 0.2034 0.5358 | 0.6703 0.6603 0.9275 | 0.2271 33.8138 40.5141 17.3191 37.7082 49.8522, TEACHER: 0.2039 0.5359
lr at 219th epoch is 2.5e-05 for optimizer
current performance: -6.6625, best performance: -5.9261
Epoch: 0219 | TRAIN: 2.2998 0.2603 0.6389 | 0.5244 0.5244 0.2449 | 0.2387 34.9431 31.2023 0.1569 0.3605 0.4844 TEST: 2.8129 0.2108 0.5392 | 0.6841 0.6740 0.9498 | 0.2295 34.0943 40.7123 16.8203 37.0116 49.1884, TEACHER: 0.2103 0.5392
lr at 220th epoch is 2.5e-05 for optimizer
current performance: -7.0982, best performance: -5.9261
Epoch: 0220 | TRAIN: 2.3076 0.2687 0.6396 | 0.5352 0.5352 0.2426 | 0.2373 34.8228 31.1099 0.1597 0.3612 0.4848 TEST: 2.7055 0.2150 0.5426 | 0.7040 0.6931 0.9729 | 0.2314 34.2221 40.9432 16.9618 37.0966 49.1283, TEACHER: 0.2147 0.5425
lr at 221th epoch is 2.5e-05 for optimizer
current performance: -9.0594, best performance: -5.9261
Epoch: 0221 | TRAIN: 2.2857 0.2671 0.6429 | 0.5236 0.5236 0.2427 | 0.2381 34.8908 31.1298 0.1577 0.3597 0.4849 TEST: 2.9010 0.1968 0.5329 | 0.7020 0.6910 0.9690 | 0.2274 33.9780 40.5048 16.6713 36.8583 49.1839, TEACHER: 0.1971 0.5330
lr at 222th epoch is 2.5e-05 for optimizer
current performance: -5.8122, best performance: -5.9261
Epoch: 0222 | TRAIN: 2.3627 0.2630 0.6390 | 0.5374 0.5374 0.2473 | 0.2372 34.7346 30.9050 0.1615 0.3658 0.4901 TEST: 2.5587 0.2174 0.5370 | 0.6832 0.6725 0.9388 | 0.2306 34.1446 40.8567 16.8025 37.1840 49.3803, TEACHER: 0.2175 0.5371
lr at 223th epoch is 2.5e-05 for optimizer
current performance: -7.5310, best performance: -5.8122
Epoch: 0223 | TRAIN: 2.3072 0.2698 0.6423 | 0.5258 0.5258 0.2471 | 0.2395 35.0157 31.2743 0.1561 0.3583 0.4830 TEST: 2.9160 0.2063 0.5419 | 0.6906 0.6802 0.9566 | 0.2299 34.1110 40.7754 16.8687 37.1206 49.2919, TEACHER: 0.2062 0.5418
lr at 224th epoch is 2.5e-05 for optimizer
current performance: -8.3370, best performance: -5.8122
Epoch: 0224 | TRAIN: 2.3059 0.2619 0.6406 | 0.5273 0.5273 0.2436 | 0.2384 34.8992 31.1039 0.1579 0.3613 0.4860 TEST: 3.2106 0.1974 0.5296 | 0.6882 0.6782 0.9504 | 0.2270 33.8976 40.4914 16.7651 37.2925 49.6620, TEACHER: 0.1976 0.5296
lr at 225th epoch is 2.5e-05 for optimizer
current performance: -7.6848, best performance: -5.8122
Epoch: 0225 | TRAIN: 2.3268 0.2665 0.6413 | 0.5265 0.5265 0.2432 | 0.2379 34.8664 31.1011 0.1591 0.3603 0.4850 TEST: 2.4974 0.2154 0.5421 | 0.7227 0.7113 0.9971 | 0.2292 34.0846 40.6929 16.7367 37.0139 49.2159, TEACHER: 0.2153 0.5420
lr at 226th epoch is 2.5e-05 for optimizer
current performance: -8.3564, best performance: -5.8122
Epoch: 0226 | TRAIN: 2.3239 0.2715 0.6459 | 0.5257 0.5257 0.2440 | 0.2366 34.6932 30.9244 0.1631 0.3648 0.4885 TEST: 3.0478 0.2049 0.5353 | 0.7050 0.6941 0.9797 | 0.2313 34.1608 40.9176 17.1175 37.2080 49.3143, TEACHER: 0.2051 0.5353
lr at 227th epoch is 2.5e-05 for optimizer
current performance: -8.0302, best performance: -5.8122
Epoch: 0227 | TRAIN: 2.3058 0.2743 0.6473 | 0.5237 0.5237 0.2413 | 0.2368 34.6767 30.9185 0.1641 0.3670 0.4902 TEST: 2.8578 0.2107 0.5382 | 0.7242 0.7135 1.0110 | 0.2265 33.7711 40.4561 17.3385 37.7412 49.9196, TEACHER: 0.2107 0.5382
lr at 228th epoch is 2.5e-05 for optimizer
current performance: -8.6750, best performance: -5.8122
Epoch: 0228 | TRAIN: 2.4074 0.2660 0.6404 | 0.5266 0.5266 0.2454 | 0.2374 34.8356 31.0888 0.1569 0.3613 0.4867 TEST: 3.2281 0.1897 0.5316 | 0.6744 0.6634 0.9348 | 0.2273 33.8822 40.5328 17.0591 37.3021 49.5898, TEACHER: 0.1900 0.5317
lr at 229th epoch is 2.5e-05 for optimizer
current performance: -6.0519, best performance: -5.8122
Epoch: 0229 | TRAIN: 2.3704 0.2729 0.6445 | 0.5287 0.5287 0.2456 | 0.2374 34.7760 30.9529 0.1610 0.3640 0.4878 TEST: 2.9315 0.2053 0.5368 | 0.6571 0.6462 0.9098 | 0.2270 33.9908 40.4547 16.2527 36.8502 49.2055, TEACHER: 0.2041 0.5367
lr at 230th epoch is 2.5e-05 for optimizer
current performance: -5.6497, best performance: -5.8122
Epoch: 0230 | TRAIN: 2.3033 0.2710 0.6511 | 0.5221 0.5221 0.2402 | 0.2347 34.5524 30.6896 0.1618 0.3678 0.4920 TEST: 2.6144 0.2173 0.5425 | 0.6854 0.6738 0.9607 | 0.2281 33.9303 40.6212 17.0024 37.4442 49.7159, TEACHER: 0.2168 0.5424
lr at 231th epoch is 2.5e-05 for optimizer
current performance: -8.2520, best performance: -5.6497
Epoch: 0231 | TRAIN: 2.3386 0.2662 0.6415 | 0.5191 0.5191 0.2437 | 0.2351 34.5837 30.7100 0.1609 0.3671 0.4922 TEST: 3.1311 0.1927 0.5299 | 0.6745 0.6638 0.9301 | 0.2266 33.8335 40.4597 17.0852 37.4220 49.6808, TEACHER: 0.1930 0.5300
lr at 232th epoch is 2.5e-05 for optimizer
current performance: -6.8520, best performance: -5.6497
Epoch: 0232 | TRAIN: 2.3625 0.2687 0.6462 | 0.5216 0.5216 0.2468 | 0.2376 34.7376 30.8613 0.1635 0.3671 0.4904 TEST: 2.9335 0.2040 0.5357 | 0.6740 0.6633 0.9287 | 0.2265 33.9003 40.4300 16.7157 37.0257 49.3594, TEACHER: 0.2040 0.5356
lr at 233th epoch is 2.5e-05 for optimizer
current performance: -7.4719, best performance: -5.6497
Epoch: 0233 | TRAIN: 2.3274 0.2688 0.6498 | 0.5141 0.5141 0.2380 | 0.2354 34.6390 30.8120 0.1593 0.3650 0.4904 TEST: 2.8896 0.2023 0.5329 | 0.6854 0.6742 0.9486 | 0.2262 33.8300 40.4260 16.8483 37.4311 49.7189, TEACHER: 0.2018 0.5327
lr at 234th epoch is 2.5e-05 for optimizer
current performance: -9.5957, best performance: -5.6497
Epoch: 0234 | TRAIN: 2.3615 0.2707 0.6515 | 0.5273 0.5273 0.2422 | 0.2345 34.5931 30.9035 0.1595 0.3627 0.4888 TEST: 2.8235 0.2029 0.5309 | 0.7295 0.7179 1.0080 | 0.2295 34.1169 40.7498 16.6418 36.9193 49.2268, TEACHER: 0.2032 0.5310
lr at 235th epoch is 2.5e-05 for optimizer
current performance: -9.4319, best performance: -5.6497
Epoch: 0235 | TRAIN: 2.3923 0.2707 0.6460 | 0.5140 0.5140 0.2425 | 0.2354 34.6409 30.8318 0.1601 0.3643 0.4895 TEST: 2.8620 0.2049 0.5342 | 0.7307 0.7195 1.0144 | 0.2301 34.1377 40.7948 16.7646 36.9153 49.2314, TEACHER: 0.2048 0.5345
lr at 236th epoch is 2.5e-05 for optimizer
current performance: -6.3564, best performance: -5.6497
Epoch: 0236 | TRAIN: 2.4295 0.2741 0.6446 | 0.5321 0.5321 0.2460 | 0.2358 34.6589 30.8096 0.1597 0.3657 0.4907 TEST: 2.9241 0.2025 0.5361 | 0.6607 0.6495 0.9184 | 0.2266 33.8210 40.4837 17.0482 37.6383 49.8863, TEACHER: 0.2027 0.5361
lr at 237th epoch is 2.5e-05 for optimizer
current performance: -7.6828, best performance: -5.6497
Epoch: 0237 | TRAIN: 2.3915 0.2730 0.6459 | 0.5219 0.5219 0.2405 | 0.2386 34.9366 31.2075 0.1558 0.3609 0.4858 TEST: 3.2518 0.1895 0.5341 | 0.6544 0.6438 0.9087 | 0.2262 33.7347 40.4426 17.4625 37.7557 49.9630, TEACHER: 0.1893 0.5341
lr at 238th epoch is 2.5e-05 for optimizer
current performance: -8.5267, best performance: -5.6497
Epoch: 0238 | TRAIN: 2.4281 0.2748 0.6438 | 0.5088 0.5088 0.2403 | 0.2332 34.3957 30.4870 0.1632 0.3701 0.4956 TEST: 3.1040 0.1932 0.5290 | 0.6816 0.6708 0.9500 | 0.2274 33.8747 40.5401 17.0412 37.4564 49.7250, TEACHER: 0.1931 0.5290
lr at 239th epoch is 2.5e-05 for optimizer
current performance: -9.3930, best performance: -5.6497
Epoch: 0239 | TRAIN: 2.4279 0.2732 0.6484 | 0.5200 0.5200 0.2397 | 0.2348 34.5285 30.6823 0.1633 0.3678 0.4925 TEST: 3.0287 0.1991 0.5305 | 0.7095 0.6981 0.9903 | 0.2325 34.2677 41.0801 16.9642 37.2584 49.3414, TEACHER: 0.1985 0.5305
lr at 240th epoch is 2.5e-05 for optimizer
current performance: -9.6997, best performance: -5.6497
Epoch: 0240 | TRAIN: 2.4214 0.2698 0.6483 | 0.5234 0.5234 0.2436 | 0.2366 34.7555 31.0172 0.1591 0.3626 0.4873 TEST: 2.5938 0.2068 0.5387 | 0.7422 0.7295 1.0294 | 0.2308 34.2121 40.8761 16.6498 36.9183 49.1316, TEACHER: 0.2071 0.5387
lr at 241th epoch is 2.5e-05 for optimizer
current performance: -10.1798, best performance: -5.6497
Epoch: 0241 | TRAIN: 2.4821 0.2679 0.6473 | 0.5213 0.5213 0.2410 | 0.2351 34.5768 30.7232 0.1622 0.3661 0.4911 TEST: 3.4343 0.1866 0.5260 | 0.7014 0.6900 0.9718 | 0.2266 33.8507 40.4776 16.8187 37.3884 49.7277, TEACHER: 0.1867 0.5261
lr at 242th epoch is 2.5e-05 for optimizer
current performance: -7.4295, best performance: -5.6497
Epoch: 0242 | TRAIN: 2.4962 0.2720 0.6464 | 0.5190 0.5190 0.2351 | 0.2357 34.6972 31.0130 0.1584 0.3625 0.4876 TEST: 2.8931 0.2065 0.5358 | 0.6802 0.6700 0.9306 | 0.2319 34.4487 40.9575 15.6067 36.3432 48.7001, TEACHER: 0.2065 0.5357
lr at 243th epoch is 2.5e-05 for optimizer
current performance: -9.1415, best performance: -5.6497
Epoch: 0243 | TRAIN: 2.4495 0.2728 0.6485 | 0.5180 0.5180 0.2403 | 0.2372 34.7412 30.8117 0.1602 0.3656 0.4904 TEST: 2.9143 0.2069 0.5337 | 0.7261 0.7155 0.9915 | 0.2314 34.2588 40.9485 16.4955 36.9251 49.1733, TEACHER: 0.2063 0.5336
lr at 244th epoch is 2.5e-05 for optimizer
current performance: -6.8722, best performance: -5.6497
Epoch: 0244 | TRAIN: 2.4560 0.2709 0.6480 | 0.5226 0.5226 0.2355 | 0.2355 34.6093 30.6981 0.1603 0.3669 0.4926 TEST: 3.2776 0.2002 0.5383 | 0.6688 0.6581 0.9302 | 0.2259 33.6809 40.4312 17.5195 38.0268 50.1829, TEACHER: 0.1997 0.5383
lr at 245th epoch is 2.5e-05 for optimizer
current performance: -10.6310, best performance: -5.6497
Epoch: 0245 | TRAIN: 2.4815 0.2676 0.6451 | 0.5179 0.5179 0.2433 | 0.2361 34.6765 30.8527 0.1602 0.3645 0.4898 TEST: 3.0710 0.2022 0.5291 | 0.7489 0.7379 1.0203 | 0.2300 34.1909 40.7730 16.3384 36.6777 49.0741, TEACHER: 0.2025 0.5293
lr at 246th epoch is 2.5e-05 for optimizer
current performance: -8.4222, best performance: -5.6497
Epoch: 0246 | TRAIN: 2.4842 0.2724 0.6462 | 0.5365 0.5365 0.2493 | 0.2338 34.4413 30.5620 0.1641 0.3699 0.4940 TEST: 3.2888 0.2009 0.5328 | 0.7015 0.6910 0.9640 | 0.2274 33.8763 40.5560 17.1323 37.4878 49.7285, TEACHER: 0.2017 0.5330
lr at 247th epoch is 2.5e-05 for optimizer
current performance: -8.9144, best performance: -5.6497
Epoch: 0247 | TRAIN: 2.5301 0.2769 0.6436 | 0.5225 0.5225 0.2398 | 0.2352 34.5651 30.7169 0.1634 0.3672 0.4916 TEST: 3.3028 0.1894 0.5295 | 0.6853 0.6734 0.9581 | 0.2250 33.6862 40.3111 17.1474 37.6958 50.0402, TEACHER: 0.1895 0.5295
lr at 248th epoch is 2.5e-05 for optimizer
current performance: -6.9262, best performance: -5.6497
Epoch: 0248 | TRAIN: 2.4892 0.2714 0.6481 | 0.5335 0.5335 0.2453 | 0.2333 34.4231 30.5199 0.1619 0.3693 0.4949 TEST: 3.1448 0.2015 0.5374 | 0.6786 0.6665 0.9514 | 0.2257 33.5540 40.4429 18.0711 38.6443 50.6925, TEACHER: 0.2009 0.5374
lr at 249th epoch is 2.5e-05 for optimizer
current performance: -8.2202, best performance: -5.6497
Epoch: 0249 | TRAIN: 2.5407 0.2773 0.6463 | 0.5230 0.5230 0.2401 | 0.2358 34.5926 30.7628 0.1629 0.3681 0.4929 TEST: 2.9831 0.2011 0.5317 | 0.6988 0.6879 0.9687 | 0.2263 33.8325 40.4280 16.8687 37.3110 49.6382, TEACHER: 0.2013 0.5317
lr at 250th epoch is 2.5e-05 for optimizer
current performance: -9.1790, best performance: -5.6497
Epoch: 0250 | TRAIN: 2.5486 0.2749 0.6510 | 0.5221 0.5221 0.2398 | 0.2330 34.4047 30.4990 0.1618 0.3693 0.4950 TEST: 2.9634 0.2006 0.5316 | 0.7149 0.7033 0.9976 | 0.2291 34.0476 40.7006 16.7177 37.1132 49.4576, TEACHER: 0.2009 0.5315
lr at 251th epoch is 2.5e-05 for optimizer
current performance: -8.6414, best performance: -5.6497
Epoch: 0251 | TRAIN: 2.4912 0.2671 0.6465 | 0.5186 0.5186 0.2431 | 0.2337 34.3992 30.4478 0.1650 0.3714 0.4967 TEST: 3.1348 0.1957 0.5360 | 0.6986 0.6872 0.9705 | 0.2259 33.6227 40.4169 17.8715 38.2747 50.3492, TEACHER: 0.1958 0.5361
lr at 252th epoch is 2.5e-05 for optimizer
current performance: -9.6157, best performance: -5.6497
Epoch: 0252 | TRAIN: 2.4777 0.2746 0.6542 | 0.5150 0.5150 0.2396 | 0.2332 34.3206 30.3186 0.1668 0.3741 0.4984 TEST: 3.1288 0.2000 0.5326 | 0.7272 0.7157 0.9991 | 0.2280 33.8853 40.6223 17.0533 37.7530 49.9995, TEACHER: 0.2005 0.5329
lr at 253th epoch is 2.5e-05 for optimizer
current performance: -7.8798, best performance: -5.6497
Epoch: 0253 | TRAIN: 2.4708 0.2751 0.6487 | 0.5138 0.5138 0.2352 | 0.2328 34.4053 30.4433 0.1597 0.3684 0.4961 TEST: 3.0464 0.2004 0.5363 | 0.6918 0.6806 0.9617 | 0.2263 33.7321 40.4508 17.3444 37.8611 50.1116, TEACHER: 0.2009 0.5364
lr at 254th epoch is 2.5e-05 for optimizer
current performance: -4.9688, best performance: -5.6497
Epoch: 0254 | TRAIN: 2.5182 0.2782 0.6519 | 0.5195 0.5195 0.2382 | 0.2332 34.3949 30.4661 0.1623 0.3709 0.4965 TEST: 3.0104 0.2112 0.5417 | 0.6587 0.6485 0.9013 | 0.2261 33.6018 40.4618 18.0845 38.4961 50.4862, TEACHER: 0.2105 0.5416
lr at 255th epoch is 2.5e-05 for optimizer
current performance: -7.3159, best performance: -4.9688
Epoch: 0255 | TRAIN: 2.5178 0.2750 0.6508 | 0.5167 0.5167 0.2396 | 0.2348 34.4936 30.5536 0.1644 0.3709 0.4945 TEST: 3.2835 0.1972 0.5268 | 0.6680 0.6576 0.9227 | 0.2263 33.7517 40.4417 17.3329 37.7118 49.9464, TEACHER: 0.1976 0.5268
lr at 256th epoch is 2.5e-05 for optimizer
current performance: -7.7358, best performance: -4.9688
Epoch: 0256 | TRAIN: 2.5673 0.2749 0.6472 | 0.5234 0.5234 0.2430 | 0.2343 34.4510 30.5142 0.1659 0.3700 0.4947 TEST: 3.2205 0.2077 0.5366 | 0.6972 0.6856 0.9722 | 0.2320 34.2434 41.0168 16.8089 37.0624 49.2713, TEACHER: 0.2075 0.5365
lr at 257th epoch is 2.5e-05 for optimizer
current performance: -8.9022, best performance: -4.9688
Epoch: 0257 | TRAIN: 2.5611 0.2767 0.6503 | 0.5136 0.5136 0.2394 | 0.2339 34.4668 30.6124 0.1616 0.3686 0.4944 TEST: 3.0926 0.2015 0.5375 | 0.7097 0.6971 0.9979 | 0.2307 34.1406 40.9000 16.8568 37.3992 49.4876, TEACHER: 0.2016 0.5375
lr at 258th epoch is 2.5e-05 for optimizer
current performance: -6.6826, best performance: -4.9688
Epoch: 0258 | TRAIN: 2.5379 0.2728 0.6518 | 0.5170 0.5170 0.2360 | 0.2348 34.5690 30.7704 0.1603 0.3668 0.4917 TEST: 3.1255 0.2026 0.5371 | 0.6785 0.6671 0.9524 | 0.2238 33.4366 40.2290 17.8034 38.5891 50.8741, TEACHER: 0.2030 0.5372
lr at 259th epoch is 2.5e-05 for optimizer
current performance: -7.5088, best performance: -4.9688
Epoch: 0259 | TRAIN: 2.5318 0.2765 0.6519 | 0.5113 0.5113 0.2392 | 0.2344 34.4750 30.5963 0.1631 0.3702 0.4956 TEST: 2.8479 0.2128 0.5403 | 0.7216 0.7097 1.0025 | 0.2263 33.6981 40.4611 17.4956 38.0518 50.2369, TEACHER: 0.2127 0.5401
lr at 260th epoch is 2.5e-05 for optimizer
current performance: -7.1418, best performance: -4.9688
Epoch: 0260 | TRAIN: 2.4847 0.2753 0.6533 | 0.5138 0.5138 0.2393 | 0.2332 34.3931 30.4708 0.1635 0.3705 0.4954 TEST: 3.2140 0.1998 0.5341 | 0.6705 0.6597 0.9217 | 0.2271 33.8165 40.5378 17.1839 37.7799 50.0432, TEACHER: 0.1994 0.5340
lr at 261th epoch is 2.5e-05 for optimizer
current performance: -6.9270, best performance: -4.9688
Epoch: 0261 | TRAIN: 2.5558 0.2755 0.6515 | 0.5157 0.5157 0.2376 | 0.2339 34.3926 30.3647 0.1662 0.3729 0.4968 TEST: 3.1130 0.2061 0.5388 | 0.6868 0.6764 0.9493 | 0.2255 33.6911 40.3588 17.2011 37.8185 50.1437, TEACHER: 0.2062 0.5389
lr at 262th epoch is 2.5e-05 for optimizer
current performance: -5.9164, best performance: -4.9688
Epoch: 0262 | TRAIN: 2.5320 0.2735 0.6507 | 0.5226 0.5226 0.2402 | 0.2346 34.4979 30.5864 0.1635 0.3692 0.4943 TEST: 3.0258 0.2073 0.5349 | 0.6668 0.6565 0.9193 | 0.2258 33.6949 40.4080 17.1035 38.1578 50.4083, TEACHER: 0.2078 0.5350
lr at 263th epoch is 2.5e-05 for optimizer
current performance: -8.8077, best performance: -4.9688
Epoch: 0263 | TRAIN: 2.5789 0.2709 0.6466 | 0.5212 0.5212 0.2397 | 0.2337 34.4457 30.4266 0.1610 0.3701 0.4960 TEST: 2.7695 0.2214 0.5387 | 0.7599 0.7493 1.0405 | 0.2327 34.3049 41.0800 16.7803 37.0431 49.2016, TEACHER: 0.2195 0.5385
lr at 264th epoch is 2.5e-05 for optimizer
current performance: -8.6152, best performance: -4.9688
Epoch: 0264 | TRAIN: 2.5693 0.2792 0.6551 | 0.5172 0.5172 0.2433 | 0.2336 34.4243 30.4906 0.1627 0.3700 0.4957 TEST: 3.2490 0.1981 0.5339 | 0.7069 0.6954 0.9787 | 0.2244 33.5623 40.2866 17.2985 38.2280 50.6110, TEACHER: 0.1985 0.5340
lr at 265th epoch is 2.5e-05 for optimizer
current performance: -8.1064, best performance: -4.9688
Epoch: 0265 | TRAIN: 2.5992 0.2823 0.6558 | 0.5170 0.5170 0.2354 | 0.2327 34.3061 30.3025 0.1646 0.3738 0.4995 TEST: 3.3925 0.2024 0.5322 | 0.7024 0.6920 0.9641 | 0.2256 33.7204 40.3761 17.0772 37.7001 50.0888, TEACHER: 0.2025 0.5323
lr at 266th epoch is 2.5e-05 for optimizer
current performance: -6.1928, best performance: -4.9688
Epoch: 0266 | TRAIN: 2.6075 0.2750 0.6549 | 0.5160 0.5160 0.2331 | 0.2321 34.2977 30.3381 0.1643 0.3718 0.4969 TEST: 3.2362 0.2091 0.5362 | 0.6804 0.6690 0.9533 | 0.2252 33.6683 40.3446 17.2331 37.9091 50.1909, TEACHER: 0.2088 0.5361
lr at 267th epoch is 2.5e-05 for optimizer
current performance: -6.1179, best performance: -4.9688
Epoch: 0267 | TRAIN: 2.5587 0.2760 0.6499 | 0.5114 0.5114 0.2366 | 0.2318 34.1625 30.0761 0.1701 0.3772 0.5012 TEST: 2.9821 0.2124 0.5385 | 0.6822 0.6714 0.9506 | 0.2282 33.8796 40.6507 17.3389 37.7109 49.8925, TEACHER: 0.2111 0.5383
lr at 268th epoch is 2.5e-05 for optimizer
current performance: -6.3169, best performance: -4.9688
Epoch: 0268 | TRAIN: 2.5975 0.2798 0.6551 | 0.5115 0.5115 0.2329 | 0.2343 34.4365 30.4459 0.1647 0.3721 0.4965 TEST: 3.3304 0.2047 0.5332 | 0.6624 0.6518 0.9169 | 0.2282 33.9387 40.6472 16.9200 37.4514 49.8122, TEACHER: 0.2056 0.5334
lr at 269th epoch is 2.5e-05 for optimizer
current performance: -6.5393, best performance: -4.9688
Epoch: 0269 | TRAIN: 2.6253 0.2846 0.6520 | 0.5146 0.5146 0.2403 | 0.2333 34.3527 30.3252 0.1649 0.3730 0.4986 TEST: 3.2019 0.2044 0.5356 | 0.6760 0.6657 0.9297 | 0.2248 33.5712 40.3066 17.5739 38.1543 50.4375, TEACHER: 0.2043 0.5356
lr at 270th epoch is 2.5e-05 for optimizer
current performance: -6.6259, best performance: -4.9688
Epoch: 0270 | TRAIN: 2.6427 0.2749 0.6502 | 0.5125 0.5125 0.2405 | 0.2343 34.4239 30.4493 0.1644 0.3731 0.4978 TEST: 3.3679 0.2054 0.5333 | 0.6780 0.6676 0.9389 | 0.2253 33.6898 40.3558 17.3866 37.8030 50.0139, TEACHER: 0.2050 0.5332
lr at 271th epoch is 2.5e-05 for optimizer
current performance: -6.7656, best performance: -4.9688
Epoch: 0271 | TRAIN: 2.5653 0.2793 0.6552 | 0.5083 0.5083 0.2336 | 0.2312 34.1508 30.1702 0.1678 0.3765 0.5017 TEST: 3.4639 0.1986 0.5293 | 0.6623 0.6510 0.9219 | 0.2250 33.6799 40.3168 17.2307 37.7241 49.9954, TEACHER: 0.1983 0.5291
lr at 272th epoch is 2.5e-05 for optimizer
current performance: -5.3194, best performance: -4.9688
Epoch: 0272 | TRAIN: 2.5511 0.2786 0.6527 | 0.5172 0.5172 0.2372 | 0.2317 34.1494 30.0733 0.1691 0.3782 0.5029 TEST: 2.9034 0.2079 0.5387 | 0.6548 0.6448 0.9089 | 0.2268 33.6887 40.5246 17.7742 38.3254 50.3969, TEACHER: 0.2081 0.5387
lr at 273th epoch is 2.5e-05 for optimizer
current performance: -6.2837, best performance: -4.9688
Epoch: 0273 | TRAIN: 2.6393 0.2842 0.6529 | 0.5299 0.5299 0.2436 | 0.2330 34.3209 30.3641 0.1663 0.3736 0.4980 TEST: 3.0956 0.2113 0.5365 | 0.6856 0.6739 0.9591 | 0.2272 33.8151 40.5523 17.0840 37.8911 50.1903, TEACHER: 0.2109 0.5366
lr at 274th epoch is 2.5e-05 for optimizer
current performance: -7.5968, best performance: -4.9688
Epoch: 0274 | TRAIN: 2.6529 0.2786 0.6478 | 0.5051 0.5051 0.2281 | 0.2311 34.1643 30.1717 0.1670 0.3757 0.5004 TEST: 3.3014 0.1957 0.5317 | 0.6734 0.6626 0.9287 | 0.2264 33.6416 40.5106 17.8657 38.4184 50.5098, TEACHER: 0.1962 0.5317
lr at 275th epoch is 2.5e-05 for optimizer
current performance: -6.7511, best performance: -4.9688
Epoch: 0275 | TRAIN: 2.6875 0.2800 0.6486 | 0.5150 0.5150 0.2342 | 0.2320 34.2603 30.3122 0.1651 0.3733 0.4989 TEST: 3.0865 0.2000 0.5339 | 0.6693 0.6591 0.9233 | 0.2243 33.5067 40.2851 17.5913 38.4873 50.7270, TEACHER: 0.2002 0.5339
lr at 276th epoch is 2.5e-05 for optimizer
current performance: -6.6646, best performance: -4.9688
Epoch: 0276 | TRAIN: 2.6484 0.2808 0.6552 | 0.5112 0.5112 0.2342 | 0.2325 34.2916 30.3220 0.1658 0.3733 0.4981 TEST: 3.3254 0.2042 0.5380 | 0.6813 0.6693 0.9496 | 0.2247 33.5188 40.3195 17.7964 38.4015 50.6235, TEACHER: 0.2040 0.5379
lr at 277th epoch is 2.5e-05 for optimizer
current performance: -7.4873, best performance: -4.9688
Epoch: 0277 | TRAIN: 2.7172 0.2818 0.6545 | 0.5137 0.5137 0.2397 | 0.2339 34.4135 30.4277 0.1642 0.3715 0.4965 TEST: 3.4297 0.2060 0.5383 | 0.6951 0.6837 0.9678 | 0.2287 33.9011 40.7105 17.3485 37.8022 49.9871, TEACHER: 0.2061 0.5383
lr at 278th epoch is 2.5e-05 for optimizer
current performance: -6.5753, best performance: -4.9688
Epoch: 0278 | TRAIN: 2.6648 0.2835 0.6545 | 0.5236 0.5236 0.2396 | 0.2310 34.1299 30.1271 0.1684 0.3763 0.5016 TEST: 3.3046 0.1964 0.5290 | 0.6534 0.6435 0.8904 | 0.2243 33.5465 40.2644 17.6273 38.1355 50.3614, TEACHER: 0.1965 0.5289
lr at 279th epoch is 2.5e-05 for optimizer
current performance: -7.6479, best performance: -4.9688
Epoch: 0279 | TRAIN: 2.6386 0.2821 0.6528 | 0.5075 0.5075 0.2383 | 0.2335 34.4289 30.5222 0.1622 0.3700 0.4956 TEST: 3.4973 0.1964 0.5294 | 0.6765 0.6650 0.9458 | 0.2257 33.6737 40.3870 17.3758 37.9469 50.2292, TEACHER: 0.1957 0.5294
lr at 280th epoch is 2.5e-05 for optimizer
current performance: -7.5709, best performance: -4.9688
Epoch: 0280 | TRAIN: 2.6611 0.2761 0.6503 | 0.5045 0.5045 0.2349 | 0.2329 34.3354 30.3928 0.1641 0.3725 0.4978 TEST: 3.0121 0.2101 0.5393 | 0.7134 0.7019 0.9843 | 0.2267 33.7385 40.4960 17.5030 37.9858 50.1413, TEACHER: 0.2098 0.5392
lr at 281th epoch is 2.5e-05 for optimizer
current performance: -7.9462, best performance: -4.9688
Epoch: 0281 | TRAIN: 2.6681 0.2788 0.6557 | 0.5209 0.5209 0.2409 | 0.2323 34.3351 30.4200 0.1635 0.3689 0.4951 TEST: 3.5331 0.1915 0.5305 | 0.6696 0.6601 0.9155 | 0.2240 33.5645 40.2297 17.3478 38.0386 50.3936, TEACHER: 0.1918 0.5306
lr at 282th epoch is 2.5e-05 for optimizer
current performance: -7.1282, best performance: -4.9688
Epoch: 0282 | TRAIN: 2.7044 0.2825 0.6558 | 0.5225 0.5225 0.2381 | 0.2310 34.1469 30.1091 0.1675 0.3757 0.5008 TEST: 3.0964 0.2106 0.5335 | 0.6992 0.6885 0.9634 | 0.2275 33.9211 40.5549 16.7896 37.2716 49.6719, TEACHER: 0.2110 0.5335
lr at 283th epoch is 2.5e-05 for optimizer
current performance: -10.0274, best performance: -4.9688
Epoch: 0283 | TRAIN: 2.6679 0.2849 0.6565 | 0.5028 0.5028 0.2336 | 0.2320 34.2147 30.1549 0.1676 0.3756 0.5009 TEST: 3.1711 0.1977 0.5294 | 0.7320 0.7204 1.0040 | 0.2267 33.8088 40.4858 16.8898 37.5739 50.0383, TEACHER: 0.1975 0.5294
lr at 284th epoch is 2.5e-05 for optimizer
current performance: -7.0806, best performance: -4.9688
Epoch: 0284 | TRAIN: 2.7894 0.2855 0.6568 | 0.5198 0.5198 0.2347 | 0.2321 34.2638 30.3249 0.1656 0.3733 0.4991 TEST: 3.3297 0.1949 0.5334 | 0.6638 0.6524 0.9142 | 0.2231 33.4786 40.1255 17.5125 38.1075 50.4380, TEACHER: 0.1953 0.5334
lr at 285th epoch is 2.5e-05 for optimizer
current performance: -9.6927, best performance: -4.9688
Epoch: 0285 | TRAIN: 2.7238 0.2770 0.6502 | 0.5211 0.5211 0.2374 | 0.2333 34.3444 30.3637 0.1654 0.3732 0.4981 TEST: 3.8101 0.1850 0.5228 | 0.6950 0.6828 0.9703 | 0.2242 33.5168 40.2533 17.5682 38.1864 50.5378, TEACHER: 0.1852 0.5229
lr at 286th epoch is 2.5e-05 for optimizer
current performance: -6.6326, best performance: -4.9688
Epoch: 0286 | TRAIN: 2.7363 0.2723 0.6553 | 0.5065 0.5065 0.2375 | 0.2342 34.4365 30.3882 0.1643 0.3717 0.4966 TEST: 3.1251 0.2096 0.5371 | 0.6894 0.6782 0.9488 | 0.2269 33.7581 40.5277 17.4995 37.9570 50.1007, TEACHER: 0.2096 0.5371
lr at 287th epoch is 2.5e-05 for optimizer
current performance: -6.7338, best performance: -4.9688
Epoch: 0287 | TRAIN: 2.7029 0.2776 0.6574 | 0.5115 0.5115 0.2364 | 0.2333 34.3790 30.4031 0.1637 0.3716 0.4972 TEST: 3.4058 0.2003 0.5336 | 0.6691 0.6584 0.9210 | 0.2242 33.5592 40.2451 17.2944 38.1267 50.4756, TEACHER: 0.2003 0.5336
lr at 288th epoch is 2.5e-05 for optimizer
current performance: -8.1163, best performance: -4.9688
Epoch: 0288 | TRAIN: 2.7183 0.2859 0.6569 | 0.5145 0.5145 0.2322 | 0.2299 34.0288 29.9547 0.1687 0.3784 0.5039 TEST: 3.6382 0.1933 0.5251 | 0.6788 0.6685 0.9310 | 0.2249 33.6000 40.3120 17.4039 38.0135 50.3917, TEACHER: 0.1932 0.5250
lr at 289th epoch is 2.5e-05 for optimizer
current performance: -6.2679, best performance: -4.9688
Epoch: 0289 | TRAIN: 2.6951 0.2816 0.6560 | 0.5173 0.5173 0.2379 | 0.2317 34.2013 30.1804 0.1660 0.3759 0.5012 TEST: 3.3582 0.2014 0.5318 | 0.6646 0.6534 0.9273 | 0.2245 33.4518 40.3262 18.1348 38.6811 50.8483, TEACHER: 0.2015 0.5318
lr at 290th epoch is 2.5e-05 for optimizer
current performance: -7.0375, best performance: -4.9688
Epoch: 0290 | TRAIN: 2.7517 0.2831 0.6514 | 0.5033 0.5033 0.2343 | 0.2312 34.1416 30.0527 0.1675 0.3774 0.5027 TEST: 3.4765 0.1886 0.5304 | 0.6465 0.6361 0.8998 | 0.2225 33.3525 40.1063 17.6964 38.5730 50.9437, TEACHER: 0.1887 0.5306
lr at 291th epoch is 2.5e-05 for optimizer
current performance: -7.5173, best performance: -4.9688
Epoch: 0291 | TRAIN: 2.7305 0.2819 0.6553 | 0.5143 0.5143 0.2377 | 0.2316 34.1425 30.0176 0.1693 0.3787 0.5029 TEST: 3.2622 0.2024 0.5364 | 0.6889 0.6780 0.9475 | 0.2261 33.7407 40.4389 17.1158 37.7731 50.1447, TEACHER: 0.2022 0.5364
lr at 292th epoch is 2.5e-05 for optimizer
current performance: -7.6783, best performance: -4.9688
Epoch: 0292 | TRAIN: 2.7078 0.2843 0.6544 | 0.5077 0.5077 0.2332 | 0.2300 33.9912 29.8952 0.1717 0.3803 0.5055 TEST: 3.4099 0.2058 0.5360 | 0.7116 0.7002 0.9947 | 0.2242 33.4143 40.3050 18.1427 38.8121 50.9791, TEACHER: 0.2055 0.5360
lr at 293th epoch is 2.5e-05 for optimizer
current performance: -7.4401, best performance: -4.9688
Epoch: 0293 | TRAIN: 2.6535 0.2862 0.6548 | 0.5222 0.5222 0.2427 | 0.2324 34.2496 30.2195 0.1657 0.3751 0.5012 TEST: 3.2559 0.2035 0.5337 | 0.7027 0.6919 0.9612 | 0.2215 33.2554 40.0186 17.9241 38.7754 51.0983, TEACHER: 0.2041 0.5336
lr at 294th epoch is 2.5e-05 for optimizer
current performance: -6.9351, best performance: -4.9688
Epoch: 0294 | TRAIN: 2.7342 0.2771 0.6529 | 0.5006 0.5006 0.2358 | 0.2327 34.2786 30.2716 0.1652 0.3751 0.5007 TEST: 3.1963 0.1992 0.5331 | 0.6695 0.6583 0.9284 | 0.2261 33.6160 40.4779 17.6827 38.5158 50.7171, TEACHER: 0.1988 0.5331
lr at 295th epoch is 2.5e-05 for optimizer
current performance: -7.5169, best performance: -4.9688
Epoch: 0295 | TRAIN: 2.6414 0.2868 0.6580 | 0.5025 0.5025 0.2336 | 0.2304 34.0558 29.9943 0.1697 0.3786 0.5032 TEST: 3.3469 0.1982 0.5323 | 0.6828 0.6704 0.9556 | 0.2247 33.5497 40.3115 17.5630 38.3131 50.5868, TEACHER: 0.1984 0.5325
lr at 296th epoch is 2.5e-05 for optimizer
current performance: -5.7255, best performance: -4.9688
Epoch: 0296 | TRAIN: 2.7457 0.2850 0.6589 | 0.5155 0.5155 0.2333 | 0.2295 33.9721 29.9087 0.1695 0.3803 0.5056 TEST: 3.5118 0.1978 0.5306 | 0.6409 0.6309 0.8825 | 0.2229 33.4243 40.1188 17.7937 38.2569 50.5030, TEACHER: 0.1979 0.5306
lr at 297th epoch is 2.5e-05 for optimizer
current performance: -5.7573, best performance: -4.9688
Epoch: 0297 | TRAIN: 2.7828 0.2893 0.6581 | 0.5092 0.5092 0.2366 | 0.2293 33.9633 29.8781 0.1687 0.3800 0.5067 TEST: 3.5021 0.2044 0.5396 | 0.6568 0.6457 0.9118 | 0.2266 33.6336 40.5191 17.9354 38.3503 50.5137, TEACHER: 0.2044 0.5396
lr at 298th epoch is 2.5e-05 for optimizer
current performance: -8.2905, best performance: -4.9688
Epoch: 0298 | TRAIN: 2.8169 0.2797 0.6535 | 0.5090 0.5090 0.2391 | 0.2296 33.9701 29.8345 0.1695 0.3814 0.5064 TEST: 3.4732 0.1910 0.5352 | 0.6855 0.6741 0.9461 | 0.2223 33.2821 40.0837 18.1523 38.8289 51.0118, TEACHER: 0.1917 0.5353
lr at 299th epoch is 2.5e-05 for optimizer
current performance: -7.8114, best performance: -4.9688
Epoch: 0299 | TRAIN: 2.7101 0.2830 0.6596 | 0.5120 0.5120 0.2360 | 0.2311 34.1339 30.0524 0.1670 0.3768 0.5033 TEST: 3.4927 0.1944 0.5283 | 0.6754 0.6641 0.9366 | 0.2247 33.6235 40.2982 17.3545 37.8382 50.1949, TEACHER: 0.1943 0.5282
Epoch: 0254 | TRAIN: 2.5182 0.2782 0.6519 | 0.5195 0.5195 0.2382 | 0.2332 34.3949 30.4661 0.1623 0.3709 0.4965 TEST: 3.0104 0.2112 0.5417 | 0.6587 0.6485 0.9013 | 0.2261 33.6018 40.4618 18.0845 38.4961 50.4862
