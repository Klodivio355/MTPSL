
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/scratch_tmp/grp/grv_shi/k21220263/MTPSL/nyu_mtl_xtc.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels_weights = torch.load('{}onelabel.pth'.format(opt.labelroot))['labels_weights'].float().cuda()
Parameter Space: ABS: 28889941.0, REL: 1.1565

LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR ROOT_MSE | NORMAL_LOSS MEAN MED <11.25 <22.5 <30

lr at 0th epoch is 0.0001 for optimizer
current performance: -99.9828, best performance: -100.0000
Epoch: 0000 | TRAIN: 2.6468 0.0649 0.2563 | 1.5635 1.5635 0.7897 | 0.3658 47.2579 46.1107 0.0330 0.1331 0.2329 TEST: 2.6581 0.0390 0.2228 | 2.1073 2.0652 2.3597 | 0.3356 44.2688 49.6817 3.9199 19.2509 32.1302
lr at 1th epoch is 0.0001 for optimizer
current performance: -55.4392, best performance: -99.9828
Epoch: 0001 | TRAIN: 2.1057 0.0926 0.3205 | 1.2017 1.2017 0.5966 | 0.3361 44.8654 43.3440 0.0411 0.1587 0.2668 TEST: 2.2330 0.0771 0.3174 | 1.1805 1.1645 1.5537 | 0.3175 43.5829 47.8717 4.4386 15.7938 26.6342
lr at 2th epoch is 0.0001 for optimizer
current performance: -37.0211, best performance: -55.4392
Epoch: 0002 | TRAIN: 1.9943 0.1028 0.3324 | 0.9827 0.9827 0.4853 | 0.3274 44.2638 42.8187 0.0394 0.1585 0.2726 TEST: 1.9262 0.1169 0.3758 | 0.8959 0.8856 1.1396 | 0.3053 42.4146 46.9505 4.3536 17.3527 30.1809
lr at 3th epoch is 0.0001 for optimizer
current performance: -42.7196, best performance: -37.0211
Epoch: 0003 | TRAIN: 1.8498 0.1193 0.3827 | 0.9690 0.9690 0.4732 | 0.3109 42.6611 41.1668 0.0523 0.1898 0.3083 TEST: 1.7911 0.1149 0.3532 | 1.0784 1.0600 1.4580 | 0.2877 40.5296 45.5737 6.5610 22.4946 35.0101
lr at 4th epoch is 0.0001 for optimizer
current performance: -31.5873, best performance: -37.0211
Epoch: 0004 | TRAIN: 1.7837 0.1270 0.3961 | 0.8939 0.8939 0.4323 | 0.3015 41.5869 39.7237 0.0648 0.2199 0.3392 TEST: 1.7819 0.1199 0.4196 | 0.8213 0.8050 1.1196 | 0.2917 40.9974 45.8386 6.2845 21.4757 33.5704
lr at 5th epoch is 0.0001 for optimizer
current performance: -24.4151, best performance: -31.5873
Epoch: 0005 | TRAIN: 1.6528 0.1432 0.4328 | 0.8583 0.8583 0.4098 | 0.2915 40.6516 38.7093 0.0732 0.2382 0.3589 TEST: 1.6239 0.1567 0.4352 | 0.8123 0.7965 1.1189 | 0.2728 39.0956 44.3151 7.7934 24.9798 37.9559
lr at 6th epoch is 0.0001 for optimizer
current performance: -24.8845, best performance: -24.4151
Epoch: 0006 | TRAIN: 1.5716 0.1612 0.4593 | 0.8034 0.8034 0.3891 | 0.2831 39.9534 37.8211 0.0759 0.2452 0.3689 TEST: 1.6215 0.1514 0.4735 | 0.8095 0.7936 1.1239 | 0.2718 39.0231 44.1996 8.1013 25.4416 37.7575
lr at 7th epoch is 0.0001 for optimizer
current performance: -27.7530, best performance: -24.4151
Epoch: 0007 | TRAIN: 1.5363 0.1732 0.4769 | 0.7905 0.7905 0.3774 | 0.2790 39.5467 37.4137 0.0808 0.2531 0.3763 TEST: 1.4614 0.2071 0.4971 | 1.0623 1.0463 1.3953 | 0.2633 38.1851 43.5088 9.4977 26.5009 39.0599
lr at 8th epoch is 0.0001 for optimizer
current performance: -5.7517, best performance: -24.4151
Epoch: 0008 | TRAIN: 1.4226 0.1968 0.5161 | 0.7352 0.7352 0.3490 | 0.2647 38.2507 35.8034 0.0899 0.2721 0.4000 TEST: 1.3481 0.2639 0.5343 | 0.7219 0.7082 0.9860 | 0.2682 38.0557 44.1862 9.6164 29.9832 42.5713
lr at 9th epoch is 0.0001 for optimizer
current performance: -9.0344, best performance: -5.7517
Epoch: 0009 | TRAIN: 1.4031 0.2042 0.5279 | 0.7093 0.7093 0.3430 | 0.2665 38.3119 35.8524 0.0933 0.2759 0.4025 TEST: 1.4424 0.2216 0.5407 | 0.7066 0.6979 0.9389 | 0.2475 36.5446 42.1562 11.1687 30.2186 43.0487
lr at 10th epoch is 0.0001 for optimizer
current performance: -2.2191, best performance: -5.7517
Epoch: 0010 | TRAIN: 1.3320 0.2179 0.5520 | 0.7378 0.7378 0.3551 | 0.2551 37.2482 34.5182 0.1011 0.2952 0.4251 TEST: 1.3379 0.2881 0.5605 | 0.7559 0.7512 0.9670 | 0.2427 35.9806 41.7729 12.0664 31.9860 44.4905
lr at 11th epoch is 0.0001 for optimizer
current performance: 4.1951, best performance: -2.2191
Epoch: 0011 | TRAIN: 1.3310 0.2200 0.5546 | 0.6662 0.6662 0.3171 | 0.2523 37.1064 34.5988 0.1002 0.2907 0.4215 TEST: 1.2880 0.2965 0.5675 | 0.6430 0.6342 0.8945 | 0.2361 35.7210 41.1270 10.5910 30.5986 44.4849
lr at 12th epoch is 0.0001 for optimizer
current performance: 2.2539, best performance: 4.1951
Epoch: 0012 | TRAIN: 1.2332 0.2399 0.5851 | 0.6431 0.6431 0.3123 | 0.2462 36.3628 33.3982 0.1122 0.3108 0.4421 TEST: 1.3566 0.2847 0.5504 | 0.6516 0.6411 0.9003 | 0.2414 35.8411 41.6530 11.8625 31.8991 44.9523
lr at 13th epoch is 0.0001 for optimizer
current performance: -3.2703, best performance: 4.1951
Epoch: 0013 | TRAIN: 1.2137 0.2475 0.6001 | 0.6105 0.6105 0.2851 | 0.2427 36.0388 33.0711 0.1149 0.3169 0.4486 TEST: 1.4714 0.2493 0.5192 | 0.6657 0.6550 0.9258 | 0.2430 36.1979 41.7418 11.4408 30.1100 43.2566
lr at 14th epoch is 0.0001 for optimizer
current performance: -0.0967, best performance: 4.1951
Epoch: 0014 | TRAIN: 1.2042 0.2572 0.6058 | 0.6269 0.6269 0.2971 | 0.2395 35.7239 32.8107 0.1200 0.3214 0.4538 TEST: 1.3840 0.2769 0.5651 | 0.7154 0.7004 1.0349 | 0.2283 34.7455 40.4297 12.9569 33.0759 46.3134
lr at 15th epoch is 0.0001 for optimizer
current performance: 6.7658, best performance: 4.1951
Epoch: 0015 | TRAIN: 1.1592 0.2668 0.6145 | 0.6108 0.6108 0.2943 | 0.2344 35.2165 32.1476 0.1245 0.3326 0.4646 TEST: 1.2887 0.2977 0.5996 | 0.6203 0.6115 0.8528 | 0.2229 34.4262 39.8875 12.0458 33.4166 46.9353
lr at 16th epoch is 0.0001 for optimizer
current performance: 10.0659, best performance: 6.7658
Epoch: 0016 | TRAIN: 1.1702 0.2628 0.6212 | 0.5897 0.5897 0.2851 | 0.2342 35.2164 32.0256 0.1220 0.3313 0.4670 TEST: 1.2880 0.3156 0.5969 | 0.6047 0.5951 0.8510 | 0.2233 34.1465 39.9581 13.6198 34.5504 48.0177
lr at 17th epoch is 0.0001 for optimizer
current performance: -1.1422, best performance: 10.0659
Epoch: 0017 | TRAIN: 1.1573 0.2720 0.6282 | 0.5932 0.5932 0.2759 | 0.2286 34.6968 31.5029 0.1276 0.3411 0.4748 TEST: 1.2653 0.3152 0.5950 | 0.8702 0.8535 1.1909 | 0.2221 34.1345 39.8615 13.3692 34.4962 47.7285
lr at 18th epoch is 0.0001 for optimizer
current performance: 8.1639, best performance: 10.0659
Epoch: 0018 | TRAIN: 1.1061 0.2801 0.6417 | 0.5872 0.5872 0.2798 | 0.2285 34.6807 31.5081 0.1274 0.3409 0.4766 TEST: 1.4179 0.3116 0.5814 | 0.6557 0.6439 0.9126 | 0.2160 33.5005 39.3038 14.2886 35.8665 49.1376
lr at 19th epoch is 0.0001 for optimizer
current performance: 13.5396, best performance: 10.0659
Epoch: 0019 | TRAIN: 1.0873 0.2898 0.6521 | 0.5563 0.5563 0.2654 | 0.2245 34.2188 30.8939 0.1349 0.3539 0.4869 TEST: 1.3319 0.3273 0.5883 | 0.5870 0.5779 0.8245 | 0.2116 33.0264 38.8929 14.9236 36.8202 50.1320
lr at 20th epoch is 0.0001 for optimizer
current performance: 8.7332, best performance: 13.5396
Epoch: 0020 | TRAIN: 1.0330 0.3053 0.6728 | 0.5448 0.5448 0.2553 | 0.2177 33.6000 30.1364 0.1395 0.3625 0.4994 TEST: 1.3321 0.3155 0.5991 | 0.6632 0.6554 0.8702 | 0.2104 32.9861 38.7186 15.0326 36.4273 49.7193
lr at 21th epoch is 0.0001 for optimizer
current performance: 9.3069, best performance: 13.5396
Epoch: 0021 | TRAIN: 1.0328 0.3034 0.6727 | 0.5610 0.5610 0.2640 | 0.2184 33.5703 30.0301 0.1436 0.3669 0.5022 TEST: 1.2770 0.3348 0.6114 | 0.7045 0.6942 0.9665 | 0.2134 33.1804 39.0819 14.2671 36.9035 50.4016
lr at 22th epoch is 0.0001 for optimizer
current performance: 15.4634, best performance: 13.5396
Epoch: 0022 | TRAIN: 1.0374 0.3079 0.6764 | 0.5374 0.5374 0.2561 | 0.2171 33.5161 30.0305 0.1410 0.3647 0.5016 TEST: 1.3477 0.3386 0.6070 | 0.5877 0.5796 0.8162 | 0.2075 32.5278 38.5245 15.7105 38.6143 51.5696
lr at 23th epoch is 0.0001 for optimizer
current performance: 18.9953, best performance: 15.4634
Epoch: 0023 | TRAIN: 1.0611 0.3049 0.6704 | 0.5380 0.5380 0.2469 | 0.2170 33.4635 29.8163 0.1432 0.3678 0.5034 TEST: 1.2542 0.3586 0.6238 | 0.5679 0.5604 0.7937 | 0.2045 32.3900 38.1802 15.4245 37.7435 51.3106
lr at 24th epoch is 0.0001 for optimizer
current performance: 15.4952, best performance: 18.9953
Epoch: 0024 | TRAIN: 1.0569 0.3132 0.6770 | 0.5380 0.5380 0.2556 | 0.2169 33.4383 29.8646 0.1433 0.3701 0.5050 TEST: 1.3007 0.3445 0.6252 | 0.6039 0.5975 0.8137 | 0.2059 32.4753 38.3334 15.7262 37.6940 51.0500
lr at 25th epoch is 0.0001 for optimizer
current performance: 16.3126, best performance: 18.9953
Epoch: 0025 | TRAIN: 1.0400 0.3185 0.6848 | 0.5117 0.5117 0.2369 | 0.2139 33.0899 29.3510 0.1490 0.3776 0.5140 TEST: 1.2835 0.3591 0.6215 | 0.6427 0.6327 0.9050 | 0.2025 32.0559 38.0625 16.4222 38.8988 52.3457
lr at 26th epoch is 0.0001 for optimizer
current performance: 15.8392, best performance: 18.9953
Epoch: 0026 | TRAIN: 1.0854 0.3105 0.6708 | 0.5190 0.5190 0.2444 | 0.2151 33.2741 29.6718 0.1448 0.3717 0.5088 TEST: 1.3515 0.3387 0.6156 | 0.5798 0.5711 0.7922 | 0.2094 32.5339 38.7696 15.7394 38.9463 52.3193
lr at 27th epoch is 0.0001 for optimizer
current performance: 16.7249, best performance: 18.9953
Epoch: 0027 | TRAIN: 1.0285 0.3218 0.6864 | 0.5318 0.5318 0.2518 | 0.2098 32.7929 29.2107 0.1502 0.3784 0.5153 TEST: 1.2831 0.3613 0.6338 | 0.6457 0.6346 0.8864 | 0.2007 31.8636 37.8356 16.2865 39.6069 53.0261
lr at 28th epoch is 0.0001 for optimizer
current performance: 21.0970, best performance: 18.9953
Epoch: 0028 | TRAIN: 0.9861 0.3327 0.7015 | 0.5020 0.5020 0.2367 | 0.2100 32.7204 28.9816 0.1537 0.3852 0.5198 TEST: 1.2373 0.3697 0.6401 | 0.5696 0.5608 0.7987 | 0.2000 31.7614 37.7797 16.5833 39.8527 53.1660
lr at 29th epoch is 0.0001 for optimizer
current performance: 13.9148, best performance: 21.0970
Epoch: 0029 | TRAIN: 0.9852 0.3309 0.7052 | 0.4856 0.4856 0.2313 | 0.2068 32.3356 28.3975 0.1594 0.3950 0.5302 TEST: 1.3228 0.3547 0.6324 | 0.6604 0.6504 0.9345 | 0.2148 33.0185 39.2905 15.3685 38.5925 51.6314
lr at 30th epoch is 0.0001 for optimizer
current performance: 21.9126, best performance: 21.0970
Epoch: 0030 | TRAIN: 0.9882 0.3351 0.7021 | 0.4945 0.4945 0.2281 | 0.2069 32.4238 28.6887 0.1570 0.3893 0.5258 TEST: 1.2162 0.3782 0.6369 | 0.5686 0.5590 0.8028 | 0.2017 32.0726 37.9589 15.8542 38.6272 52.2189
lr at 31th epoch is 0.0001 for optimizer
current performance: 18.6455, best performance: 21.9126
Epoch: 0031 | TRAIN: 0.9989 0.3403 0.7041 | 0.5024 0.5024 0.2379 | 0.2060 32.3171 28.4427 0.1581 0.3919 0.5287 TEST: 1.3532 0.3497 0.6236 | 0.5551 0.5464 0.7950 | 0.2015 32.2309 37.8747 14.8479 37.8136 51.5338
lr at 32th epoch is 0.0001 for optimizer
current performance: 16.4955, best performance: 21.9126
Epoch: 0032 | TRAIN: 0.9736 0.3405 0.7104 | 0.4876 0.4876 0.2291 | 0.2020 31.8994 28.0211 0.1655 0.4002 0.5364 TEST: 1.4495 0.3330 0.6075 | 0.5780 0.5688 0.7993 | 0.1962 31.3784 37.4413 17.1733 40.4767 53.9505
lr at 33th epoch is 0.0001 for optimizer
current performance: 12.0921, best performance: 21.9126
Epoch: 0033 | TRAIN: 0.9841 0.3385 0.7059 | 0.4889 0.4889 0.2261 | 0.2024 31.9503 28.0280 0.1632 0.3995 0.5364 TEST: 1.2919 0.3540 0.6335 | 0.7449 0.7336 0.9927 | 0.1965 31.3420 37.5029 17.2573 40.9441 54.3760
lr at 34th epoch is 0.0001 for optimizer
current performance: 23.8649, best performance: 21.9126
Epoch: 0034 | TRAIN: 0.9393 0.3515 0.7194 | 0.5003 0.5003 0.2373 | 0.2038 32.0570 28.1198 0.1631 0.3992 0.5346 TEST: 1.2357 0.3853 0.6442 | 0.5487 0.5423 0.7594 | 0.2013 31.7796 37.9488 16.7876 40.0884 53.5191
lr at 35th epoch is 0.0001 for optimizer
current performance: 20.8527, best performance: 23.8649
Epoch: 0035 | TRAIN: 1.0178 0.3393 0.7053 | 0.4768 0.4768 0.2227 | 0.2028 31.9225 27.9060 0.1647 0.4030 0.5394 TEST: 1.3699 0.3593 0.6327 | 0.5521 0.5429 0.7999 | 0.1979 31.4791 37.5539 17.4462 40.0440 53.4531
lr at 36th epoch is 0.0001 for optimizer
current performance: 22.8275, best performance: 23.8649
Epoch: 0036 | TRAIN: 0.9903 0.3461 0.7115 | 0.4903 0.4903 0.2293 | 0.2000 31.6312 27.5290 0.1682 0.4097 0.5460 TEST: 1.3104 0.3831 0.6326 | 0.5498 0.5413 0.7732 | 0.2093 32.5033 38.7480 16.3099 38.8818 52.1349
lr at 37th epoch is 0.0001 for optimizer
current performance: 19.3815, best performance: 23.8649
Epoch: 0037 | TRAIN: 0.9895 0.3550 0.7161 | 0.4874 0.4874 0.2279 | 0.1986 31.5208 27.4564 0.1699 0.4102 0.5464 TEST: 1.3909 0.3637 0.6318 | 0.5998 0.5915 0.8258 | 0.1981 31.4208 37.7124 17.7352 40.8146 54.1098
lr at 38th epoch is 0.0001 for optimizer
current performance: 20.6103, best performance: 23.8649
Epoch: 0038 | TRAIN: 1.0099 0.3464 0.7089 | 0.4742 0.4742 0.2279 | 0.2004 31.6778 27.5798 0.1676 0.4078 0.5449 TEST: 1.3483 0.3550 0.6310 | 0.5473 0.5393 0.7554 | 0.1981 31.3404 37.7162 17.8804 41.5404 54.7199
lr at 39th epoch is 0.0001 for optimizer
current performance: 13.6066, best performance: 23.8649
Epoch: 0039 | TRAIN: 0.9602 0.3543 0.7234 | 0.4701 0.4701 0.2223 | 0.1992 31.4811 27.3362 0.1748 0.4146 0.5491 TEST: 1.3073 0.3686 0.6405 | 0.7539 0.7444 1.0148 | 0.1952 31.2284 37.3349 17.5181 41.1200 54.3942
lr at 40th epoch is 0.0001 for optimizer
current performance: 25.9945, best performance: 23.8649
Epoch: 0040 | TRAIN: 0.9152 0.3597 0.7309 | 0.4764 0.4764 0.2198 | 0.1953 31.2514 27.2671 0.1702 0.4125 0.5506 TEST: 1.2940 0.3955 0.6507 | 0.5402 0.5319 0.7654 | 0.1981 31.4437 37.6594 17.7771 40.6725 53.9491
lr at 41th epoch is 0.0001 for optimizer
current performance: 21.1597, best performance: 25.9945
Epoch: 0041 | TRAIN: 0.9567 0.3577 0.7237 | 0.4561 0.4561 0.2089 | 0.1970 31.2497 27.0736 0.1788 0.4190 0.5534 TEST: 1.3306 0.3690 0.6393 | 0.5858 0.5761 0.8037 | 0.1929 31.0298 37.0967 17.7687 41.2500 54.5958
lr at 42th epoch is 0.0001 for optimizer
current performance: 24.0461, best performance: 25.9945
Epoch: 0042 | TRAIN: 0.9274 0.3701 0.7339 | 0.4742 0.4742 0.2201 | 0.1981 31.4275 27.2682 0.1717 0.4139 0.5502 TEST: 1.3546 0.3942 0.6497 | 0.5881 0.5779 0.8386 | 0.1943 31.2497 37.1942 17.1226 40.4409 53.9620
lr at 43th epoch is 0.0001 for optimizer
current performance: 23.4326, best performance: 25.9945
Epoch: 0043 | TRAIN: 0.9687 0.3621 0.7262 | 0.4585 0.4585 0.2148 | 0.1942 30.9628 26.8008 0.1820 0.4247 0.5588 TEST: 1.3549 0.3744 0.6356 | 0.5469 0.5385 0.7670 | 0.1947 31.0610 37.3152 18.5366 41.5187 54.6532
lr at 44th epoch is 0.0001 for optimizer
current performance: 25.5474, best performance: 25.9945
Epoch: 0044 | TRAIN: 0.9659 0.3649 0.7311 | 0.4812 0.4812 0.2229 | 0.1935 31.0014 26.8027 0.1758 0.4211 0.5581 TEST: 1.3548 0.3879 0.6465 | 0.5395 0.5302 0.7677 | 0.1950 31.0348 37.3898 18.3834 41.8058 55.1606
lr at 45th epoch is 0.0001 for optimizer
current performance: 18.7389, best performance: 25.9945
Epoch: 0045 | TRAIN: 0.9557 0.3705 0.7355 | 0.4524 0.4524 0.2106 | 0.1956 31.0984 26.8632 0.1805 0.4225 0.5566 TEST: 1.4184 0.3348 0.6429 | 0.5516 0.5407 0.7840 | 0.1903 30.6576 36.8240 18.7732 42.1192 55.4007
lr at 46th epoch is 0.0001 for optimizer
current performance: 19.6009, best performance: 25.9945
Epoch: 0046 | TRAIN: 0.9966 0.3580 0.7227 | 0.4445 0.4445 0.2107 | 0.1939 31.0021 26.8702 0.1783 0.4209 0.5582 TEST: 1.4109 0.3476 0.6327 | 0.5468 0.5384 0.7621 | 0.1963 31.4380 37.4122 16.8604 39.9936 53.5807
lr at 47th epoch is 0.0001 for optimizer
current performance: 22.2779, best performance: 25.9945
Epoch: 0047 | TRAIN: 1.0373 0.3462 0.7090 | 0.4636 0.4636 0.2126 | 0.1977 31.4299 27.3939 0.1705 0.4116 0.5492 TEST: 1.4226 0.3632 0.6314 | 0.5446 0.5367 0.7557 | 0.1929 30.8806 37.1350 17.8919 42.2645 55.5999
lr at 48th epoch is 0.0001 for optimizer
current performance: 26.8603, best performance: 25.9945
Epoch: 0048 | TRAIN: 0.9623 0.3610 0.7283 | 0.4356 0.4356 0.2060 | 0.1930 30.8424 26.5681 0.1829 0.4284 0.5626 TEST: 1.2964 0.3946 0.6580 | 0.5429 0.5345 0.7504 | 0.1876 30.4539 36.5563 18.6164 42.3264 55.7946
lr at 49th epoch is 0.0001 for optimizer
current performance: 26.7189, best performance: 26.8603
Epoch: 0049 | TRAIN: 0.9119 0.3760 0.7429 | 0.4389 0.4389 0.2061 | 0.1909 30.5552 26.1049 0.1889 0.4369 0.5707 TEST: 1.2915 0.3947 0.6502 | 0.5392 0.5328 0.7425 | 0.1897 30.6608 36.7607 18.2785 41.7645 55.4374
lr at 50th epoch is 0.0001 for optimizer
current performance: 27.6117, best performance: 26.8603
Epoch: 0050 | TRAIN: 0.9698 0.3653 0.7292 | 0.4426 0.4426 0.2021 | 0.1905 30.5985 26.2633 0.1848 0.4315 0.5678 TEST: 1.3581 0.3935 0.6501 | 0.5160 0.5078 0.7341 | 0.1905 30.6819 36.8753 18.2036 42.1854 55.7421
lr at 51th epoch is 0.0001 for optimizer
current performance: 26.8523, best performance: 27.6117
Epoch: 0051 | TRAIN: 0.9833 0.3629 0.7226 | 0.4505 0.4505 0.2104 | 0.1922 30.8459 26.5690 0.1775 0.4258 0.5629 TEST: 1.3645 0.3887 0.6443 | 0.5252 0.5171 0.7443 | 0.1880 30.4622 36.6359 18.3572 42.7552 56.2251
lr at 52th epoch is 0.0001 for optimizer
current performance: 22.3363, best performance: 27.6117
Epoch: 0052 | TRAIN: 1.0048 0.3584 0.7239 | 0.4468 0.4468 0.2064 | 0.1945 31.0470 26.8460 0.1765 0.4228 0.5594 TEST: 1.4358 0.3618 0.6424 | 0.5541 0.5465 0.7618 | 0.1868 30.2838 36.4874 18.9326 43.1349 56.5224
lr at 53th epoch is 0.0001 for optimizer
current performance: 27.8154, best performance: 27.6117
Epoch: 0053 | TRAIN: 0.9467 0.3739 0.7367 | 0.4407 0.4407 0.2048 | 0.1883 30.3221 25.9213 0.1921 0.4398 0.5734 TEST: 1.3240 0.4011 0.6624 | 0.5406 0.5304 0.7713 | 0.1901 30.4934 36.8895 19.1264 42.9896 56.3304
lr at 54th epoch is 0.0001 for optimizer
current performance: 26.9321, best performance: 27.8154
Epoch: 0054 | TRAIN: 0.9489 0.3762 0.7410 | 0.4414 0.4414 0.2084 | 0.1877 30.3165 25.9461 0.1884 0.4386 0.5744 TEST: 1.3968 0.3891 0.6554 | 0.5284 0.5207 0.7296 | 0.1876 30.2884 36.6466 19.2130 43.3038 56.6910
lr at 55th epoch is 0.0001 for optimizer
current performance: 24.8800, best performance: 27.8154
Epoch: 0055 | TRAIN: 0.9262 0.3777 0.7430 | 0.4452 0.4452 0.2087 | 0.1824 29.7355 25.2457 0.1991 0.4513 0.5863 TEST: 1.3595 0.3812 0.6464 | 0.5416 0.5359 0.7524 | 0.1905 30.6428 36.9620 18.1772 42.7326 56.3513
lr at 56th epoch is 0.0001 for optimizer
current performance: 24.7396, best performance: 27.8154
Epoch: 0056 | TRAIN: 0.9126 0.3804 0.7441 | 0.4338 0.4338 0.2068 | 0.1911 30.5426 26.0584 0.1893 0.4384 0.5725 TEST: 1.3999 0.3793 0.6479 | 0.5331 0.5247 0.7459 | 0.1960 30.9871 37.5404 18.5499 42.5593 55.9079
lr at 57th epoch is 0.0001 for optimizer
current performance: 25.5002, best performance: 27.8154
Epoch: 0057 | TRAIN: 0.9300 0.3777 0.7450 | 0.4395 0.4395 0.2031 | 0.1864 30.1490 25.6325 0.1902 0.4454 0.5800 TEST: 1.3900 0.3776 0.6448 | 0.5298 0.5203 0.7653 | 0.1876 30.2785 36.6649 19.0873 43.6354 56.9365
lr at 58th epoch is 0.0001 for optimizer
current performance: 25.9156, best performance: 27.8154
Epoch: 0058 | TRAIN: 0.9344 0.3821 0.7438 | 0.4251 0.4251 0.1978 | 0.1868 30.1231 25.6131 0.1968 0.4452 0.5783 TEST: 1.3899 0.3807 0.6518 | 0.5320 0.5230 0.7464 | 0.1856 30.1493 36.4263 19.2390 43.3327 56.8865
lr at 59th epoch is 0.0001 for optimizer
current performance: 26.0627, best performance: 27.8154
Epoch: 0059 | TRAIN: 0.9532 0.3726 0.7414 | 0.4275 0.4275 0.1972 | 0.1860 30.0053 25.4722 0.1984 0.4487 0.5823 TEST: 1.4085 0.3865 0.6458 | 0.5388 0.5310 0.7526 | 0.1892 30.3717 36.8622 19.1344 43.9716 57.0510
lr at 60th epoch is 0.0001 for optimizer
current performance: 21.9399, best performance: 27.8154
Epoch: 0060 | TRAIN: 0.9131 0.3825 0.7462 | 0.4435 0.4435 0.2060 | 0.1861 30.1191 25.7266 0.1928 0.4440 0.5790 TEST: 1.4418 0.3578 0.6479 | 0.5511 0.5412 0.7868 | 0.1892 30.3931 36.7709 19.3581 43.4799 56.6946
lr at 61th epoch is 0.0001 for optimizer
current performance: 26.5529, best performance: 27.8154
Epoch: 0061 | TRAIN: 0.9093 0.3878 0.7526 | 0.4355 0.4355 0.2020 | 0.1840 29.8390 25.3865 0.1998 0.4510 0.5849 TEST: 1.2797 0.4069 0.6690 | 0.5981 0.5877 0.8503 | 0.1856 30.0761 36.4443 19.5331 43.7528 57.2208
lr at 62th epoch is 0.0001 for optimizer
current performance: 26.8802, best performance: 27.8154
Epoch: 0062 | TRAIN: 0.9279 0.3873 0.7475 | 0.4452 0.4452 0.2123 | 0.1892 30.3384 25.8840 0.1932 0.4418 0.5759 TEST: 1.3842 0.3850 0.6472 | 0.5196 0.5120 0.7429 | 0.1871 30.2105 36.6069 19.4963 43.6785 56.9924
lr at 63th epoch is 0.0001 for optimizer
current performance: 25.2761, best performance: 27.8154
Epoch: 0063 | TRAIN: 0.9361 0.3802 0.7422 | 0.4531 0.4531 0.2122 | 0.1865 30.0944 25.5845 0.1946 0.4474 0.5817 TEST: 1.4248 0.3784 0.6230 | 0.5304 0.5223 0.7538 | 0.1887 30.4924 36.7394 18.5300 42.7205 56.2036
lr at 64th epoch is 0.0001 for optimizer
current performance: 26.1909, best performance: 27.8154
Epoch: 0064 | TRAIN: 0.9433 0.3840 0.7432 | 0.4267 0.4267 0.1982 | 0.1850 29.8856 25.2682 0.2008 0.4526 0.5850 TEST: 1.4465 0.3816 0.6447 | 0.5312 0.5241 0.7440 | 0.1851 29.9640 36.3915 20.0983 44.1950 57.4146
lr at 65th epoch is 0.0001 for optimizer
current performance: 24.7332, best performance: 27.8154
Epoch: 0065 | TRAIN: 1.0189 0.3713 0.7289 | 0.4369 0.4369 0.2047 | 0.1862 30.0363 25.4261 0.1968 0.4491 0.5824 TEST: 1.4910 0.3664 0.6449 | 0.5197 0.5114 0.7381 | 0.1864 30.0224 36.5774 20.2989 44.4311 57.4753
lr at 66th epoch is 0.0001 for optimizer
current performance: 27.8382, best performance: 27.8154
Epoch: 0066 | TRAIN: 0.9764 0.3722 0.7371 | 0.4273 0.4273 0.1953 | 0.1893 30.3573 25.8265 0.1918 0.4417 0.5770 TEST: 1.3166 0.4070 0.6595 | 0.5688 0.5588 0.7891 | 0.1865 30.0526 36.5996 20.0578 44.2847 57.4080
lr at 67th epoch is 0.0001 for optimizer
current performance: 25.6165, best performance: 27.8382
Epoch: 0067 | TRAIN: 0.9428 0.3876 0.7475 | 0.4285 0.4285 0.1966 | 0.1832 29.6471 24.9679 0.2081 0.4583 0.5898 TEST: 1.4170 0.3790 0.6376 | 0.5333 0.5255 0.7315 | 0.1858 30.1293 36.4682 19.1506 43.6734 57.1245
lr at 68th epoch is 0.0001 for optimizer
current performance: 27.8728, best performance: 27.8382
Epoch: 0068 | TRAIN: 0.8943 0.3956 0.7575 | 0.4140 0.4140 0.1910 | 0.1852 29.9056 25.2953 0.2001 0.4526 0.5854 TEST: 1.3800 0.3907 0.6617 | 0.5195 0.5111 0.7395 | 0.1858 30.0004 36.5274 19.9273 44.6873 57.7260
lr at 69th epoch is 0.0001 for optimizer
current performance: 29.1791, best performance: 27.8728
Epoch: 0069 | TRAIN: 0.9268 0.3882 0.7495 | 0.4214 0.4214 0.1946 | 0.1838 29.7380 25.0488 0.2025 0.4573 0.5907 TEST: 1.3107 0.3994 0.6675 | 0.5242 0.5162 0.7493 | 0.1818 29.6229 36.0590 20.2819 45.1995 58.2847
lr at 70th epoch is 0.0001 for optimizer
current performance: 29.6379, best performance: 29.1791
Epoch: 0070 | TRAIN: 0.8997 0.3974 0.7565 | 0.4211 0.4211 0.1994 | 0.1809 29.4575 24.8732 0.2086 0.4615 0.5928 TEST: 1.3182 0.4008 0.6681 | 0.5197 0.5115 0.7445 | 0.1815 29.5515 36.0218 20.9085 45.1370 58.1916
lr at 71th epoch is 0.0001 for optimizer
current performance: 27.0545, best performance: 29.6379
Epoch: 0071 | TRAIN: 0.9170 0.3936 0.7540 | 0.4251 0.4251 0.1956 | 0.1815 29.4937 24.7972 0.2093 0.4607 0.5926 TEST: 1.4212 0.3872 0.6564 | 0.5131 0.5054 0.7183 | 0.1910 30.5614 37.0061 19.0729 43.2890 56.5380
lr at 72th epoch is 0.0001 for optimizer
current performance: 30.0466, best performance: 29.6379
Epoch: 0072 | TRAIN: 0.9333 0.3963 0.7518 | 0.4215 0.4215 0.1956 | 0.1829 29.6706 25.0490 0.2027 0.4575 0.5912 TEST: 1.2939 0.4060 0.6683 | 0.5248 0.5175 0.7307 | 0.1820 29.5564 36.1064 20.8482 45.2809 58.4737
lr at 73th epoch is 0.0001 for optimizer
current performance: 27.4088, best performance: 30.0466
Epoch: 0073 | TRAIN: 0.9054 0.3940 0.7558 | 0.4054 0.4054 0.1857 | 0.1797 29.2935 24.5664 0.2108 0.4662 0.5985 TEST: 1.3696 0.3877 0.6590 | 0.5346 0.5257 0.7747 | 0.1802 29.5054 35.8398 20.5374 44.8758 58.2104
lr at 74th epoch is 0.0001 for optimizer
current performance: 27.2284, best performance: 30.0466
Epoch: 0074 | TRAIN: 0.9170 0.3916 0.7550 | 0.4134 0.4134 0.1929 | 0.1788 29.2310 24.6215 0.2113 0.4653 0.5985 TEST: 1.3343 0.3945 0.6647 | 0.5465 0.5360 0.7774 | 0.1882 30.0548 36.8108 20.4731 45.0230 58.0416
lr at 75th epoch is 0.0001 for optimizer
current performance: 30.3142, best performance: 30.0466
Epoch: 0075 | TRAIN: 0.9217 0.3898 0.7543 | 0.4198 0.4198 0.1943 | 0.1821 29.5085 24.7239 0.2085 0.4638 0.5954 TEST: 1.2880 0.4151 0.6692 | 0.5431 0.5343 0.7708 | 0.1812 29.7005 35.9306 19.6551 44.3374 57.8364
lr at 76th epoch is 0.0001 for optimizer
current performance: 28.1278, best performance: 30.3142
Epoch: 0076 | TRAIN: 0.9439 0.3905 0.7489 | 0.4182 0.4182 0.1948 | 0.1793 29.2720 24.5463 0.2097 0.4667 0.5985 TEST: 1.3196 0.4015 0.6623 | 0.5506 0.5397 0.7957 | 0.1838 29.9024 36.2410 19.5862 44.2440 57.6566
lr at 77th epoch is 0.0001 for optimizer
current performance: 30.7136, best performance: 30.3142
Epoch: 0077 | TRAIN: 0.9258 0.3879 0.7546 | 0.4120 0.4120 0.1923 | 0.1796 29.3463 24.6645 0.2079 0.4632 0.5955 TEST: 1.3645 0.4104 0.6583 | 0.5324 0.5230 0.7479 | 0.1799 29.2494 35.8922 21.7362 46.3114 59.2153
lr at 78th epoch is 0.0001 for optimizer
current performance: 28.1023, best performance: 30.7136
Epoch: 0078 | TRAIN: 0.9404 0.3882 0.7524 | 0.4241 0.4241 0.1998 | 0.1827 29.5755 24.8217 0.2085 0.4616 0.5927 TEST: 1.3001 0.3981 0.6690 | 0.5442 0.5356 0.7665 | 0.1823 29.6879 36.1160 20.7187 44.4476 57.7230
lr at 79th epoch is 0.0001 for optimizer
current performance: 28.4226, best performance: 30.7136
Epoch: 0079 | TRAIN: 0.9041 0.4027 0.7609 | 0.4111 0.4111 0.1926 | 0.1797 29.3483 24.7457 0.2098 0.4627 0.5952 TEST: 1.3456 0.4082 0.6585 | 0.5701 0.5600 0.7886 | 0.1816 29.6149 36.0190 20.2786 45.0205 58.3788
lr at 80th epoch is 0.0001 for optimizer
current performance: 29.8481, best performance: 30.7136
Epoch: 0080 | TRAIN: 0.9173 0.3974 0.7606 | 0.4116 0.4116 0.1931 | 0.1801 29.2990 24.5596 0.2124 0.4676 0.5988 TEST: 1.4149 0.3953 0.6611 | 0.5117 0.5039 0.7188 | 0.1764 29.0330 35.4702 21.5801 46.2288 59.3323
lr at 81th epoch is 0.0001 for optimizer
current performance: 28.2745, best performance: 30.7136
Epoch: 0081 | TRAIN: 0.9263 0.4010 0.7546 | 0.4177 0.4177 0.1936 | 0.1795 29.2632 24.5698 0.2124 0.4663 0.5984 TEST: 1.3448 0.4008 0.6656 | 0.5584 0.5485 0.8046 | 0.1796 29.3515 35.8345 21.0377 45.5449 58.7829
lr at 82th epoch is 0.0001 for optimizer
current performance: 29.4172, best performance: 30.7136
Epoch: 0082 | TRAIN: 0.9281 0.4024 0.7557 | 0.4108 0.4108 0.1913 | 0.1786 29.1499 24.3044 0.2139 0.4707 0.6024 TEST: 1.3870 0.3938 0.6637 | 0.5096 0.5009 0.7280 | 0.1793 29.3604 35.7786 20.8444 45.5756 58.7029
lr at 83th epoch is 0.0001 for optimizer
current performance: 28.8678, best performance: 30.7136
Epoch: 0083 | TRAIN: 0.9148 0.3908 0.7542 | 0.4001 0.4001 0.1854 | 0.1763 28.9037 24.1728 0.2195 0.4743 0.6057 TEST: 1.4511 0.3896 0.6548 | 0.5130 0.5058 0.7224 | 0.1792 29.1862 35.8062 21.6963 46.3811 59.3120
lr at 84th epoch is 0.0001 for optimizer
current performance: 27.8334, best performance: 30.7136
Epoch: 0084 | TRAIN: 0.9286 0.4023 0.7602 | 0.4093 0.4093 0.1909 | 0.1757 28.8277 24.0327 0.2213 0.4762 0.6067 TEST: 1.4819 0.3883 0.6517 | 0.5215 0.5141 0.7293 | 0.1826 29.6418 36.1262 20.8448 44.7250 57.9277
lr at 85th epoch is 0.0001 for optimizer
current performance: 30.4273, best performance: 30.7136
Epoch: 0085 | TRAIN: 0.9479 0.3943 0.7548 | 0.4143 0.4143 0.1871 | 0.1803 29.3131 24.5946 0.2122 0.4668 0.5987 TEST: 1.3944 0.4036 0.6605 | 0.5137 0.5048 0.7363 | 0.1807 29.4336 35.9493 20.9704 45.6585 58.7455
lr at 86th epoch is 0.0001 for optimizer
current performance: 30.8983, best performance: 30.7136
Epoch: 0086 | TRAIN: 0.9409 0.3966 0.7553 | 0.4193 0.4193 0.1942 | 0.1792 29.2182 24.4831 0.2141 0.4678 0.5996 TEST: 1.4173 0.4029 0.6640 | 0.5012 0.4933 0.7101 | 0.1798 29.3720 35.8494 21.2685 45.4321 58.5889
lr at 87th epoch is 0.0001 for optimizer
current performance: 30.8822, best performance: 30.8983
Epoch: 0087 | TRAIN: 0.9428 0.3973 0.7578 | 0.4136 0.4136 0.1919 | 0.1791 29.1723 24.4169 0.2168 0.4705 0.6010 TEST: 1.4072 0.4060 0.6623 | 0.5085 0.5002 0.7202 | 0.1801 29.4798 35.8457 20.4931 45.1067 58.4719
lr at 88th epoch is 0.0001 for optimizer
current performance: 28.4622, best performance: 30.8983
Epoch: 0088 | TRAIN: 0.9559 0.3968 0.7563 | 0.4147 0.4147 0.1914 | 0.1759 28.9154 24.1550 0.2155 0.4743 0.6065 TEST: 1.4428 0.3881 0.6622 | 0.5248 0.5158 0.7343 | 0.1765 28.9883 35.5314 21.6004 46.7552 59.8203
lr at 89th epoch is 0.0001 for optimizer
current performance: 26.6057, best performance: 30.8983
Epoch: 0089 | TRAIN: 0.9747 0.3901 0.7537 | 0.4126 0.4126 0.1920 | 0.1784 29.1398 24.4524 0.2163 0.4682 0.5992 TEST: 1.5054 0.3789 0.6484 | 0.5323 0.5231 0.7584 | 0.1803 29.3175 35.9355 21.5890 45.9928 59.0870
lr at 90th epoch is 0.0001 for optimizer
current performance: 27.4901, best performance: 30.8983
Epoch: 0090 | TRAIN: 0.9789 0.3945 0.7545 | 0.3983 0.3983 0.1825 | 0.1749 28.7415 23.8644 0.2228 0.4792 0.6096 TEST: 1.4565 0.3869 0.6525 | 0.5320 0.5228 0.7694 | 0.1796 29.4503 35.7851 20.5433 44.9547 58.3434
lr at 91th epoch is 0.0001 for optimizer
current performance: 29.1616, best performance: 30.8983
Epoch: 0091 | TRAIN: 0.9614 0.3913 0.7520 | 0.4003 0.4003 0.1878 | 0.1762 28.9850 24.2564 0.2140 0.4710 0.6037 TEST: 1.4952 0.3920 0.6483 | 0.5132 0.5055 0.7181 | 0.1795 29.2115 35.8502 21.7508 46.2783 59.2392
lr at 92th epoch is 0.0001 for optimizer
current performance: 26.1694, best performance: 30.8983
Epoch: 0092 | TRAIN: 0.9660 0.3832 0.7491 | 0.4194 0.4194 0.1959 | 0.1776 29.0329 24.2533 0.2174 0.4726 0.6037 TEST: 1.4680 0.3813 0.6508 | 0.5282 0.5192 0.7473 | 0.1877 30.1404 36.7981 19.8612 44.5472 57.8055
lr at 93th epoch is 0.0001 for optimizer
current performance: 29.6524, best performance: 30.8983
Epoch: 0093 | TRAIN: 0.9590 0.3871 0.7519 | 0.4166 0.4166 0.1906 | 0.1778 29.1128 24.4760 0.2131 0.4694 0.6012 TEST: 1.4170 0.3986 0.6645 | 0.5139 0.5058 0.7235 | 0.1820 29.5182 36.1668 20.9509 45.7930 58.8418
lr at 94th epoch is 0.0001 for optimizer
current performance: 28.3910, best performance: 30.8983
Epoch: 0094 | TRAIN: 0.9404 0.4028 0.7596 | 0.3924 0.3924 0.1831 | 0.1735 28.6106 23.7566 0.2238 0.4798 0.6117 TEST: 1.4109 0.3909 0.6616 | 0.5185 0.5093 0.7407 | 0.1827 29.6256 36.1605 20.6881 45.2171 58.4607
lr at 95th epoch is 0.0001 for optimizer
current performance: 29.3251, best performance: 30.8983
Epoch: 0095 | TRAIN: 0.9597 0.3963 0.7571 | 0.4049 0.4049 0.1880 | 0.1739 28.6574 23.8510 0.2219 0.4798 0.6115 TEST: 1.4873 0.3898 0.6526 | 0.5107 0.5012 0.7391 | 0.1784 28.9711 35.7707 22.5599 47.1428 59.9970
lr at 96th epoch is 0.0001 for optimizer
current performance: 31.7119, best performance: 30.8983
Epoch: 0096 | TRAIN: 0.9176 0.3965 0.7638 | 0.3903 0.3903 0.1833 | 0.1752 28.7408 23.9068 0.2243 0.4789 0.6095 TEST: 1.4235 0.4125 0.6654 | 0.5236 0.5134 0.7549 | 0.1772 28.9632 35.6300 22.1443 46.7468 59.8069
lr at 97th epoch is 0.0001 for optimizer
current performance: 30.0370, best performance: 31.7119
Epoch: 0097 | TRAIN: 0.8988 0.4053 0.7668 | 0.3948 0.3948 0.1831 | 0.1760 28.8165 23.9461 0.2220 0.4787 0.6091 TEST: 1.3920 0.4048 0.6651 | 0.5256 0.5164 0.7534 | 0.1800 29.4730 35.8855 20.6390 45.0717 58.3804
lr at 98th epoch is 0.0001 for optimizer
current performance: 27.1850, best performance: 31.7119
Epoch: 0098 | TRAIN: 0.9667 0.4033 0.7579 | 0.4047 0.4047 0.1827 | 0.1729 28.5296 23.6135 0.2238 0.4842 0.6164 TEST: 1.5772 0.3827 0.6483 | 0.5285 0.5194 0.7564 | 0.1809 29.3744 36.0143 21.5432 45.7920 58.9503
lr at 99th epoch is 0.0001 for optimizer
current performance: 31.3458, best performance: 31.7119
Epoch: 0099 | TRAIN: 0.9591 0.3935 0.7559 | 0.4015 0.4015 0.1869 | 0.1754 28.7678 23.8866 0.2220 0.4812 0.6101 TEST: 1.3945 0.4080 0.6655 | 0.5073 0.4990 0.7130 | 0.1802 29.3376 35.9066 21.2951 46.0569 59.0218
lr at 100th epoch is 5e-05 for optimizer
current performance: 32.9474, best performance: 31.7119
Epoch: 0100 | TRAIN: 0.8992 0.4206 0.7726 | 0.3755 0.3755 0.1697 | 0.1689 28.0593 23.0741 0.2345 0.4948 0.6240 TEST: 1.3727 0.4173 0.6764 | 0.5100 0.5016 0.7316 | 0.1755 28.8582 35.4133 22.0966 46.6752 59.8206
lr at 101th epoch is 5e-05 for optimizer
current performance: 33.2549, best performance: 32.9474
Epoch: 0101 | TRAIN: 0.8848 0.4217 0.7757 | 0.3666 0.3666 0.1690 | 0.1663 27.7699 22.7863 0.2405 0.5005 0.6296 TEST: 1.3546 0.4185 0.6761 | 0.5075 0.4984 0.7299 | 0.1744 28.8393 35.2850 21.7870 46.3825 59.7329
lr at 102th epoch is 5e-05 for optimizer
current performance: 34.5569, best performance: 33.2549
Epoch: 0102 | TRAIN: 0.8687 0.4252 0.7756 | 0.3642 0.3642 0.1681 | 0.1684 27.9653 22.9533 0.2397 0.4970 0.6252 TEST: 1.3711 0.4229 0.6777 | 0.4959 0.4879 0.7095 | 0.1737 28.5814 35.2511 22.8855 47.5076 60.4944
lr at 103th epoch is 5e-05 for optimizer
current performance: 35.7086, best performance: 34.5569
Epoch: 0103 | TRAIN: 0.8747 0.4286 0.7815 | 0.3594 0.3594 0.1644 | 0.1668 27.7284 22.7041 0.2464 0.5026 0.6300 TEST: 1.3767 0.4261 0.6794 | 0.4811 0.4732 0.6890 | 0.1735 28.4916 35.2364 23.3017 47.8517 60.7660
lr at 104th epoch is 5e-05 for optimizer
current performance: 35.1236, best performance: 35.7086
Epoch: 0104 | TRAIN: 0.8822 0.4377 0.7842 | 0.3584 0.3584 0.1627 | 0.1663 27.7155 22.7071 0.2445 0.5023 0.6308 TEST: 1.3720 0.4236 0.6793 | 0.4840 0.4758 0.6908 | 0.1737 28.6227 35.2246 22.4632 47.4434 60.4903
lr at 105th epoch is 5e-05 for optimizer
current performance: 34.3644, best performance: 35.7086
Epoch: 0105 | TRAIN: 0.8579 0.4298 0.7848 | 0.3599 0.3599 0.1640 | 0.1652 27.6178 22.6508 0.2446 0.5039 0.6331 TEST: 1.3890 0.4255 0.6785 | 0.5069 0.4983 0.7258 | 0.1737 28.6546 35.2273 22.6513 47.1027 60.0839
lr at 106th epoch is 5e-05 for optimizer
current performance: 34.2624, best performance: 35.7086
Epoch: 0106 | TRAIN: 0.8789 0.4318 0.7841 | 0.3532 0.3532 0.1648 | 0.1665 27.7269 22.6536 0.2462 0.5023 0.6295 TEST: 1.4116 0.4219 0.6760 | 0.4975 0.4895 0.7122 | 0.1735 28.6694 35.2155 22.2969 47.1873 60.2158
lr at 107th epoch is 5e-05 for optimizer
current performance: 33.9111, best performance: 35.7086
Epoch: 0107 | TRAIN: 0.8988 0.4254 0.7778 | 0.3557 0.3557 0.1639 | 0.1644 27.5169 22.4928 0.2477 0.5069 0.6342 TEST: 1.4402 0.4159 0.6731 | 0.4910 0.4833 0.6958 | 0.1741 28.5448 35.2954 23.2678 47.8867 60.6984
lr at 108th epoch is 5e-05 for optimizer
current performance: 35.5547, best performance: 35.7086
Epoch: 0108 | TRAIN: 0.8921 0.4279 0.7800 | 0.3581 0.3581 0.1651 | 0.1680 27.8268 22.7461 0.2453 0.5025 0.6295 TEST: 1.3939 0.4272 0.6821 | 0.4875 0.4796 0.7011 | 0.1734 28.5066 35.2276 23.1000 47.9322 60.7807
lr at 109th epoch is 5e-05 for optimizer
current performance: 35.3753, best performance: 35.7086
Epoch: 0109 | TRAIN: 0.9123 0.4236 0.7808 | 0.3494 0.3494 0.1624 | 0.1658 27.6957 22.7437 0.2438 0.5019 0.6305 TEST: 1.3929 0.4256 0.6774 | 0.4849 0.4771 0.6920 | 0.1746 28.5788 35.3579 23.2500 47.9201 60.7201
lr at 110th epoch is 5e-05 for optimizer
current performance: 33.8889, best performance: 35.7086
Epoch: 0110 | TRAIN: 0.8942 0.4265 0.7826 | 0.3538 0.3538 0.1607 | 0.1647 27.5037 22.4545 0.2501 0.5079 0.6344 TEST: 1.3962 0.4234 0.6791 | 0.5115 0.5024 0.7383 | 0.1736 28.6810 35.2022 22.4052 46.8924 60.0488
lr at 111th epoch is 5e-05 for optimizer
current performance: 35.2769, best performance: 35.7086
Epoch: 0111 | TRAIN: 0.9108 0.4293 0.7805 | 0.3716 0.3716 0.1714 | 0.1671 27.8273 22.8636 0.2420 0.4987 0.6278 TEST: 1.3989 0.4276 0.6822 | 0.4864 0.4784 0.6996 | 0.1761 28.8509 35.5023 22.2385 47.1956 60.1977
lr at 112th epoch is 5e-05 for optimizer
current performance: 36.0790, best performance: 35.7086
Epoch: 0112 | TRAIN: 0.8848 0.4333 0.7848 | 0.3683 0.3683 0.1681 | 0.1653 27.5721 22.4814 0.2495 0.5066 0.6327 TEST: 1.3944 0.4289 0.6804 | 0.4862 0.4780 0.7025 | 0.1708 28.2870 34.9593 23.3169 48.2984 61.1791
lr at 113th epoch is 5e-05 for optimizer
current performance: 34.3772, best performance: 36.0790
Epoch: 0113 | TRAIN: 0.8869 0.4331 0.7853 | 0.3611 0.3611 0.1654 | 0.1644 27.4672 22.2877 0.2510 0.5097 0.6355 TEST: 1.4514 0.4158 0.6759 | 0.4827 0.4742 0.6915 | 0.1718 28.4631 35.0278 22.8986 47.4615 60.5116
lr at 114th epoch is 5e-05 for optimizer
current performance: 35.6667, best performance: 36.0790
Epoch: 0114 | TRAIN: 0.8771 0.4364 0.7879 | 0.3547 0.3547 0.1621 | 0.1638 27.4108 22.4365 0.2517 0.5093 0.6360 TEST: 1.3763 0.4309 0.6838 | 0.4930 0.4848 0.7036 | 0.1744 28.6300 35.3124 22.8447 47.5943 60.4717
lr at 115th epoch is 5e-05 for optimizer
current performance: 35.8488, best performance: 36.0790
Epoch: 0115 | TRAIN: 0.8662 0.4356 0.7878 | 0.3532 0.3532 0.1628 | 0.1642 27.4427 22.3900 0.2516 0.5091 0.6359 TEST: 1.4031 0.4259 0.6828 | 0.4835 0.4755 0.6913 | 0.1706 28.2519 34.9443 23.3205 48.5682 61.3451
lr at 116th epoch is 5e-05 for optimizer
current performance: 35.2386, best performance: 36.0790
Epoch: 0116 | TRAIN: 0.8913 0.4378 0.7852 | 0.3578 0.3578 0.1653 | 0.1631 27.2905 22.1919 0.2556 0.5132 0.6388 TEST: 1.4360 0.4244 0.6813 | 0.4970 0.4877 0.7165 | 0.1705 28.1553 34.9405 23.9421 48.7433 61.5237
lr at 117th epoch is 5e-05 for optimizer
current performance: 35.4822, best performance: 36.0790
Epoch: 0117 | TRAIN: 0.9029 0.4363 0.7822 | 0.3601 0.3601 0.1655 | 0.1646 27.5205 22.4317 0.2484 0.5074 0.6351 TEST: 1.4332 0.4258 0.6819 | 0.4886 0.4799 0.7048 | 0.1725 28.3941 35.1369 23.2937 48.3377 61.1076
lr at 118th epoch is 5e-05 for optimizer
current performance: 35.3820, best performance: 36.0790
Epoch: 0118 | TRAIN: 0.9073 0.4305 0.7850 | 0.3639 0.3639 0.1634 | 0.1634 27.3544 22.2377 0.2528 0.5111 0.6381 TEST: 1.4252 0.4225 0.6801 | 0.4841 0.4761 0.6994 | 0.1710 28.2566 34.9934 23.5156 48.5564 61.3997
lr at 119th epoch is 5e-05 for optimizer
current performance: 35.0050, best performance: 36.0790
Epoch: 0119 | TRAIN: 0.9187 0.4292 0.7805 | 0.3532 0.3532 0.1642 | 0.1650 27.5078 22.4046 0.2506 0.5092 0.6362 TEST: 1.4485 0.4233 0.6824 | 0.4916 0.4831 0.7077 | 0.1713 28.4125 34.9833 22.8600 47.6213 60.7233
lr at 120th epoch is 5e-05 for optimizer
current performance: 34.8904, best performance: 36.0790
Epoch: 0120 | TRAIN: 0.9065 0.4363 0.7846 | 0.3594 0.3594 0.1643 | 0.1644 27.4194 22.2692 0.2534 0.5112 0.6375 TEST: 1.4505 0.4191 0.6792 | 0.4903 0.4814 0.7014 | 0.1687 28.0945 34.6933 23.5856 48.2692 61.3211
lr at 121th epoch is 5e-05 for optimizer
current performance: 35.6471, best performance: 36.0790
Epoch: 0121 | TRAIN: 0.8904 0.4338 0.7870 | 0.3513 0.3513 0.1627 | 0.1627 27.2713 22.1643 0.2552 0.5125 0.6386 TEST: 1.4047 0.4258 0.6847 | 0.4905 0.4821 0.7102 | 0.1696 28.1561 34.8232 23.5629 48.4121 61.3680
lr at 122th epoch is 5e-05 for optimizer
current performance: 36.1173, best performance: 36.0790
Epoch: 0122 | TRAIN: 0.8876 0.4353 0.7856 | 0.3569 0.3569 0.1626 | 0.1634 27.3308 22.2469 0.2548 0.5125 0.6377 TEST: 1.4454 0.4282 0.6851 | 0.4857 0.4778 0.6951 | 0.1701 28.1804 34.9024 23.6171 48.5145 61.4347
lr at 123th epoch is 5e-05 for optimizer
current performance: 34.9283, best performance: 36.1173
Epoch: 0123 | TRAIN: 0.9060 0.4374 0.7858 | 0.3559 0.3559 0.1621 | 0.1635 27.3617 22.2429 0.2524 0.5120 0.6381 TEST: 1.4569 0.4222 0.6785 | 0.4952 0.4868 0.7088 | 0.1699 28.2170 34.8516 23.2062 48.1254 61.2779
lr at 124th epoch is 5e-05 for optimizer
current performance: 35.2351, best performance: 36.1173
Epoch: 0124 | TRAIN: 0.9223 0.4287 0.7799 | 0.3557 0.3557 0.1645 | 0.1623 27.2188 22.0486 0.2558 0.5156 0.6407 TEST: 1.4312 0.4273 0.6834 | 0.5066 0.4972 0.7281 | 0.1699 28.1135 34.8851 23.8109 48.8840 61.6550
lr at 125th epoch is 5e-05 for optimizer
current performance: 34.6852, best performance: 36.1173
Epoch: 0125 | TRAIN: 0.8938 0.4283 0.7866 | 0.3493 0.3493 0.1618 | 0.1616 27.1217 21.9863 0.2593 0.5166 0.6421 TEST: 1.4591 0.4235 0.6813 | 0.5011 0.4933 0.7072 | 0.1709 28.3325 34.9441 23.1385 47.8436 60.8917
lr at 126th epoch is 5e-05 for optimizer
current performance: 34.9575, best performance: 36.1173
Epoch: 0126 | TRAIN: 0.8858 0.4367 0.7909 | 0.3497 0.3497 0.1605 | 0.1610 27.0484 21.7820 0.2598 0.5199 0.6451 TEST: 1.4699 0.4203 0.6765 | 0.4901 0.4817 0.7024 | 0.1697 28.1594 34.8346 23.3442 48.5753 61.5395
lr at 127th epoch is 5e-05 for optimizer
current performance: 35.6074, best performance: 36.1173
Epoch: 0127 | TRAIN: 0.9044 0.4360 0.7839 | 0.3489 0.3489 0.1598 | 0.1616 27.0915 21.9018 0.2596 0.5186 0.6448 TEST: 1.4157 0.4249 0.6830 | 0.4882 0.4793 0.7103 | 0.1703 28.2031 34.9255 23.3409 48.4381 61.4784
lr at 128th epoch is 5e-05 for optimizer
current performance: 35.0860, best performance: 36.1173
Epoch: 0128 | TRAIN: 0.9243 0.4334 0.7862 | 0.3490 0.3490 0.1592 | 0.1615 27.0951 21.9961 0.2601 0.5185 0.6433 TEST: 1.4339 0.4195 0.6823 | 0.4859 0.4773 0.7025 | 0.1704 28.1287 34.9288 24.0184 48.7275 61.5532
lr at 129th epoch is 5e-05 for optimizer
current performance: 34.7052, best performance: 36.1173
Epoch: 0129 | TRAIN: 0.9208 0.4288 0.7828 | 0.3556 0.3556 0.1622 | 0.1618 27.1157 21.9774 0.2600 0.5181 0.6427 TEST: 1.4627 0.4237 0.6818 | 0.5013 0.4915 0.7359 | 0.1724 28.4027 35.1290 23.3327 48.0824 60.9790
lr at 130th epoch is 5e-05 for optimizer
current performance: 36.1574, best performance: 36.1173
Epoch: 0130 | TRAIN: 0.8994 0.4357 0.7892 | 0.3494 0.3494 0.1587 | 0.1641 27.3997 22.3603 0.2541 0.5110 0.6368 TEST: 1.4615 0.4260 0.6799 | 0.4811 0.4733 0.6839 | 0.1691 28.0733 34.7496 23.8835 48.4911 61.4019
lr at 131th epoch is 5e-05 for optimizer
current performance: 34.9891, best performance: 36.1574
Epoch: 0131 | TRAIN: 0.9327 0.4388 0.7869 | 0.3480 0.3480 0.1596 | 0.1623 27.1823 21.9721 0.2589 0.5157 0.6411 TEST: 1.4938 0.4201 0.6814 | 0.4899 0.4812 0.7073 | 0.1701 28.1366 34.9117 23.7042 48.7707 61.6309
lr at 132th epoch is 5e-05 for optimizer
current performance: 35.3678, best performance: 36.1574
Epoch: 0132 | TRAIN: 0.9289 0.4389 0.7888 | 0.3479 0.3479 0.1589 | 0.1610 27.0831 21.9548 0.2598 0.5162 0.6420 TEST: 1.4748 0.4277 0.6798 | 0.4993 0.4900 0.7334 | 0.1716 28.3233 35.0855 23.1765 48.4300 61.3898
lr at 133th epoch is 5e-05 for optimizer
current performance: 35.7237, best performance: 36.1574
Epoch: 0133 | TRAIN: 0.9046 0.4416 0.7882 | 0.3570 0.3570 0.1633 | 0.1626 27.2097 22.0135 0.2587 0.5167 0.6410 TEST: 1.4650 0.4242 0.6822 | 0.4788 0.4710 0.6824 | 0.1718 28.3451 35.0960 22.9767 48.7355 61.5282
lr at 134th epoch is 5e-05 for optimizer
current performance: 36.6464, best performance: 36.1574
Epoch: 0134 | TRAIN: 0.9334 0.4339 0.7833 | 0.3460 0.3460 0.1566 | 0.1615 27.0605 21.8910 0.2606 0.5201 0.6452 TEST: 1.4322 0.4332 0.6852 | 0.4901 0.4813 0.7043 | 0.1702 28.1394 34.9044 23.6660 48.7869 61.6627
lr at 135th epoch is 5e-05 for optimizer
current performance: 35.7857, best performance: 36.6464
Epoch: 0135 | TRAIN: 0.9401 0.4397 0.7869 | 0.3477 0.3477 0.1577 | 0.1609 27.0025 21.7075 0.2613 0.5217 0.6472 TEST: 1.4800 0.4239 0.6837 | 0.4831 0.4747 0.6899 | 0.1693 28.1032 34.7800 23.6078 48.6225 61.5304
lr at 136th epoch is 5e-05 for optimizer
current performance: 36.2578, best performance: 36.6464
Epoch: 0136 | TRAIN: 0.9141 0.4362 0.7876 | 0.3460 0.3460 0.1558 | 0.1613 27.0448 21.8142 0.2615 0.5207 0.6453 TEST: 1.4551 0.4286 0.6831 | 0.4838 0.4753 0.7032 | 0.1705 28.2000 34.9526 23.5651 48.5563 61.4554
lr at 137th epoch is 5e-05 for optimizer
current performance: 35.3942, best performance: 36.6464
Epoch: 0137 | TRAIN: 0.9107 0.4350 0.7876 | 0.3581 0.3581 0.1618 | 0.1613 27.0660 21.9442 0.2603 0.5195 0.6443 TEST: 1.4364 0.4257 0.6823 | 0.4990 0.4899 0.7310 | 0.1695 28.0769 34.8207 23.9289 48.8131 61.6398
lr at 138th epoch is 5e-05 for optimizer
current performance: 35.7857, best performance: 36.6464
Epoch: 0138 | TRAIN: 0.8927 0.4333 0.7911 | 0.3450 0.3450 0.1588 | 0.1599 26.9120 21.6481 0.2635 0.5233 0.6475 TEST: 1.4696 0.4282 0.6846 | 0.4940 0.4851 0.7190 | 0.1709 28.1948 35.0014 23.4259 49.0330 61.8731
lr at 139th epoch is 5e-05 for optimizer
current performance: 35.9704, best performance: 36.6464
Epoch: 0139 | TRAIN: 0.9300 0.4336 0.7858 | 0.3504 0.3504 0.1611 | 0.1594 26.9097 21.7346 0.2609 0.5209 0.6470 TEST: 1.4510 0.4254 0.6814 | 0.4842 0.4758 0.7029 | 0.1687 28.0702 34.7174 23.5566 48.5812 61.5603
lr at 140th epoch is 5e-05 for optimizer
current performance: 36.0556, best performance: 36.6464
Epoch: 0140 | TRAIN: 0.9240 0.4313 0.7848 | 0.3493 0.3493 0.1624 | 0.1615 27.0560 21.7948 0.2622 0.5213 0.6449 TEST: 1.4530 0.4328 0.6856 | 0.4993 0.4902 0.7161 | 0.1712 28.2823 34.9923 23.6543 48.0741 61.0088
lr at 141th epoch is 5e-05 for optimizer
current performance: 35.6720, best performance: 36.6464
Epoch: 0141 | TRAIN: 0.9306 0.4319 0.7863 | 0.3485 0.3485 0.1578 | 0.1616 27.0688 21.8201 0.2622 0.5197 0.6443 TEST: 1.4936 0.4273 0.6817 | 0.4984 0.4886 0.7306 | 0.1695 28.0560 34.8525 23.8395 48.9850 61.9213
lr at 142th epoch is 5e-05 for optimizer
current performance: 36.6628, best performance: 36.6464
Epoch: 0142 | TRAIN: 0.8833 0.4386 0.7915 | 0.3527 0.3527 0.1562 | 0.1589 26.7834 21.6344 0.2670 0.5247 0.6488 TEST: 1.4725 0.4278 0.6869 | 0.4772 0.4692 0.6852 | 0.1684 27.9745 34.7098 23.7286 49.0612 62.0956
lr at 143th epoch is 5e-05 for optimizer
current performance: 35.3617, best performance: 36.6628
Epoch: 0143 | TRAIN: 0.9005 0.4358 0.7900 | 0.3537 0.3537 0.1599 | 0.1591 26.7852 21.5280 0.2671 0.5255 0.6499 TEST: 1.5063 0.4230 0.6799 | 0.4877 0.4815 0.6818 | 0.1687 28.1214 34.6879 23.2633 48.2273 61.3883
lr at 144th epoch is 5e-05 for optimizer
current performance: 36.8987, best performance: 36.6628
Epoch: 0144 | TRAIN: 0.9208 0.4374 0.7863 | 0.3509 0.3509 0.1602 | 0.1579 26.7178 21.5621 0.2669 0.5255 0.6499 TEST: 1.4308 0.4320 0.6844 | 0.4872 0.4777 0.7068 | 0.1681 27.9146 34.6642 24.2022 49.2040 61.9686
lr at 145th epoch is 5e-05 for optimizer
current performance: 35.4131, best performance: 36.8987
Epoch: 0145 | TRAIN: 0.9193 0.4307 0.7861 | 0.3473 0.3473 0.1581 | 0.1588 26.7576 21.5165 0.2676 0.5262 0.6506 TEST: 1.4946 0.4217 0.6796 | 0.4858 0.4766 0.7055 | 0.1686 28.1125 34.7008 23.2645 48.4629 61.4727
lr at 146th epoch is 5e-05 for optimizer
current performance: 35.9893, best performance: 36.8987
Epoch: 0146 | TRAIN: 0.8955 0.4315 0.7904 | 0.3474 0.3474 0.1610 | 0.1597 26.8592 21.6326 0.2656 0.5243 0.6484 TEST: 1.4755 0.4266 0.6851 | 0.4898 0.4800 0.7124 | 0.1696 28.0298 34.8570 23.9833 49.3331 62.0919
lr at 147th epoch is 5e-05 for optimizer
current performance: 36.4136, best performance: 36.8987
Epoch: 0147 | TRAIN: 0.9520 0.4355 0.7859 | 0.3505 0.3505 0.1599 | 0.1582 26.7102 21.5080 0.2674 0.5266 0.6515 TEST: 1.5275 0.4275 0.6832 | 0.4828 0.4738 0.7000 | 0.1693 27.9865 34.7872 24.2774 49.1055 61.8871
lr at 148th epoch is 5e-05 for optimizer
current performance: 36.8490, best performance: 36.8987
Epoch: 0148 | TRAIN: 0.9540 0.4399 0.7875 | 0.3454 0.3454 0.1600 | 0.1597 26.8123 21.5215 0.2683 0.5261 0.6498 TEST: 1.5057 0.4276 0.6868 | 0.4725 0.4651 0.6726 | 0.1679 27.9482 34.6236 24.0231 48.8391 61.7319
lr at 149th epoch is 5e-05 for optimizer
current performance: 35.5166, best performance: 36.8987
Epoch: 0149 | TRAIN: 0.9324 0.4333 0.7879 | 0.3536 0.3536 0.1610 | 0.1588 26.7315 21.4759 0.2688 0.5287 0.6518 TEST: 1.5342 0.4221 0.6801 | 0.4863 0.4781 0.6989 | 0.1700 28.0091 34.9594 23.9214 49.7087 62.5392
lr at 150th epoch is 5e-05 for optimizer
current performance: 36.7946, best performance: 36.8987
Epoch: 0150 | TRAIN: 0.9455 0.4322 0.7893 | 0.3540 0.3540 0.1614 | 0.1580 26.6631 21.3765 0.2690 0.5291 0.6529 TEST: 1.4962 0.4302 0.6839 | 0.4816 0.4729 0.6897 | 0.1686 27.9950 34.7677 23.7108 49.2273 62.1255
lr at 151th epoch is 5e-05 for optimizer
current performance: 36.4098, best performance: 36.8987
Epoch: 0151 | TRAIN: 0.9449 0.4394 0.7871 | 0.3481 0.3481 0.1617 | 0.1571 26.6229 21.4723 0.2692 0.5273 0.6513 TEST: 1.4893 0.4320 0.6850 | 0.4934 0.4842 0.7171 | 0.1695 28.1014 34.8345 23.7289 48.6868 61.6008
lr at 152th epoch is 5e-05 for optimizer
current performance: 37.1914, best performance: 36.8987
Epoch: 0152 | TRAIN: 0.9272 0.4437 0.7906 | 0.3507 0.3507 0.1599 | 0.1581 26.6806 21.4025 0.2698 0.5283 0.6517 TEST: 1.4733 0.4331 0.6883 | 0.4786 0.4703 0.6878 | 0.1683 28.0673 34.6543 23.5892 48.3579 61.3017
lr at 153th epoch is 5e-05 for optimizer
current performance: 36.1084, best performance: 37.1914
Epoch: 0153 | TRAIN: 0.9256 0.4380 0.7913 | 0.3415 0.3415 0.1595 | 0.1583 26.6643 21.4099 0.2698 0.5294 0.6538 TEST: 1.5072 0.4276 0.6844 | 0.4903 0.4817 0.7057 | 0.1690 27.9705 34.7761 24.2274 49.1847 61.9591
lr at 154th epoch is 5e-05 for optimizer
current performance: 35.7745, best performance: 37.1914
Epoch: 0154 | TRAIN: 0.9542 0.4400 0.7882 | 0.3518 0.3518 0.1630 | 0.1582 26.6550 21.3624 0.2699 0.5302 0.6540 TEST: 1.4962 0.4260 0.6828 | 0.4905 0.4810 0.7130 | 0.1701 28.1069 34.9001 23.8087 48.9014 61.8314
lr at 155th epoch is 5e-05 for optimizer
current performance: 36.3171, best performance: 37.1914
Epoch: 0155 | TRAIN: 0.9429 0.4327 0.7856 | 0.3503 0.3503 0.1599 | 0.1602 26.8972 21.6770 0.2651 0.5240 0.6480 TEST: 1.5059 0.4261 0.6829 | 0.4841 0.4751 0.7003 | 0.1675 27.8597 34.6094 24.2196 49.2942 62.1157
lr at 156th epoch is 5e-05 for optimizer
current performance: 37.8461, best performance: 37.1914
Epoch: 0156 | TRAIN: 0.9116 0.4357 0.7923 | 0.3483 0.3483 0.1571 | 0.1587 26.7183 21.4604 0.2681 0.5280 0.6525 TEST: 1.4817 0.4343 0.6883 | 0.4730 0.4645 0.6840 | 0.1674 27.8440 34.6059 24.2842 49.2117 62.0842
lr at 157th epoch is 5e-05 for optimizer
current performance: 36.9811, best performance: 37.8461
Epoch: 0157 | TRAIN: 0.9466 0.4367 0.7863 | 0.3396 0.3396 0.1553 | 0.1591 26.7241 21.3197 0.2708 0.5304 0.6522 TEST: 1.5148 0.4304 0.6884 | 0.4830 0.4741 0.6969 | 0.1685 27.8021 34.7764 24.8260 49.8571 62.5739
lr at 158th epoch is 5e-05 for optimizer
current performance: 37.2245, best performance: 37.8461
Epoch: 0158 | TRAIN: 0.9386 0.4352 0.7890 | 0.3522 0.3522 0.1593 | 0.1579 26.6711 21.4707 0.2682 0.5276 0.6521 TEST: 1.5047 0.4315 0.6869 | 0.4745 0.4664 0.6791 | 0.1694 28.0130 34.8180 24.1336 49.1172 61.9698
lr at 159th epoch is 5e-05 for optimizer
current performance: 36.3489, best performance: 37.8461
Epoch: 0159 | TRAIN: 0.9095 0.4341 0.7921 | 0.3407 0.3407 0.1578 | 0.1592 26.7504 21.4419 0.2698 0.5278 0.6518 TEST: 1.4859 0.4277 0.6881 | 0.4900 0.4805 0.7162 | 0.1674 27.8116 34.6064 24.4926 49.4613 62.2293
lr at 160th epoch is 5e-05 for optimizer
current performance: 37.6994, best performance: 37.8461
Epoch: 0160 | TRAIN: 0.9276 0.4327 0.7872 | 0.3469 0.3469 0.1586 | 0.1580 26.6409 21.2993 0.2700 0.5304 0.6545 TEST: 1.4551 0.4377 0.6887 | 0.4822 0.4736 0.6960 | 0.1687 28.0054 34.7403 23.9915 48.9010 61.7997
lr at 161th epoch is 5e-05 for optimizer
current performance: 36.9226, best performance: 37.8461
Epoch: 0161 | TRAIN: 0.9093 0.4452 0.7915 | 0.3512 0.3512 0.1597 | 0.1569 26.5155 21.2479 0.2728 0.5325 0.6568 TEST: 1.5006 0.4314 0.6878 | 0.4832 0.4750 0.6929 | 0.1690 27.9318 34.8110 24.4158 49.3694 62.1524
lr at 162th epoch is 5e-05 for optimizer
current performance: 36.3234, best performance: 37.8461
Epoch: 0162 | TRAIN: 0.9238 0.4369 0.7927 | 0.3442 0.3442 0.1567 | 0.1561 26.4568 21.2012 0.2713 0.5346 0.6582 TEST: 1.4929 0.4318 0.6860 | 0.4949 0.4860 0.7119 | 0.1695 28.0933 34.8305 23.8902 48.6455 61.5613
lr at 163th epoch is 5e-05 for optimizer
current performance: 34.8511, best performance: 37.8461
Epoch: 0163 | TRAIN: 0.9479 0.4311 0.7877 | 0.3408 0.3408 0.1569 | 0.1584 26.6556 21.4442 0.2710 0.5309 0.6538 TEST: 1.5428 0.4180 0.6772 | 0.4811 0.4728 0.6944 | 0.1709 28.3385 34.9516 22.9873 47.9264 60.9975
lr at 164th epoch is 5e-05 for optimizer
current performance: 35.9762, best performance: 37.8461
Epoch: 0164 | TRAIN: 0.9564 0.4316 0.7819 | 0.3460 0.3460 0.1583 | 0.1569 26.5270 21.2184 0.2723 0.5319 0.6558 TEST: 1.5041 0.4269 0.6868 | 0.4936 0.4847 0.7106 | 0.1690 27.8888 34.8145 24.6139 49.7021 62.3419
lr at 165th epoch is 5e-05 for optimizer
current performance: 36.8291, best performance: 37.8461
Epoch: 0165 | TRAIN: 0.9383 0.4389 0.7903 | 0.3439 0.3439 0.1589 | 0.1588 26.7247 21.4719 0.2686 0.5288 0.6528 TEST: 1.4775 0.4286 0.6866 | 0.4791 0.4703 0.6984 | 0.1693 27.8740 34.8562 24.7397 49.8567 62.4937
lr at 166th epoch is 5e-05 for optimizer
current performance: 36.2454, best performance: 37.8461
Epoch: 0166 | TRAIN: 0.9342 0.4430 0.7916 | 0.3430 0.3430 0.1559 | 0.1570 26.4938 21.1149 0.2737 0.5349 0.6574 TEST: 1.5189 0.4264 0.6859 | 0.4865 0.4778 0.7069 | 0.1682 27.8540 34.7321 24.3689 49.6285 62.3745
lr at 167th epoch is 5e-05 for optimizer
current performance: 36.0719, best performance: 37.8461
Epoch: 0167 | TRAIN: 0.9321 0.4390 0.7922 | 0.3473 0.3473 0.1552 | 0.1581 26.6264 21.4217 0.2729 0.5309 0.6533 TEST: 1.5061 0.4302 0.6886 | 0.5019 0.4920 0.7370 | 0.1679 27.8988 34.6720 24.1995 49.2174 62.0504
lr at 168th epoch is 5e-05 for optimizer
current performance: 36.9604, best performance: 37.8461
Epoch: 0168 | TRAIN: 0.9352 0.4418 0.7902 | 0.3457 0.3457 0.1589 | 0.1573 26.5671 21.2251 0.2706 0.5324 0.6564 TEST: 1.4958 0.4318 0.6844 | 0.4812 0.4727 0.7003 | 0.1690 28.0329 34.8031 23.6621 48.9517 61.9947
lr at 169th epoch is 5e-05 for optimizer
current performance: 37.0872, best performance: 37.8461
Epoch: 0169 | TRAIN: 0.9541 0.4421 0.7908 | 0.3482 0.3482 0.1601 | 0.1567 26.4797 21.1660 0.2742 0.5335 0.6567 TEST: 1.5031 0.4290 0.6872 | 0.4775 0.4693 0.6785 | 0.1673 27.7257 34.6310 24.6694 49.9933 62.7377
lr at 170th epoch is 5e-05 for optimizer
current performance: 37.0771, best performance: 37.8461
Epoch: 0170 | TRAIN: 0.9354 0.4419 0.7915 | 0.3405 0.3405 0.1558 | 0.1556 26.3807 21.1492 0.2770 0.5341 0.6576 TEST: 1.4983 0.4308 0.6874 | 0.4860 0.4773 0.7051 | 0.1662 27.6290 34.5119 24.6962 50.2172 62.9581
lr at 171th epoch is 5e-05 for optimizer
current performance: 37.0636, best performance: 37.8461
Epoch: 0171 | TRAIN: 0.9138 0.4408 0.7944 | 0.3479 0.3479 0.1587 | 0.1561 26.4136 21.0921 0.2756 0.5347 0.6579 TEST: 1.5306 0.4300 0.6857 | 0.4805 0.4726 0.6924 | 0.1669 27.7369 34.5543 24.5737 49.7207 62.4846
lr at 172th epoch is 5e-05 for optimizer
current performance: 34.7088, best performance: 37.8461
Epoch: 0172 | TRAIN: 0.9277 0.4453 0.7939 | 0.3480 0.3480 0.1601 | 0.1582 26.6282 21.4057 0.2727 0.5306 0.6537 TEST: 1.5183 0.4148 0.6864 | 0.4894 0.4800 0.7180 | 0.1684 27.8286 34.7645 24.6072 49.8120 62.5501
lr at 173th epoch is 5e-05 for optimizer
current performance: 37.7186, best performance: 37.8461
Epoch: 0173 | TRAIN: 0.9286 0.4359 0.7904 | 0.3469 0.3469 0.1560 | 0.1570 26.5438 21.3242 0.2718 0.5313 0.6557 TEST: 1.4928 0.4351 0.6876 | 0.4835 0.4747 0.7012 | 0.1662 27.6541 34.4962 24.9183 49.8792 62.5998
lr at 174th epoch is 5e-05 for optimizer
current performance: 36.5516, best performance: 37.8461
Epoch: 0174 | TRAIN: 0.9371 0.4467 0.7945 | 0.3438 0.3438 0.1556 | 0.1560 26.3966 21.1927 0.2769 0.5343 0.6576 TEST: 1.5231 0.4317 0.6836 | 0.4872 0.4789 0.6971 | 0.1703 28.1435 34.9284 23.9322 48.6768 61.5550
lr at 175th epoch is 5e-05 for optimizer
current performance: 37.2772, best performance: 37.8461
Epoch: 0175 | TRAIN: 0.9527 0.4389 0.7900 | 0.3420 0.3420 0.1534 | 0.1571 26.5171 21.1835 0.2747 0.5332 0.6562 TEST: 1.5039 0.4351 0.6870 | 0.4910 0.4824 0.7023 | 0.1678 27.7449 34.6978 24.9661 50.0448 62.6430
lr at 176th epoch is 5e-05 for optimizer
current performance: 35.9230, best performance: 37.8461
Epoch: 0176 | TRAIN: 0.9342 0.4391 0.7925 | 0.3477 0.3477 0.1591 | 0.1567 26.4755 21.2222 0.2745 0.5335 0.6567 TEST: 1.5467 0.4280 0.6832 | 0.4994 0.4899 0.7240 | 0.1679 27.8683 34.6749 24.3330 49.3413 62.1375
lr at 177th epoch is 5e-05 for optimizer
current performance: 36.1502, best performance: 37.8461
Epoch: 0177 | TRAIN: 0.9440 0.4411 0.7919 | 0.3461 0.3461 0.1608 | 0.1570 26.5573 21.2926 0.2703 0.5308 0.6553 TEST: 1.5849 0.4221 0.6798 | 0.4813 0.4728 0.6902 | 0.1661 27.6397 34.4738 24.9147 49.9267 62.6101
lr at 178th epoch is 5e-05 for optimizer
current performance: 37.3210, best performance: 37.8461
Epoch: 0178 | TRAIN: 0.9470 0.4378 0.7895 | 0.3446 0.3446 0.1582 | 0.1574 26.5890 21.3552 0.2707 0.5295 0.6541 TEST: 1.5067 0.4358 0.6884 | 0.4826 0.4736 0.7024 | 0.1702 28.1384 34.9482 23.7788 48.8525 61.7710
lr at 179th epoch is 5e-05 for optimizer
current performance: 35.8452, best performance: 37.8461
Epoch: 0179 | TRAIN: 0.9378 0.4305 0.7907 | 0.3465 0.3465 0.1569 | 0.1585 26.6884 21.4909 0.2706 0.5287 0.6529 TEST: 1.5552 0.4231 0.6811 | 0.4858 0.4767 0.7106 | 0.1683 27.8836 34.7324 24.2054 49.6274 62.4071
lr at 180th epoch is 5e-05 for optimizer
current performance: 37.1880, best performance: 37.8461
Epoch: 0180 | TRAIN: 0.9365 0.4441 0.7930 | 0.3415 0.3415 0.1543 | 0.1543 26.2299 20.7782 0.2788 0.5389 0.6622 TEST: 1.5387 0.4330 0.6877 | 0.4936 0.4845 0.7219 | 0.1649 27.5046 34.3529 24.9079 50.4228 63.1474
lr at 181th epoch is 5e-05 for optimizer
current performance: 36.5776, best performance: 37.8461
Epoch: 0181 | TRAIN: 0.9613 0.4406 0.7903 | 0.3418 0.3418 0.1562 | 0.1573 26.4893 21.1318 0.2764 0.5348 0.6574 TEST: 1.5680 0.4267 0.6842 | 0.4794 0.4718 0.6850 | 0.1676 27.8323 34.6626 24.4014 49.5354 62.2950
lr at 182th epoch is 5e-05 for optimizer
current performance: 37.6056, best performance: 37.8461
Epoch: 0182 | TRAIN: 0.9863 0.4414 0.7888 | 0.3458 0.3458 0.1574 | 0.1535 26.1471 20.9069 0.2798 0.5397 0.6623 TEST: 1.5367 0.4335 0.6875 | 0.4812 0.4723 0.6993 | 0.1673 27.6591 34.6471 25.0677 50.3307 62.9722
lr at 183th epoch is 5e-05 for optimizer
current performance: 33.9907, best performance: 37.8461
Epoch: 0183 | TRAIN: 0.9609 0.4412 0.7895 | 0.3366 0.3366 0.1550 | 0.1568 26.4554 21.1596 0.2773 0.5350 0.6566 TEST: 1.5798 0.4050 0.6854 | 0.4792 0.4708 0.6947 | 0.1669 27.7023 34.5897 24.7124 50.0437 62.7440
lr at 184th epoch is 5e-05 for optimizer
current performance: 36.2948, best performance: 37.8461
Epoch: 0184 | TRAIN: 0.9582 0.4424 0.7921 | 0.3426 0.3426 0.1571 | 0.1543 26.2175 20.9563 0.2786 0.5399 0.6629 TEST: 1.5706 0.4251 0.6850 | 0.4853 0.4764 0.6970 | 0.1669 27.7202 34.5696 24.7347 49.8140 62.5528
lr at 185th epoch is 5e-05 for optimizer
current performance: 37.1638, best performance: 37.8461
Epoch: 0185 | TRAIN: 0.9463 0.4429 0.7944 | 0.3417 0.3417 0.1542 | 0.1562 26.4267 21.1610 0.2763 0.5344 0.6573 TEST: 1.5104 0.4311 0.6873 | 0.4803 0.4719 0.6880 | 0.1672 27.8072 34.5836 24.3542 49.4331 62.2979
lr at 186th epoch is 5e-05 for optimizer
current performance: 35.9969, best performance: 37.8461
Epoch: 0186 | TRAIN: 0.9229 0.4336 0.7924 | 0.3423 0.3423 0.1585 | 0.1572 26.5404 21.2824 0.2731 0.5318 0.6551 TEST: 1.5216 0.4286 0.6840 | 0.5015 0.4922 0.7306 | 0.1684 27.7758 34.7742 24.8906 50.0855 62.7444
lr at 187th epoch is 5e-05 for optimizer
current performance: 36.2215, best performance: 37.8461
Epoch: 0187 | TRAIN: 0.9594 0.4340 0.7891 | 0.3383 0.3383 0.1548 | 0.1569 26.4407 21.0439 0.2760 0.5367 0.6594 TEST: 1.5422 0.4281 0.6869 | 0.4934 0.4840 0.7110 | 0.1677 27.8293 34.6545 24.4234 49.4835 62.3372
lr at 188th epoch is 5e-05 for optimizer
current performance: 38.0099, best performance: 37.8461
Epoch: 0188 | TRAIN: 0.9431 0.4389 0.7913 | 0.3426 0.3426 0.1553 | 0.1548 26.2391 20.9088 0.2801 0.5393 0.6625 TEST: 1.5089 0.4342 0.6885 | 0.4754 0.4672 0.6848 | 0.1651 27.5777 34.3635 24.7874 49.7922 62.6995
lr at 189th epoch is 5e-05 for optimizer
current performance: 37.4314, best performance: 38.0099
Epoch: 0189 | TRAIN: 0.9396 0.4433 0.7959 | 0.3355 0.3355 0.1522 | 0.1551 26.3118 21.0374 0.2775 0.5360 0.6596 TEST: 1.5246 0.4341 0.6874 | 0.4864 0.4770 0.7041 | 0.1668 27.7117 34.5779 24.5103 49.7920 62.6939
lr at 190th epoch is 5e-05 for optimizer
current performance: 35.9916, best performance: 38.0099
Epoch: 0190 | TRAIN: 0.9605 0.4495 0.7929 | 0.3470 0.3470 0.1550 | 0.1521 26.0069 20.6791 0.2811 0.5435 0.6664 TEST: 1.5525 0.4311 0.6858 | 0.5126 0.5027 0.7386 | 0.1673 27.6530 34.6594 25.0699 50.4196 63.0342
lr at 191th epoch is 5e-05 for optimizer
current performance: 36.3366, best performance: 38.0099
Epoch: 0191 | TRAIN: 0.9674 0.4417 0.7944 | 0.3359 0.3359 0.1548 | 0.1543 26.2144 20.9138 0.2793 0.5395 0.6621 TEST: 1.5659 0.4270 0.6842 | 0.4951 0.4858 0.7154 | 0.1656 27.5314 34.4460 25.2747 50.3660 62.9788
lr at 192th epoch is 5e-05 for optimizer
current performance: 37.3085, best performance: 38.0099
Epoch: 0192 | TRAIN: 0.9605 0.4406 0.7946 | 0.3433 0.3433 0.1572 | 0.1526 26.0041 20.6873 0.2854 0.5435 0.6654 TEST: 1.5340 0.4331 0.6849 | 0.4855 0.4773 0.6950 | 0.1670 27.6903 34.6052 24.9233 50.0089 62.6848
lr at 193th epoch is 5e-05 for optimizer
current performance: 36.8198, best performance: 38.0099
Epoch: 0193 | TRAIN: 0.9661 0.4376 0.7921 | 0.3399 0.3399 0.1546 | 0.1556 26.3421 21.0520 0.2786 0.5367 0.6588 TEST: 1.5297 0.4292 0.6860 | 0.4906 0.4814 0.7116 | 0.1657 27.5243 34.4725 25.1599 50.5617 63.1773
lr at 194th epoch is 5e-05 for optimizer
current performance: 34.8250, best performance: 38.0099
Epoch: 0194 | TRAIN: 0.9656 0.4404 0.7923 | 0.3357 0.3357 0.1540 | 0.1552 26.3548 21.0902 0.2744 0.5351 0.6598 TEST: 1.6027 0.4187 0.6842 | 0.4892 0.4807 0.7011 | 0.1714 28.1424 35.0680 24.3433 49.0310 61.6922
lr at 195th epoch is 5e-05 for optimizer
current performance: 37.1770, best performance: 38.0099
Epoch: 0195 | TRAIN: 0.9442 0.4489 0.7957 | 0.3419 0.3419 0.1565 | 0.1547 26.2159 20.9013 0.2828 0.5394 0.6608 TEST: 1.5664 0.4323 0.6864 | 0.4783 0.4693 0.6957 | 0.1686 28.0308 34.7093 23.8298 48.5834 61.5568
lr at 196th epoch is 5e-05 for optimizer
current performance: 37.0998, best performance: 38.0099
Epoch: 0196 | TRAIN: 0.9609 0.4385 0.7950 | 0.3448 0.3448 0.1581 | 0.1536 26.1317 20.7931 0.2804 0.5419 0.6645 TEST: 1.5827 0.4275 0.6863 | 0.4748 0.4663 0.6843 | 0.1663 27.6618 34.4886 24.7966 49.8193 62.5984
lr at 197th epoch is 5e-05 for optimizer
current performance: 34.8134, best performance: 38.0099
Epoch: 0197 | TRAIN: 0.9586 0.4385 0.7921 | 0.3416 0.3416 0.1544 | 0.1544 26.2052 20.8596 0.2799 0.5400 0.6622 TEST: 1.5471 0.4222 0.6824 | 0.4975 0.4875 0.7218 | 0.1737 28.2820 35.3812 23.8901 49.5284 62.2859
lr at 198th epoch is 5e-05 for optimizer
current performance: 35.7509, best performance: 38.0099
Epoch: 0198 | TRAIN: 0.9530 0.4368 0.7931 | 0.3452 0.3452 0.1550 | 0.1537 26.1642 20.8498 0.2795 0.5399 0.6628 TEST: 1.5715 0.4224 0.6793 | 0.4908 0.4814 0.7155 | 0.1666 27.7050 34.5316 24.4956 49.7444 62.6641
lr at 199th epoch is 5e-05 for optimizer
current performance: 36.4382, best performance: 38.0099
Epoch: 0199 | TRAIN: 0.9560 0.4405 0.7917 | 0.3434 0.3434 0.1552 | 0.1544 26.1819 20.8212 0.2802 0.5416 0.6648 TEST: 1.5906 0.4219 0.6850 | 0.4751 0.4662 0.6883 | 0.1670 27.6192 34.6145 25.2349 50.2784 62.9187
Epoch: 0188 | TRAIN: 0.9431 0.4389 0.7913 | 0.3426 0.3426 0.1553 | 0.1548 26.2391 20.9088 0.2801 0.5393 0.6625 TEST: 1.5089 0.4342 0.6885 | 0.4754 0.4672 0.6848 | 0.1651 27.5777 34.3635 24.7874 49.7922 62.6995
