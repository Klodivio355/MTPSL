
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/scratch_tmp/grp/grv_shi/k21220263/MTPSL/nyu_mtl_xtc.py:109: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels_weights = torch.load('{}onelabel.pth'.format(opt.labelroot))['labels_weights'].float().cuda()
Parameter Space: ABS: 28889941.0, REL: 1.1565

LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR ROOT_MSE | NORMAL_LOSS MEAN MED <11.25 <22.5 <30

lr at 0th epoch is 0.0001 for optimizer
current performance: -51.0880, best performance: -100.0000
Epoch: 0000 | TRAIN: 3.1170 0.0354 0.1474 | 1.3947 1.3947 0.6235 | 0.4872 56.1670 55.5449 0.0137 0.0788 0.1580 TEST: 2.2280 0.0494 0.1388 | 0.8990 0.8844 1.1660 | 0.3576 47.3801 50.9009 1.7665 9.5178 18.4120
lr at 1th epoch is 0.0001 for optimizer
current performance: -64.6102, best performance: -51.0880
Epoch: 0001 | TRAIN: 2.6378 0.0424 0.1492 | 0.9816 0.9816 0.4414 | 0.3400 45.7415 44.8942 0.0275 0.1227 0.2214 TEST: 2.2556 0.0556 0.2083 | 1.3101 1.2927 1.7071 | 0.3255 44.3737 48.4960 3.8087 13.6263 23.5997
lr at 2th epoch is 0.0001 for optimizer
current performance: -45.2204, best performance: -51.0880
Epoch: 0002 | TRAIN: 2.5500 0.0421 0.1387 | 0.9102 0.9102 0.4289 | 0.3280 44.4291 43.2388 0.0418 0.1509 0.2550 TEST: 2.2196 0.0573 0.2533 | 0.8967 0.8780 1.2535 | 0.3143 43.2504 47.6382 4.4992 15.6475 27.3567
lr at 3th epoch is 0.0001 for optimizer
current performance: -48.0877, best performance: -45.2204
Epoch: 0003 | TRAIN: 2.4307 0.0449 0.1642 | 0.8857 0.8857 0.4188 | 0.3245 44.1137 42.9840 0.0431 0.1550 0.2631 TEST: 2.4075 0.0297 0.1304 | 0.8415 0.8249 1.1493 | 0.3302 44.7243 48.8240 4.3832 14.6658 23.6520
lr at 4th epoch is 0.0001 for optimizer
current performance: -52.8326, best performance: -45.2204
Epoch: 0004 | TRAIN: 2.4366 0.0485 0.1753 | 0.8549 0.8549 0.3953 | 0.3235 44.0301 42.7502 0.0422 0.1559 0.2661 TEST: 2.1790 0.0487 0.1666 | 1.0470 1.0283 1.4411 | 0.3130 43.2646 47.4775 4.5937 15.3400 26.0667
lr at 5th epoch is 0.0001 for optimizer
current performance: -44.0964, best performance: -45.2204
Epoch: 0005 | TRAIN: 2.3528 0.0466 0.1742 | 0.8703 0.8703 0.4114 | 0.3212 43.8586 42.5144 0.0426 0.1559 0.2670 TEST: 2.3053 0.0590 0.2660 | 0.8527 0.8356 1.1636 | 0.3208 44.0754 48.0045 4.3521 14.6681 23.9020
lr at 6th epoch is 0.0001 for optimizer
current performance: -43.9775, best performance: -44.0964
Epoch: 0006 | TRAIN: 2.4464 0.0478 0.1856 | 0.8417 0.8417 0.3890 | 0.3241 44.1638 43.1207 0.0404 0.1509 0.2599 TEST: 2.1130 0.0685 0.2467 | 0.9107 0.8918 1.2671 | 0.3094 42.8818 47.1996 4.5734 16.2461 27.9154
lr at 7th epoch is 0.0001 for optimizer
current performance: -48.0557, best performance: -43.9775
Epoch: 0007 | TRAIN: 2.3533 0.0463 0.1997 | 0.8315 0.8315 0.3856 | 0.3215 43.8428 42.7132 0.0434 0.1604 0.2713 TEST: 2.1881 0.0520 0.3078 | 0.9533 0.9344 1.3343 | 0.3100 42.9965 47.2158 4.6634 15.9268 27.0208
lr at 8th epoch is 0.0001 for optimizer
current performance: -44.6458, best performance: -43.9775
Epoch: 0008 | TRAIN: 2.3714 0.0508 0.2215 | 0.8359 0.8359 0.3965 | 0.3198 43.7245 42.5626 0.0418 0.1607 0.2744 TEST: 2.4321 0.0483 0.1059 | 0.8779 0.8593 1.2242 | 0.3060 42.4264 46.9974 4.5945 17.7495 30.3600
lr at 9th epoch is 0.0001 for optimizer
current performance: -52.3165, best performance: -43.9775
Epoch: 0009 | TRAIN: 2.3799 0.0403 0.1990 | 0.8393 0.8393 0.3927 | 0.3206 43.7994 42.4740 0.0418 0.1597 0.2709 TEST: 2.2418 0.0146 0.1763 | 0.9431 0.9241 1.3089 | 0.3128 42.9288 47.6003 4.4655 16.9422 29.7650
lr at 10th epoch is 0.0001 for optimizer
current performance: -46.5830, best performance: -43.9775
Epoch: 0010 | TRAIN: 2.4379 0.0459 0.1759 | 0.8370 0.8370 0.3872 | 0.3180 43.5565 42.4992 0.0440 0.1648 0.2769 TEST: 2.3613 0.0485 0.2869 | 0.9040 0.8851 1.2643 | 0.3118 43.1884 47.3991 4.0343 14.8963 26.5662
lr at 11th epoch is 0.0001 for optimizer
current performance: -49.4177, best performance: -43.9775
Epoch: 0011 | TRAIN: 2.3271 0.0456 0.2253 | 0.8402 0.8402 0.3942 | 0.3184 43.6408 42.5355 0.0427 0.1602 0.2725 TEST: 2.3083 0.0137 0.1746 | 0.8769 0.8582 1.2261 | 0.3063 42.7801 46.8654 4.7024 15.8404 26.7228
lr at 12th epoch is 0.0001 for optimizer
current performance: -52.8952, best performance: -43.9775
Epoch: 0012 | TRAIN: 2.4383 0.0472 0.1664 | 0.8321 0.8321 0.3791 | 0.3195 43.6835 42.6745 0.0434 0.1636 0.2746 TEST: 2.3391 0.0141 0.1748 | 0.9707 0.9517 1.3479 | 0.3040 42.3225 46.7957 4.8124 17.3963 29.7418
lr at 13th epoch is 0.0001 for optimizer
current performance: -47.4190, best performance: -43.9775
Epoch: 0013 | TRAIN: 2.3429 0.0427 0.2162 | 0.8343 0.8343 0.3884 | 0.3168 43.5819 42.4365 0.0400 0.1562 0.2706 TEST: 2.4267 0.0140 0.1757 | 0.8339 0.8171 1.1410 | 0.3045 42.6170 46.7676 4.2336 15.6406 27.7055
lr at 14th epoch is 0.0001 for optimizer
current performance: -46.2069, best performance: -43.9775
Epoch: 0014 | TRAIN: 2.5185 0.0394 0.1467 | 0.8280 0.8280 0.3905 | 0.3161 43.4495 42.2051 0.0419 0.1606 0.2771 TEST: 2.3658 0.0397 0.2597 | 0.8682 0.8498 1.2135 | 0.3126 43.2080 47.4525 4.4218 15.5704 26.6987
lr at 15th epoch is 0.0001 for optimizer
current performance: -40.9881, best performance: -43.9775
Epoch: 0015 | TRAIN: 2.3608 0.0447 0.1988 | 0.8260 0.8260 0.3906 | 0.3138 43.2489 42.0464 0.0439 0.1651 0.2797 TEST: 2.0403 0.0926 0.3000 | 0.9350 0.9162 1.3081 | 0.2996 42.0072 46.4249 4.7057 17.4854 30.1160
lr at 16th epoch is 0.0001 for optimizer
current performance: -51.8676, best performance: -40.9881
Epoch: 0016 | TRAIN: 2.6493 0.0397 0.1153 | 0.8146 0.8146 0.3830 | 0.3135 43.2046 41.9902 0.0454 0.1655 0.2814 TEST: 4.6348 0.0058 0.0434 | 0.9242 0.9054 1.2897 | 0.3057 42.2436 47.0362 4.6607 18.3927 32.1406
lr at 17th epoch is 0.0001 for optimizer
current performance: -55.3622, best performance: -40.9881
Epoch: 0017 | TRAIN: 2.4773 0.0495 0.2159 | 0.8419 0.8419 0.4015 | 0.3137 43.2977 42.1451 0.0420 0.1603 0.2755 TEST: 2.3438 0.0135 0.1739 | 1.0163 0.9976 1.4099 | 0.3039 42.6942 46.6767 4.1723 14.8664 26.1382
lr at 18th epoch is 0.0001 for optimizer
current performance: -47.3814, best performance: -40.9881
Epoch: 0018 | TRAIN: 2.2670 0.0428 0.2157 | 0.8352 0.8352 0.3925 | 0.3132 43.2844 42.1142 0.0427 0.1588 0.2721 TEST: 2.0345 0.0469 0.2556 | 0.9777 0.9588 1.3561 | 0.2908 40.8433 45.7717 6.1620 22.0375 34.6860
lr at 19th epoch is 0.0001 for optimizer
current performance: -53.2751, best performance: -40.9881
Epoch: 0019 | TRAIN: 2.3584 0.0390 0.1636 | 0.8201 0.8201 0.3911 | 0.3095 42.9060 41.7938 0.0455 0.1705 0.2860 TEST: 3.0220 0.0019 0.0240 | 0.9387 0.9197 1.3114 | 0.3023 42.5128 46.4994 4.6776 16.0693 26.7983
lr at 20th epoch is 0.0001 for optimizer
current performance: -44.4720, best performance: -40.9881
Epoch: 0020 | TRAIN: 2.5515 0.0377 0.1155 | 0.8268 0.8268 0.3855 | 0.3103 43.0208 41.9707 0.0431 0.1654 0.2800 TEST: 2.4228 0.0326 0.1265 | 0.8523 0.8341 1.1898 | 0.2923 41.4351 45.7780 4.8243 18.2238 31.0117
lr at 21th epoch is 0.0001 for optimizer
current performance: -52.2791, best performance: -40.9881
Epoch: 0021 | TRAIN: 2.4815 0.0414 0.1346 | 0.8164 0.8164 0.3922 | 0.3085 42.8148 41.5613 0.0437 0.1710 0.2895 TEST: 3.2660 0.0024 0.0245 | 0.9110 0.8920 1.2666 | 0.3059 42.7427 46.9469 2.9135 15.3129 28.6500
lr at 22th epoch is 0.0001 for optimizer
current performance: -51.5492, best performance: -40.9881
Epoch: 0022 | TRAIN: 2.5616 0.0332 0.0988 | 0.8359 0.8359 0.3902 | 0.3067 42.6356 41.5475 0.0472 0.1749 0.2925 TEST: 2.5006 0.0248 0.0717 | 0.9539 0.9350 1.3314 | 0.3088 42.9907 46.9978 4.9276 16.5918 26.4598
lr at 23th epoch is 0.0001 for optimizer
current performance: -41.1672, best performance: -40.9881
Epoch: 0023 | TRAIN: 2.6847 0.0425 0.1302 | 0.8361 0.8361 0.3877 | 0.3093 42.8391 41.7351 0.0459 0.1719 0.2894 TEST: 2.0778 0.0867 0.3016 | 0.9359 0.9170 1.3046 | 0.2919 41.4527 45.6999 5.0725 18.0921 30.5716
lr at 24th epoch is 0.0001 for optimizer
current performance: -46.8737, best performance: -40.9881
Epoch: 0024 | TRAIN: 2.6784 0.0264 0.0749 | 0.8275 0.8275 0.3881 | 0.3093 42.8876 41.8765 0.0456 0.1705 0.2838 TEST: 2.5107 0.0152 0.0541 | 0.8396 0.8222 1.1563 | 0.2995 42.0601 46.3478 5.0928 17.7281 29.3475
lr at 25th epoch is 0.0001 for optimizer
current performance: -43.9492, best performance: -40.9881
Epoch: 0025 | TRAIN: 2.5278 0.0427 0.1195 | 0.8428 0.8428 0.4078 | 0.3049 42.4293 41.1944 0.0468 0.1815 0.3013 TEST: 2.3077 0.0451 0.0955 | 0.8857 0.8672 1.2359 | 0.2881 41.1130 45.3942 5.0677 18.6217 31.5121
lr at 26th epoch is 0.0001 for optimizer
current performance: -47.3796, best performance: -40.9881
Epoch: 0026 | TRAIN: 2.5696 0.0373 0.0993 | 0.8240 0.8240 0.3916 | 0.3015 42.1523 41.0279 0.0502 0.1829 0.3032 TEST: 2.6998 0.0141 0.0656 | 0.8436 0.8257 1.1737 | 0.3014 42.2590 46.4587 5.1310 16.9606 28.0517
lr at 27th epoch is 0.0001 for optimizer
current performance: -50.1500, best performance: -40.9881
Epoch: 0027 | TRAIN: 2.3996 0.0449 0.1473 | 0.8175 0.8175 0.3879 | 0.3032 42.3277 41.1605 0.0469 0.1788 0.2995 TEST: 2.3326 0.0365 0.1463 | 1.0158 0.9972 1.3954 | 0.2867 40.6559 45.3683 5.8473 21.4568 34.1684
lr at 28th epoch is 0.0001 for optimizer
current performance: -47.2430, best performance: -40.9881
Epoch: 0028 | TRAIN: 2.2615 0.0495 0.1719 | 0.8205 0.8205 0.3831 | 0.2997 41.9805 40.7509 0.0484 0.1859 0.3106 TEST: 2.4059 0.0338 0.1234 | 0.9373 0.9185 1.3078 | 0.2862 40.7912 45.3015 5.0045 19.8501 33.0672
lr at 29th epoch is 0.0001 for optimizer
current performance: -48.1633, best performance: -40.9881
Epoch: 0029 | TRAIN: 2.5803 0.0306 0.0846 | 0.8202 0.8202 0.3837 | 0.2968 41.7796 40.6427 0.0493 0.1868 0.3108 TEST: 3.4149 0.0019 0.0237 | 0.8332 0.8158 1.1540 | 0.2949 41.9386 45.9007 4.3506 15.7363 27.7258
lr at 30th epoch is 0.0001 for optimizer
current performance: -38.9348, best performance: -40.9881
Epoch: 0030 | TRAIN: 2.6062 0.0352 0.1032 | 0.8183 0.8183 0.3758 | 0.2995 42.0757 41.0309 0.0493 0.1794 0.2963 TEST: 2.0566 0.1007 0.2737 | 0.9317 0.9126 1.3043 | 0.2887 41.2216 45.4598 4.6552 17.8016 30.6871
lr at 31th epoch is 0.0001 for optimizer
current performance: -46.5168, best performance: -38.9348
Epoch: 0031 | TRAIN: 2.5078 0.0298 0.0878 | 0.8053 0.8053 0.3811 | 0.2930 41.4663 40.4246 0.0507 0.1917 0.3149 TEST: 2.2566 0.0460 0.1289 | 0.9498 0.9309 1.3292 | 0.2868 41.0551 45.2678 5.0626 18.4741 31.0923
lr at 32th epoch is 0.0001 for optimizer
current performance: -52.0595, best performance: -38.9348
Epoch: 0032 | TRAIN: 2.5531 0.0402 0.1038 | 0.8080 0.8080 0.3872 | 0.2994 42.0501 40.9506 0.0481 0.1805 0.3016 TEST: 3.0235 0.0022 0.0072 | 0.9563 0.9374 1.3364 | 0.2830 40.7536 44.9764 4.7177 18.0979 31.5302
lr at 33th epoch is 0.0001 for optimizer
current performance: -44.1219, best performance: -38.9348
Epoch: 0033 | TRAIN: 2.3706 0.0477 0.1430 | 0.8240 0.8240 0.3748 | 0.2970 41.8241 40.8844 0.0493 0.1872 0.3078 TEST: 2.1425 0.0591 0.1356 | 0.9458 0.9268 1.3177 | 0.2813 40.5639 44.8146 5.0175 19.3068 32.1095
lr at 34th epoch is 0.0001 for optimizer
current performance: -46.0910, best performance: -38.9348
Epoch: 0034 | TRAIN: 2.3337 0.0465 0.1717 | 0.8064 0.8064 0.3818 | 0.2935 41.5594 40.6543 0.0505 0.1871 0.3090 TEST: 2.7425 0.0212 0.0910 | 0.8724 0.8538 1.2143 | 0.2893 40.8173 45.6202 5.9454 21.1093 33.5893
lr at 35th epoch is 0.0001 for optimizer
current performance: -46.0723, best performance: -38.9348
Epoch: 0035 | TRAIN: 2.4124 0.0410 0.1513 | 0.8289 0.8289 0.3984 | 0.2972 41.8146 40.6457 0.0502 0.1854 0.3080 TEST: 2.4209 0.0196 0.0426 | 0.8971 0.8786 1.2487 | 0.2789 39.6481 44.7994 7.5181 24.5270 37.0037
lr at 36th epoch is 0.0001 for optimizer
current performance: -37.6555, best performance: -38.9348
Epoch: 0036 | TRAIN: 2.3922 0.0472 0.1546 | 0.7978 0.7978 0.3864 | 0.2939 41.5809 40.4724 0.0489 0.1869 0.3097 TEST: 2.2256 0.0740 0.2156 | 0.8404 0.8232 1.1586 | 0.2808 40.4843 44.7340 5.5679 20.1826 32.4762
lr at 37th epoch is 0.0001 for optimizer
current performance: -49.9708, best performance: -37.6555
Epoch: 0037 | TRAIN: 2.7082 0.0325 0.0839 | 0.8427 0.8427 0.3901 | 0.2960 41.7222 40.6644 0.0492 0.1879 0.3094 TEST: 2.8636 0.0042 0.0120 | 0.9309 0.9120 1.3001 | 0.2765 40.0911 44.4264 5.2313 20.1784 33.7424
lr at 38th epoch is 0.0001 for optimizer
current performance: -34.7810, best performance: -37.6555
Epoch: 0038 | TRAIN: 2.5194 0.0301 0.0912 | 0.8104 0.8104 0.3751 | 0.2890 41.1638 40.0096 0.0518 0.1934 0.3186 TEST: 2.1434 0.0960 0.2875 | 0.8577 0.8394 1.1954 | 0.2772 39.7893 44.5581 6.8704 23.1939 35.3368
lr at 39th epoch is 0.0001 for optimizer
current performance: -46.4495, best performance: -34.7810
Epoch: 0039 | TRAIN: 2.5919 0.0320 0.0893 | 0.8211 0.8211 0.3807 | 0.2923 41.4499 40.2660 0.0500 0.1886 0.3115 TEST: 2.6253 0.0071 0.0638 | 0.8327 0.8156 1.1462 | 0.2844 41.0086 44.9844 5.0764 17.8335 29.9704
lr at 40th epoch is 0.0001 for optimizer
current performance: -44.6222, best performance: -34.7810
Epoch: 0040 | TRAIN: 2.4227 0.0358 0.1413 | 0.8013 0.8013 0.3742 | 0.2921 41.4137 40.2644 0.0508 0.1897 0.3137 TEST: 2.8548 0.0151 0.0604 | 0.8386 0.8208 1.1645 | 0.2766 40.0793 44.3696 5.8431 20.9512 33.5209
lr at 41th epoch is 0.0001 for optimizer
current performance: -41.2963, best performance: -34.7810
Epoch: 0041 | TRAIN: 2.3375 0.0513 0.1697 | 0.8223 0.8223 0.3873 | 0.2942 41.5639 40.5577 0.0524 0.1897 0.3116 TEST: 2.1561 0.0605 0.2341 | 0.8946 0.8756 1.2548 | 0.2782 40.1663 44.5879 5.4093 20.6036 33.6932
lr at 42th epoch is 0.0001 for optimizer
current performance: -41.8846, best performance: -34.7810
Epoch: 0042 | TRAIN: 2.2445 0.0488 0.2023 | 0.7899 0.7899 0.3739 | 0.2900 41.2458 40.0731 0.0496 0.1923 0.3174 TEST: 2.1637 0.0537 0.2320 | 0.8760 0.8575 1.2210 | 0.2818 40.6172 44.8213 5.2542 19.2636 31.6574
lr at 43th epoch is 0.0001 for optimizer
current performance: -42.5298, best performance: -34.7810
Epoch: 0043 | TRAIN: 2.3357 0.0495 0.1691 | 0.8082 0.8082 0.3897 | 0.2919 41.3039 40.0507 0.0525 0.1959 0.3217 TEST: 2.1185 0.0687 0.1876 | 0.9553 0.9363 1.3347 | 0.2757 39.8580 44.3893 5.9744 21.9559 34.5262
lr at 44th epoch is 0.0001 for optimizer
current performance: -43.1246, best performance: -34.7810
Epoch: 0044 | TRAIN: 2.4260 0.0425 0.1150 | 0.8140 0.8140 0.3835 | 0.2894 41.1299 39.8918 0.0527 0.1977 0.3219 TEST: 2.6806 0.0298 0.0966 | 0.8243 0.8071 1.1373 | 0.2837 40.9586 44.9688 4.5867 17.3156 30.2785
lr at 45th epoch is 0.0001 for optimizer
current performance: -47.0597, best performance: -34.7810
Epoch: 0045 | TRAIN: 2.4678 0.0430 0.1199 | 0.8245 0.8245 0.3938 | 0.2882 41.0484 39.7424 0.0509 0.1965 0.3245 TEST: 2.6355 0.0179 0.0771 | 0.9093 0.8903 1.2718 | 0.2753 39.8857 44.3446 5.5787 21.3210 34.3283
lr at 46th epoch is 0.0001 for optimizer
current performance: -37.0827, best performance: -34.7810
Epoch: 0046 | TRAIN: 2.3200 0.0532 0.1560 | 0.7953 0.7953 0.3763 | 0.2880 41.0410 39.7575 0.0519 0.1974 0.3231 TEST: 2.0479 0.1067 0.2866 | 0.9549 0.9359 1.3317 | 0.2709 39.3385 43.9887 6.3777 23.3976 36.2430
lr at 47th epoch is 0.0001 for optimizer
current performance: -49.5953, best performance: -34.7810
Epoch: 0047 | TRAIN: 2.3963 0.0481 0.1406 | 0.8141 0.8141 0.3928 | 0.2857 40.8494 39.7148 0.0536 0.1996 0.3261 TEST: 2.3013 0.0396 0.1487 | 1.0493 1.0305 1.4441 | 0.2685 39.2066 43.7668 6.3960 23.0024 35.8709
lr at 48th epoch is 0.0001 for optimizer
current performance: -40.5547, best performance: -34.7810
Epoch: 0048 | TRAIN: 2.4250 0.0437 0.1320 | 0.8029 0.8029 0.3781 | 0.2853 40.8028 39.4589 0.0524 0.1994 0.3280 TEST: 2.2479 0.0488 0.1796 | 0.8501 0.8321 1.1886 | 0.2729 39.8451 44.0898 5.4449 20.4303 33.8123
lr at 49th epoch is 0.0001 for optimizer
current performance: -51.2039, best performance: -34.7810
Epoch: 0049 | TRAIN: 2.2789 0.0494 0.1675 | 0.8121 0.8121 0.3899 | 0.2829 40.5815 39.2826 0.0537 0.2044 0.3330 TEST: 2.6728 0.0303 0.0989 | 1.0572 1.0388 1.4448 | 0.2681 39.2682 43.7358 5.7410 22.1377 35.9237
lr at 50th epoch is 0.0001 for optimizer
current performance: -48.3778, best performance: -34.7810
Epoch: 0050 | TRAIN: 2.3430 0.0566 0.1830 | 0.8084 0.8084 0.3672 | 0.2841 40.7364 39.4144 0.0521 0.1981 0.3274 TEST: 3.2015 0.0034 0.0262 | 0.8482 0.8300 1.1874 | 0.2900 41.7561 45.4806 3.5535 14.3433 26.7953
lr at 51th epoch is 0.0001 for optimizer
current performance: -42.6033, best performance: -34.7810
Epoch: 0051 | TRAIN: 2.3341 0.0501 0.1637 | 0.8050 0.8050 0.3843 | 0.2826 40.6248 39.4367 0.0525 0.1998 0.3275 TEST: 3.1742 0.0231 0.1096 | 0.8243 0.8071 1.1388 | 0.2721 39.7094 44.0340 5.3872 21.2536 34.3951
lr at 52th epoch is 0.0001 for optimizer
current performance: -44.0785, best performance: -34.7810
Epoch: 0052 | TRAIN: 2.2791 0.0488 0.1936 | 0.8011 0.8011 0.3885 | 0.2827 40.4619 39.1219 0.0571 0.2120 0.3398 TEST: 2.5866 0.0315 0.0903 | 0.8864 0.8677 1.2376 | 0.2733 39.6433 44.1899 5.9172 22.3026 35.0669
lr at 53th epoch is 0.0001 for optimizer
current performance: -41.9711, best performance: -34.7810
Epoch: 0053 | TRAIN: 2.2864 0.0528 0.1939 | 0.8175 0.8175 0.3830 | 0.2813 40.4563 39.1738 0.0540 0.2069 0.3349 TEST: 2.1454 0.0719 0.2677 | 0.9691 0.9499 1.3471 | 0.2685 39.1956 43.7509 6.5814 23.0626 35.7955
lr at 54th epoch is 0.0001 for optimizer
current performance: -45.8633, best performance: -34.7810
Epoch: 0054 | TRAIN: 2.2212 0.0584 0.2245 | 0.8265 0.8265 0.3896 | 0.2824 40.5871 39.3173 0.0512 0.2011 0.3327 TEST: 2.5543 0.0230 0.1312 | 0.8851 0.8665 1.2350 | 0.2764 40.3212 44.3121 4.9335 18.5555 31.6523
lr at 55th epoch is 0.0001 for optimizer
current performance: -42.0769, best performance: -34.7810
Epoch: 0055 | TRAIN: 2.2328 0.0550 0.1780 | 0.8116 0.8116 0.3860 | 0.2799 40.4317 39.1006 0.0508 0.1990 0.3316 TEST: 2.4912 0.0319 0.1087 | 0.8365 0.8188 1.1646 | 0.2723 39.7890 44.0652 5.3214 20.5517 33.9267
lr at 56th epoch is 0.0001 for optimizer
current performance: -42.6108, best performance: -34.7810
Epoch: 0056 | TRAIN: 2.3714 0.0496 0.1688 | 0.8166 0.8166 0.3787 | 0.2837 40.5654 39.3426 0.0564 0.2106 0.3369 TEST: 2.4268 0.0487 0.1282 | 0.8977 0.8789 1.2630 | 0.2736 39.8638 44.1507 5.5035 20.9325 33.5627
lr at 57th epoch is 0.0001 for optimizer
current performance: -44.3892, best performance: -34.7810
Epoch: 0057 | TRAIN: 2.4286 0.0462 0.1389 | 0.8183 0.8183 0.4007 | 0.2850 40.8486 39.7130 0.0511 0.1962 0.3237 TEST: 2.2973 0.0489 0.1089 | 0.9510 0.9320 1.3258 | 0.2684 39.4249 43.6724 5.8278 21.3404 34.1982
lr at 58th epoch is 0.0001 for optimizer
current performance: -42.6750, best performance: -34.7810
Epoch: 0058 | TRAIN: 2.2624 0.0568 0.1733 | 0.8281 0.8281 0.3819 | 0.2801 40.3816 39.1455 0.0537 0.2041 0.3337 TEST: 2.3575 0.0277 0.0732 | 0.8232 0.8059 1.1473 | 0.2779 40.3576 44.4990 4.8378 18.8661 32.4253
lr at 59th epoch is 0.0001 for optimizer
current performance: -39.5341, best performance: -34.7810
Epoch: 0059 | TRAIN: 2.2504 0.0611 0.2015 | 0.8072 0.8072 0.3807 | 0.2834 40.5793 39.2521 0.0552 0.2071 0.3354 TEST: 2.2148 0.0578 0.1736 | 0.8628 0.8442 1.2071 | 0.2694 39.4935 43.7927 5.3237 21.4005 34.8639
lr at 60th epoch is 0.0001 for optimizer
current performance: -43.4598, best performance: -34.7810
Epoch: 0060 | TRAIN: 2.3536 0.0577 0.2003 | 0.8043 0.8043 0.3744 | 0.2834 40.6420 39.4102 0.0522 0.2026 0.3324 TEST: 2.6228 0.0266 0.1091 | 0.8456 0.8275 1.1800 | 0.2776 40.0944 44.5303 5.5242 20.8533 33.9131
lr at 61th epoch is 0.0001 for optimizer
current performance: -46.1740, best performance: -34.7810
Epoch: 0061 | TRAIN: 2.4434 0.0486 0.1390 | 0.7975 0.7975 0.3895 | 0.2851 40.7875 39.4813 0.0528 0.1990 0.3284 TEST: 2.4042 0.0319 0.0870 | 0.9547 0.9359 1.3274 | 0.2667 38.9236 43.6377 6.8721 23.7210 36.7714
lr at 62th epoch is 0.0001 for optimizer
current performance: -47.6418, best performance: -34.7810
Epoch: 0062 | TRAIN: 2.3657 0.0434 0.1397 | 0.8046 0.8046 0.3802 | 0.2821 40.5864 39.4382 0.0527 0.2015 0.3287 TEST: 3.7073 0.0077 0.0304 | 0.8970 0.8779 1.2502 | 0.2792 39.7228 44.8263 6.8584 24.2020 36.7919
lr at 63th epoch is 0.0001 for optimizer
current performance: -49.7999, best performance: -34.7810
Epoch: 0063 | TRAIN: 2.4588 0.0410 0.1227 | 0.8172 0.8172 0.3872 | 0.2826 40.4561 39.1061 0.0570 0.2117 0.3403 TEST: 2.7265 0.0092 0.0406 | 0.9241 0.9050 1.2942 | 0.2811 40.7836 44.7643 4.4587 17.1611 30.5010
lr at 64th epoch is 0.0001 for optimizer
current performance: -45.5631, best performance: -34.7810
Epoch: 0064 | TRAIN: 2.3338 0.0585 0.1901 | 0.8092 0.8092 0.3825 | 0.2823 40.5380 39.2667 0.0544 0.2056 0.3319 TEST: 2.6863 0.0240 0.0660 | 0.9041 0.8853 1.2670 | 0.2688 39.4347 43.7727 5.5918 21.2333 34.7956
lr at 65th epoch is 0.0001 for optimizer
current performance: -39.5281, best performance: -34.7810
Epoch: 0065 | TRAIN: 2.2257 0.0562 0.2205 | 0.8077 0.8077 0.3817 | 0.2805 40.3869 39.0156 0.0533 0.2051 0.3370 TEST: 2.1322 0.0442 0.2437 | 0.8352 0.8178 1.1572 | 0.2659 38.9489 43.5529 6.6185 23.6253 36.3625
lr at 66th epoch is 0.0001 for optimizer
current performance: -44.2880, best performance: -34.7810
Epoch: 0066 | TRAIN: 2.3574 0.0553 0.1685 | 0.8003 0.8003 0.3953 | 0.2795 40.2465 38.8302 0.0563 0.2112 0.3408 TEST: 2.8302 0.0312 0.0696 | 0.9028 0.8837 1.2691 | 0.2680 39.1804 43.7267 6.2076 22.7544 35.7918
lr at 67th epoch is 0.0001 for optimizer
current performance: -32.3946, best performance: -34.7810
Epoch: 0067 | TRAIN: 2.4143 0.0524 0.1489 | 0.8090 0.8090 0.3765 | 0.2792 40.2873 38.9523 0.0541 0.2074 0.3377 TEST: 1.9979 0.1210 0.3026 | 0.8567 0.8383 1.1977 | 0.2805 40.5579 44.6851 5.3654 18.9676 31.5502
lr at 68th epoch is 0.0001 for optimizer
current performance: -33.1927, best performance: -32.3946
Epoch: 0068 | TRAIN: 2.3039 0.0580 0.1674 | 0.8050 0.8050 0.3860 | 0.2828 40.5661 39.3380 0.0544 0.2050 0.3320 TEST: 2.2450 0.1047 0.2366 | 0.8620 0.8437 1.2013 | 0.2678 39.1923 43.7201 6.0175 22.6621 35.9048
lr at 69th epoch is 0.0001 for optimizer
current performance: -39.0065, best performance: -32.3946
Epoch: 0069 | TRAIN: 2.2896 0.0557 0.1728 | 0.8098 0.8098 0.3848 | 0.2788 40.2357 39.0042 0.0559 0.2083 0.3389 TEST: 2.4541 0.0621 0.1499 | 0.8680 0.8501 1.2077 | 0.2682 39.2771 43.7419 5.8039 22.1968 35.4235
lr at 70th epoch is 0.0001 for optimizer
current performance: -39.4653, best performance: -32.3946
Epoch: 0070 | TRAIN: 2.2608 0.0615 0.2043 | 0.7990 0.7990 0.3739 | 0.2813 40.4851 39.0895 0.0520 0.2025 0.3332 TEST: 2.1503 0.0933 0.2676 | 0.9757 0.9566 1.3565 | 0.2665 39.1364 43.5991 5.8144 22.4534 35.6246
lr at 71th epoch is 0.0001 for optimizer
current performance: -44.2807, best performance: -32.3946
Epoch: 0071 | TRAIN: 2.2897 0.0582 0.2074 | 0.8082 0.8082 0.3855 | 0.2819 40.5456 39.2088 0.0520 0.2026 0.3321 TEST: 2.4784 0.0370 0.1186 | 0.8954 0.8768 1.2584 | 0.2750 40.1098 44.2648 4.5307 19.1791 32.9302
lr at 72th epoch is 0.0001 for optimizer
current performance: -34.5693, best performance: -32.3946
Epoch: 0072 | TRAIN: 2.3503 0.0551 0.1874 | 0.8059 0.8059 0.3818 | 0.2810 40.4938 39.2281 0.0507 0.2019 0.3325 TEST: 2.0687 0.1020 0.3144 | 0.8642 0.8461 1.2033 | 0.2744 40.0279 44.1997 5.3856 20.1869 32.6268
lr at 73th epoch is 0.0001 for optimizer
current performance: -40.8522, best performance: -32.3946
Epoch: 0073 | TRAIN: 2.3329 0.0598 0.2138 | 0.8023 0.8023 0.3870 | 0.2806 40.4569 39.2428 0.0505 0.2024 0.3335 TEST: 2.3305 0.0470 0.1642 | 0.8774 0.8590 1.2262 | 0.2647 38.8648 43.4299 6.6351 23.5255 36.4264
lr at 74th epoch is 0.0001 for optimizer
current performance: -45.6875, best performance: -32.3946
Epoch: 0074 | TRAIN: 2.2992 0.0610 0.2235 | 0.8120 0.8120 0.3786 | 0.2803 40.3569 39.0161 0.0540 0.2085 0.3387 TEST: 3.3150 0.0104 0.0479 | 0.8536 0.8353 1.2004 | 0.2720 39.9257 43.9330 5.3845 19.3188 32.2178
lr at 75th epoch is 0.0001 for optimizer
current performance: -43.0478, best performance: -32.3946
Epoch: 0075 | TRAIN: 2.2861 0.0633 0.2207 | 0.8158 0.8158 0.3801 | 0.2819 40.5398 39.3134 0.0521 0.2038 0.3323 TEST: 2.8310 0.0259 0.1038 | 0.8656 0.8468 1.2170 | 0.2638 38.8862 43.3278 6.1845 22.8812 36.0023
lr at 76th epoch is 0.0001 for optimizer
current performance: -44.8134, best performance: -32.3946
Epoch: 0076 | TRAIN: 2.2940 0.0624 0.2010 | 0.8066 0.8066 0.3807 | 0.2790 40.2721 38.8759 0.0531 0.2070 0.3387 TEST: 2.5691 0.0449 0.1309 | 0.9581 0.9393 1.3367 | 0.2661 39.0669 43.5579 6.1701 22.8163 35.8611
lr at 77th epoch is 0.0001 for optimizer
current performance: -38.9597, best performance: -32.3946
Epoch: 0077 | TRAIN: 2.3299 0.0625 0.2231 | 0.8073 0.8073 0.3789 | 0.2760 40.0476 38.6415 0.0520 0.2088 0.3427 TEST: 2.4621 0.0641 0.1979 | 0.8658 0.8472 1.2122 | 0.2698 39.5844 43.8156 5.1636 20.7738 34.2987
lr at 78th epoch is 0.0001 for optimizer
current performance: -40.2962, best performance: -32.3946
Epoch: 0078 | TRAIN: 2.4559 0.0554 0.1775 | 0.7902 0.7902 0.3794 | 0.2819 40.5279 39.2812 0.0537 0.2041 0.3319 TEST: 2.4201 0.0656 0.1305 | 0.9014 0.8825 1.2613 | 0.2732 39.5909 44.1853 5.8451 22.4021 35.5070
lr at 79th epoch is 0.0001 for optimizer
current performance: -42.4354, best performance: -32.3946
Epoch: 0079 | TRAIN: 2.3801 0.0577 0.1833 | 0.8054 0.8054 0.3845 | 0.2807 40.3584 39.0603 0.0563 0.2094 0.3389 TEST: 2.7487 0.0641 0.1502 | 0.9476 0.9286 1.3196 | 0.2721 39.5442 44.0642 6.1799 21.9580 35.0203
lr at 80th epoch is 0.0001 for optimizer
current performance: -39.7646, best performance: -32.3946
Epoch: 0080 | TRAIN: 2.5390 0.0555 0.1612 | 0.8053 0.8053 0.3758 | 0.2772 40.1377 38.7862 0.0539 0.2075 0.3385 TEST: 2.1208 0.0886 0.2408 | 0.9669 0.9482 1.3386 | 0.2656 39.1934 43.4775 5.5113 21.3539 35.0942
lr at 81th epoch is 0.0001 for optimizer
current performance: -37.3920, best performance: -32.3946
Epoch: 0081 | TRAIN: 2.3838 0.0619 0.1954 | 0.8011 0.8011 0.3804 | 0.2795 40.2927 38.9412 0.0551 0.2088 0.3384 TEST: 2.3078 0.0834 0.2215 | 0.9063 0.8874 1.2677 | 0.2648 38.8224 43.4365 6.7581 23.8715 36.7881
lr at 82th epoch is 0.0001 for optimizer
current performance: -45.7908, best performance: -32.3946
Epoch: 0082 | TRAIN: 2.5002 0.0558 0.1708 | 0.8091 0.8091 0.3805 | 0.2784 40.1971 38.8346 0.0552 0.2100 0.3400 TEST: 2.8129 0.0233 0.0594 | 0.8890 0.8703 1.2427 | 0.2757 40.1506 44.3128 4.9460 19.0954 32.4524
lr at 83th epoch is 0.0001 for optimizer
current performance: -30.4698, best performance: -32.3946
Epoch: 0083 | TRAIN: 2.3717 0.0627 0.2142 | 0.7991 0.7991 0.3730 | 0.2803 40.3996 39.1220 0.0534 0.2052 0.3339 TEST: 2.0718 0.1197 0.2929 | 0.8136 0.7979 1.1065 | 0.2768 40.2460 44.4634 4.6074 19.1205 32.9117
lr at 84th epoch is 0.0001 for optimizer
current performance: -40.2154, best performance: -30.4698
Epoch: 0084 | TRAIN: 2.3238 0.0647 0.1986 | 0.8181 0.8181 0.3914 | 0.2761 40.0361 38.7117 0.0552 0.2096 0.3402 TEST: 2.4771 0.0517 0.1383 | 0.8545 0.8362 1.2008 | 0.2706 39.7188 43.8826 4.9654 19.8717 33.5952
lr at 85th epoch is 0.0001 for optimizer
current performance: -43.1536, best performance: -30.4698
Epoch: 0085 | TRAIN: 2.3298 0.0604 0.1948 | 0.7973 0.7973 0.3806 | 0.2756 39.9839 38.7040 0.0554 0.2110 0.3425 TEST: 2.8092 0.0429 0.1018 | 0.9024 0.8835 1.2706 | 0.2676 39.5050 43.5949 5.3507 20.2032 33.6544
lr at 86th epoch is 0.0001 for optimizer
current performance: -36.5930, best performance: -30.4698
Epoch: 0086 | TRAIN: 2.3421 0.0634 0.1995 | 0.8128 0.8128 0.3786 | 0.2790 40.2679 39.1335 0.0552 0.2088 0.3367 TEST: 2.4559 0.0739 0.1937 | 0.8413 0.8233 1.1776 | 0.2680 39.5004 43.6517 5.0745 20.3085 33.9497
lr at 87th epoch is 0.0001 for optimizer
current performance: -43.7333, best performance: -30.4698
Epoch: 0087 | TRAIN: 2.3757 0.0642 0.2113 | 0.8126 0.8126 0.3819 | 0.2769 40.1071 38.8410 0.0546 0.2084 0.3392 TEST: 2.5626 0.0304 0.1349 | 0.8948 0.8761 1.2517 | 0.2637 38.8795 43.3278 6.2756 23.0361 36.1266
lr at 88th epoch is 0.0001 for optimizer
current performance: -40.0696, best performance: -30.4698
Epoch: 0088 | TRAIN: 2.3712 0.0629 0.2101 | 0.7978 0.7978 0.3762 | 0.2771 40.0114 38.6521 0.0589 0.2175 0.3454 TEST: 2.5090 0.0572 0.1242 | 0.8617 0.8436 1.2087 | 0.2724 39.9275 43.9956 5.0942 19.6153 32.7174
lr at 89th epoch is 0.0001 for optimizer
current performance: -39.1131, best performance: -30.4698
Epoch: 0089 | TRAIN: 2.3618 0.0670 0.2066 | 0.8147 0.8147 0.3919 | 0.2778 40.1998 38.9120 0.0527 0.2066 0.3382 TEST: 2.6614 0.0524 0.1191 | 0.8365 0.8188 1.1652 | 0.2679 39.4826 43.6265 5.3502 20.5871 34.0933
lr at 90th epoch is 0.0001 for optimizer
current performance: -33.5720, best performance: -30.4698
Epoch: 0090 | TRAIN: 2.4746 0.0645 0.1988 | 0.7989 0.7989 0.3914 | 0.2771 40.1347 38.9831 0.0538 0.2105 0.3380 TEST: 2.1560 0.1052 0.2585 | 0.8746 0.8562 1.2154 | 0.2668 39.1002 43.5925 6.4428 22.9533 35.7066
lr at 91th epoch is 0.0001 for optimizer
current performance: -35.6019, best performance: -30.4698
Epoch: 0091 | TRAIN: 2.4159 0.0642 0.2179 | 0.8055 0.8055 0.3778 | 0.2784 40.2172 38.8896 0.0534 0.2092 0.3395 TEST: 2.3684 0.0793 0.1895 | 0.8445 0.8267 1.1726 | 0.2684 39.0963 43.7719 6.8721 23.6101 36.3335
lr at 92th epoch is 0.0001 for optimizer
current performance: -37.2245, best performance: -30.4698
Epoch: 0092 | TRAIN: 2.3216 0.0672 0.2322 | 0.7916 0.7916 0.3756 | 0.2741 39.7378 38.4181 0.0598 0.2221 0.3511 TEST: 2.5433 0.0800 0.1776 | 0.8850 0.8663 1.2376 | 0.2661 39.1059 43.5254 5.9790 22.3567 35.5613
lr at 93th epoch is 0.0001 for optimizer
current performance: -36.0888, best performance: -30.4698
Epoch: 0093 | TRAIN: 2.5184 0.0618 0.2129 | 0.8076 0.8076 0.3791 | 0.2767 40.1000 38.7351 0.0533 0.2079 0.3402 TEST: 2.2612 0.0972 0.2243 | 0.8904 0.8718 1.2427 | 0.2707 39.8430 43.8519 4.8739 19.2887 32.6682
lr at 94th epoch is 0.0001 for optimizer
current performance: -39.5938, best performance: -30.4698
Epoch: 0094 | TRAIN: 2.4517 0.0680 0.2234 | 0.7930 0.7930 0.3722 | 0.2739 39.9002 38.5641 0.0531 0.2081 0.3400 TEST: 2.9561 0.0521 0.1383 | 0.8530 0.8348 1.1995 | 0.2665 39.2564 43.5335 5.7167 21.6326 34.6868
lr at 95th epoch is 0.0001 for optimizer
current performance: -32.9291, best performance: -30.4698
Epoch: 0095 | TRAIN: 2.4649 0.0705 0.2186 | 0.7859 0.7859 0.3914 | 0.2783 40.1828 38.9113 0.0557 0.2119 0.3404 TEST: 2.1679 0.1106 0.2533 | 0.8699 0.8514 1.2127 | 0.2681 39.3267 43.7249 5.4453 21.5924 35.1312
lr at 96th epoch is 0.0001 for optimizer
current performance: -36.2389, best performance: -30.4698
Epoch: 0096 | TRAIN: 2.4117 0.0720 0.2187 | 0.8020 0.8020 0.3839 | 0.2768 40.0994 38.7649 0.0542 0.2084 0.3397 TEST: 2.3039 0.0897 0.2497 | 0.8775 0.8588 1.2290 | 0.2691 39.6215 43.6949 5.4924 20.4579 33.0065
lr at 97th epoch is 0.0001 for optimizer
current performance: -37.9527, best performance: -30.4698
Epoch: 0097 | TRAIN: 2.4398 0.0710 0.2312 | 0.7971 0.7971 0.3737 | 0.2765 40.1142 38.9890 0.0537 0.2081 0.3362 TEST: 2.7044 0.0605 0.1320 | 0.8159 0.7990 1.1286 | 0.2735 40.1367 44.0636 4.8853 18.4408 31.5417
lr at 98th epoch is 0.0001 for optimizer
current performance: -34.3178, best performance: -30.4698
Epoch: 0098 | TRAIN: 2.5166 0.0694 0.2111 | 0.8068 0.8068 0.3941 | 0.2759 40.0751 38.7851 0.0520 0.2064 0.3379 TEST: 2.2096 0.0992 0.2510 | 0.8700 0.8512 1.2209 | 0.2678 39.2821 43.6763 5.7671 22.1521 35.1886
lr at 99th epoch is 0.0001 for optimizer
current performance: -32.4532, best performance: -30.4698
Epoch: 0099 | TRAIN: 2.4747 0.0735 0.2320 | 0.8139 0.8139 0.3806 | 0.2780 40.2393 38.9641 0.0521 0.2052 0.3360 TEST: 2.0988 0.1191 0.2849 | 0.8666 0.8481 1.2111 | 0.2736 40.0124 44.1206 4.8127 19.4452 32.8132
lr at 100th epoch is 5e-05 for optimizer
current performance: -36.9327, best performance: -30.4698
Epoch: 0100 | TRAIN: 2.4366 0.0754 0.2282 | 0.7908 0.7908 0.3795 | 0.2742 39.8982 38.8238 0.0543 0.2129 0.3431 TEST: 2.4709 0.0808 0.1826 | 0.8885 0.8698 1.2454 | 0.2627 38.7972 43.2200 6.4302 23.0563 35.9613
lr at 101th epoch is 5e-05 for optimizer
current performance: -38.7060, best performance: -30.4698
Epoch: 0101 | TRAIN: 2.3584 0.0865 0.2650 | 0.7864 0.7864 0.3714 | 0.2746 39.8856 38.6443 0.0560 0.2150 0.3437 TEST: 2.9247 0.0564 0.1427 | 0.8505 0.8324 1.1924 | 0.2640 39.0467 43.3029 5.8835 21.8423 34.8979
lr at 102th epoch is 5e-05 for optimizer
current performance: -37.2987, best performance: -30.4698
Epoch: 0102 | TRAIN: 2.3643 0.0819 0.2639 | 0.7866 0.7866 0.3711 | 0.2725 39.7237 38.3670 0.0565 0.2145 0.3463 TEST: 2.8362 0.0659 0.1670 | 0.8604 0.8421 1.2078 | 0.2613 38.4873 43.1411 7.3323 24.2783 36.9998
lr at 103th epoch is 5e-05 for optimizer
current performance: -35.7683, best performance: -30.4698
Epoch: 0103 | TRAIN: 2.4390 0.0805 0.2550 | 0.7868 0.7868 0.3790 | 0.2736 39.7755 38.4637 0.0571 0.2166 0.3478 TEST: 2.5251 0.0844 0.2253 | 0.8777 0.8592 1.2281 | 0.2604 38.5719 43.0247 6.7208 23.3810 36.3784
lr at 104th epoch is 5e-05 for optimizer
current performance: -35.3168, best performance: -30.4698
Epoch: 0104 | TRAIN: 2.4940 0.0855 0.2680 | 0.8025 0.8025 0.3764 | 0.2724 39.7573 38.5865 0.0552 0.2130 0.3434 TEST: 2.6519 0.0883 0.2026 | 0.8573 0.8390 1.1973 | 0.2661 39.4012 43.4302 5.5029 20.4274 33.3820
lr at 105th epoch is 5e-05 for optimizer
current performance: -36.3700, best performance: -30.4698
Epoch: 0105 | TRAIN: 2.5537 0.0762 0.2446 | 0.7826 0.7826 0.3860 | 0.2715 39.6223 38.3675 0.0584 0.2177 0.3472 TEST: 2.4138 0.0906 0.2154 | 0.9100 0.8912 1.2719 | 0.2598 38.5772 42.9483 6.6140 23.0596 35.9977
lr at 106th epoch is 5e-05 for optimizer
current performance: -36.2997, best performance: -30.4698
Epoch: 0106 | TRAIN: 2.5214 0.0782 0.2393 | 0.8068 0.8068 0.3734 | 0.2741 39.8451 38.6506 0.0570 0.2149 0.3443 TEST: 2.7918 0.0758 0.1702 | 0.8674 0.8489 1.2116 | 0.2598 38.4660 42.9828 7.0657 23.8587 36.6844
lr at 107th epoch is 5e-05 for optimizer
current performance: -39.4499, best performance: -30.4698
Epoch: 0107 | TRAIN: 2.5112 0.0779 0.2425 | 0.7919 0.7919 0.3776 | 0.2730 39.8053 38.5621 0.0546 0.2121 0.3431 TEST: 2.5654 0.0762 0.1774 | 0.9343 0.9152 1.3065 | 0.2610 38.7657 43.0407 6.1050 22.2236 35.4664
lr at 108th epoch is 5e-05 for optimizer
current performance: -34.4325, best performance: -30.4698
Epoch: 0108 | TRAIN: 2.5071 0.0773 0.2371 | 0.8021 0.8021 0.3681 | 0.2717 39.6172 38.3718 0.0581 0.2189 0.3495 TEST: 2.5412 0.0956 0.2032 | 0.8703 0.8517 1.2187 | 0.2625 38.9482 43.1766 5.7353 21.8374 35.2394
lr at 109th epoch is 5e-05 for optimizer
current performance: -34.0897, best performance: -30.4698
Epoch: 0109 | TRAIN: 2.5280 0.0778 0.2348 | 0.8077 0.8077 0.3889 | 0.2731 39.7584 38.6671 0.0572 0.2160 0.3466 TEST: 2.5068 0.0961 0.2026 | 0.8711 0.8526 1.2171 | 0.2604 38.6677 42.9857 6.4734 22.7476 35.8646
lr at 110th epoch is 5e-05 for optimizer
current performance: -36.6422, best performance: -30.4698
Epoch: 0110 | TRAIN: 2.4871 0.0786 0.2550 | 0.8097 0.8097 0.3841 | 0.2728 39.7517 38.4878 0.0568 0.2140 0.3455 TEST: 2.5660 0.0770 0.1944 | 0.8721 0.8535 1.2209 | 0.2603 38.7277 42.9650 6.0585 22.2084 35.4979
lr at 111th epoch is 5e-05 for optimizer
current performance: -34.0597, best performance: -30.4698
Epoch: 0111 | TRAIN: 2.4561 0.0855 0.2899 | 0.7898 0.7898 0.3861 | 0.2704 39.4943 38.1641 0.0594 0.2202 0.3517 TEST: 2.4321 0.0963 0.2590 | 0.8777 0.8591 1.2294 | 0.2591 38.4092 42.9128 6.8518 23.7518 36.9788
lr at 112th epoch is 5e-05 for optimizer
current performance: -35.8612, best performance: -30.4698
Epoch: 0112 | TRAIN: 2.6478 0.0864 0.2653 | 0.7934 0.7934 0.3848 | 0.2725 39.7497 38.5036 0.0563 0.2131 0.3442 TEST: 2.6699 0.0739 0.2050 | 0.8413 0.8232 1.1739 | 0.2621 38.8519 43.1318 6.2249 22.2090 35.2675
lr at 113th epoch is 5e-05 for optimizer
current performance: -32.9474, best performance: -30.4698
Epoch: 0113 | TRAIN: 2.6329 0.0849 0.2709 | 0.7937 0.7937 0.3809 | 0.2719 39.6178 38.3667 0.0596 0.2189 0.3494 TEST: 2.4050 0.1079 0.2584 | 0.8675 0.8492 1.2117 | 0.2647 39.1214 43.3691 5.6760 21.4330 34.9119
lr at 114th epoch is 5e-05 for optimizer
current performance: -37.0918, best performance: -30.4698
Epoch: 0114 | TRAIN: 2.6310 0.0820 0.2535 | 0.8081 0.8081 0.3906 | 0.2735 39.8161 38.5587 0.0563 0.2135 0.3441 TEST: 3.2712 0.0689 0.1481 | 0.8697 0.8513 1.2193 | 0.2586 38.2908 42.9076 7.3688 24.3806 37.3794
lr at 115th epoch is 5e-05 for optimizer
current performance: -32.7507, best performance: -30.4698
Epoch: 0115 | TRAIN: 2.7973 0.0808 0.2485 | 0.7938 0.7938 0.3832 | 0.2736 39.7860 38.4791 0.0583 0.2161 0.3452 TEST: 2.4604 0.1088 0.2507 | 0.8643 0.8457 1.2114 | 0.2657 39.1905 43.4917 5.6411 21.4485 34.8941
lr at 116th epoch is 5e-05 for optimizer
current performance: -40.0585, best performance: -30.4698
Epoch: 0116 | TRAIN: 2.6830 0.0855 0.2530 | 0.8033 0.8033 0.3843 | 0.2713 39.6185 38.3868 0.0581 0.2153 0.3467 TEST: 3.9266 0.0422 0.0986 | 0.8636 0.8450 1.2088 | 0.2575 38.1368 42.8136 7.7789 24.7933 37.6322
lr at 117th epoch is 5e-05 for optimizer
current performance: -35.9379, best performance: -30.4698
Epoch: 0117 | TRAIN: 2.7704 0.0832 0.2468 | 0.7947 0.7947 0.3822 | 0.2708 39.5325 38.1405 0.0589 0.2195 0.3515 TEST: 2.6777 0.0905 0.2007 | 0.8862 0.8674 1.2399 | 0.2634 39.1080 43.2376 5.4636 21.0010 34.4266
lr at 118th epoch is 5e-05 for optimizer
current performance: -33.8199, best performance: -30.4698
Epoch: 0118 | TRAIN: 2.6836 0.0896 0.2551 | 0.8013 0.8013 0.3721 | 0.2712 39.6918 38.4022 0.0542 0.2099 0.3422 TEST: 2.5526 0.1030 0.2400 | 0.8846 0.8657 1.2363 | 0.2608 38.7100 43.0343 6.3342 22.5586 35.6693
lr at 119th epoch is 5e-05 for optimizer
current performance: -37.5085, best performance: -30.4698
Epoch: 0119 | TRAIN: 2.6603 0.0927 0.2613 | 0.7936 0.7936 0.3776 | 0.2737 39.8749 38.5875 0.0554 0.2096 0.3409 TEST: 3.0159 0.0751 0.1872 | 0.9021 0.8833 1.2590 | 0.2574 38.1298 42.8147 7.8946 24.8268 37.6233
lr at 120th epoch is 5e-05 for optimizer
current performance: -40.1836, best performance: -30.4698
Epoch: 0120 | TRAIN: 2.7413 0.0909 0.2678 | 0.7936 0.7936 0.3735 | 0.2719 39.6518 38.4205 0.0598 0.2156 0.3450 TEST: 3.6045 0.0452 0.1459 | 0.8525 0.8344 1.1929 | 0.2632 39.0087 43.2244 5.8228 21.5862 34.9830
lr at 121th epoch is 5e-05 for optimizer
current performance: -36.8936, best performance: -30.4698
Epoch: 0121 | TRAIN: 2.8656 0.0789 0.2346 | 0.7944 0.7944 0.3873 | 0.2722 39.6627 38.3802 0.0595 0.2175 0.3480 TEST: 3.0442 0.0744 0.1724 | 0.8656 0.8471 1.2124 | 0.2633 38.9123 43.2820 6.0352 22.4408 35.6891
lr at 122th epoch is 5e-05 for optimizer
current performance: -41.4776, best performance: -30.4698
Epoch: 0122 | TRAIN: 2.8840 0.0857 0.2320 | 0.7902 0.7902 0.3896 | 0.2735 39.8085 38.5120 0.0562 0.2131 0.3442 TEST: 3.5030 0.0412 0.0812 | 0.8779 0.8591 1.2287 | 0.2614 38.7571 43.0961 6.1651 22.4952 35.7872
lr at 123th epoch is 5e-05 for optimizer
current performance: -38.3694, best performance: -30.4698
Epoch: 0123 | TRAIN: 2.8335 0.0808 0.2249 | 0.7985 0.7985 0.3815 | 0.2715 39.6130 38.2148 0.0575 0.2168 0.3499 TEST: 2.9424 0.0761 0.1354 | 0.9064 0.8874 1.2672 | 0.2632 38.8630 43.2750 6.3207 22.4290 35.7151
lr at 124th epoch is 5e-05 for optimizer
current performance: -32.7063, best performance: -30.4698
Epoch: 0124 | TRAIN: 2.9338 0.0837 0.2320 | 0.7914 0.7914 0.3679 | 0.2709 39.5817 38.1839 0.0568 0.2164 0.3480 TEST: 2.5323 0.1071 0.2486 | 0.8638 0.8454 1.2059 | 0.2629 38.9669 43.2183 5.8976 21.7646 34.9853
lr at 125th epoch is 5e-05 for optimizer
current performance: -36.0123, best performance: -30.4698
Epoch: 0125 | TRAIN: 2.8169 0.0849 0.2301 | 0.7992 0.7992 0.3876 | 0.2715 39.6028 38.2471 0.0579 0.2171 0.3491 TEST: 2.6020 0.0941 0.2209 | 0.9032 0.8842 1.2668 | 0.2621 38.9353 43.1146 5.9564 21.5315 34.7623
lr at 126th epoch is 5e-05 for optimizer
current performance: -39.7095, best performance: -30.4698
Epoch: 0126 | TRAIN: 2.8536 0.0821 0.2321 | 0.7998 0.7998 0.3778 | 0.2723 39.6908 38.4172 0.0585 0.2158 0.3470 TEST: 3.3152 0.0584 0.1277 | 0.8972 0.8784 1.2523 | 0.2577 38.3909 42.7837 6.5550 23.1612 36.5136
lr at 127th epoch is 5e-05 for optimizer
current performance: -39.8310, best performance: -30.4698
Epoch: 0127 | TRAIN: 2.9602 0.0848 0.2247 | 0.8075 0.8075 0.3844 | 0.2719 39.6659 38.3737 0.0581 0.2137 0.3451 TEST: 3.3914 0.0505 0.1121 | 0.8778 0.8591 1.2273 | 0.2577 38.3363 42.7867 6.9106 23.6147 36.7172
lr at 128th epoch is 5e-05 for optimizer
current performance: -35.4896, best performance: -30.4698
Epoch: 0128 | TRAIN: 2.9227 0.0835 0.2230 | 0.8039 0.8039 0.3789 | 0.2693 39.4678 38.1276 0.0579 0.2164 0.3494 TEST: 2.8588 0.0775 0.1510 | 0.8479 0.8297 1.1854 | 0.2619 38.6815 43.1805 6.6737 23.1506 36.1837
lr at 129th epoch is 5e-05 for optimizer
current performance: -37.8279, best performance: -30.4698
Epoch: 0129 | TRAIN: 2.9338 0.0864 0.2429 | 0.8143 0.8143 0.3850 | 0.2722 39.7417 38.5735 0.0575 0.2105 0.3408 TEST: 3.1924 0.0607 0.1533 | 0.8730 0.8544 1.2232 | 0.2543 37.8900 42.5131 7.8857 24.9751 37.8490
lr at 130th epoch is 5e-05 for optimizer
current performance: -35.3911, best performance: -30.4698
Epoch: 0130 | TRAIN: 2.7839 0.0868 0.2397 | 0.7904 0.7904 0.3867 | 0.2713 39.6534 38.3928 0.0573 0.2122 0.3431 TEST: 2.6577 0.0911 0.2066 | 0.8905 0.8716 1.2458 | 0.2601 38.5162 43.0081 6.9595 23.2704 36.3122
lr at 131th epoch is 5e-05 for optimizer
current performance: -41.0764, best performance: -30.4698
Epoch: 0131 | TRAIN: 2.8464 0.0883 0.2299 | 0.7962 0.7962 0.3747 | 0.2716 39.6839 38.4182 0.0577 0.2121 0.3417 TEST: 4.1663 0.0367 0.0788 | 0.8798 0.8612 1.2296 | 0.2532 37.7936 42.4488 7.7749 25.1554 38.2710
lr at 132th epoch is 5e-05 for optimizer
current performance: -39.6977, best performance: -30.4698
Epoch: 0132 | TRAIN: 2.9288 0.0864 0.2315 | 0.8002 0.8002 0.3781 | 0.2715 39.6129 38.1966 0.0587 0.2148 0.3469 TEST: 3.5841 0.0466 0.1068 | 0.8671 0.8486 1.2159 | 0.2562 38.1759 42.6591 7.1695 23.9394 37.0100
lr at 133th epoch is 5e-05 for optimizer
current performance: -38.9821, best performance: -30.4698
Epoch: 0133 | TRAIN: 3.0034 0.0821 0.2223 | 0.7949 0.7949 0.3819 | 0.2711 39.6130 38.2977 0.0576 0.2148 0.3463 TEST: 3.5204 0.0566 0.1024 | 0.8851 0.8662 1.2395 | 0.2547 38.0032 42.5264 7.3991 24.4212 37.4854
lr at 134th epoch is 5e-05 for optimizer
current performance: -37.1903, best performance: -30.4698
Epoch: 0134 | TRAIN: 2.8841 0.0855 0.2315 | 0.7754 0.7754 0.3720 | 0.2708 39.5748 38.2952 0.0590 0.2153 0.3466 TEST: 3.1470 0.0699 0.1448 | 0.8677 0.8490 1.2162 | 0.2611 38.5867 43.1035 7.0137 23.5077 36.3945
lr at 135th epoch is 5e-05 for optimizer
current performance: -37.0806, best performance: -30.4698
Epoch: 0135 | TRAIN: 3.0931 0.0861 0.2331 | 0.7850 0.7850 0.3732 | 0.2717 39.6542 38.3648 0.0586 0.2141 0.3448 TEST: 2.9526 0.0787 0.1491 | 0.8841 0.8654 1.2347 | 0.2616 38.8569 43.1079 5.9422 21.9114 35.2252
lr at 136th epoch is 5e-05 for optimizer
current performance: -32.8692, best performance: -30.4698
Epoch: 0136 | TRAIN: 2.9154 0.0859 0.2215 | 0.7766 0.7766 0.3698 | 0.2731 39.8361 38.5697 0.0569 0.2086 0.3381 TEST: 2.5657 0.1060 0.2240 | 0.8640 0.8455 1.2066 | 0.2627 38.9821 43.1797 5.8778 21.4428 34.6315
lr at 137th epoch is 5e-05 for optimizer
current performance: -38.2498, best performance: -30.4698
Epoch: 0137 | TRAIN: 2.8819 0.0895 0.2348 | 0.8016 0.8016 0.3910 | 0.2730 39.7752 38.6083 0.0589 0.2121 0.3409 TEST: 3.2399 0.0681 0.1369 | 0.8885 0.8698 1.2446 | 0.2609 38.5192 43.0968 7.3038 23.5981 36.4396
lr at 138th epoch is 5e-05 for optimizer
current performance: -40.1209, best performance: -30.4698
Epoch: 0138 | TRAIN: 2.8901 0.0890 0.2325 | 0.7966 0.7966 0.3845 | 0.2724 39.7089 38.3960 0.0585 0.2141 0.3448 TEST: 3.6789 0.0483 0.0902 | 0.8724 0.8538 1.2180 | 0.2605 38.5550 43.0620 6.7186 23.4077 36.5737
lr at 139th epoch is 5e-05 for optimizer
current performance: -37.1615, best performance: -30.4698
Epoch: 0139 | TRAIN: 2.9411 0.0829 0.2250 | 0.7903 0.7903 0.3762 | 0.2717 39.6749 38.4851 0.0589 0.2122 0.3421 TEST: 3.1022 0.0713 0.1416 | 0.8893 0.8703 1.2431 | 0.2537 37.8846 42.4286 7.8216 24.6256 37.5539
lr at 140th epoch is 5e-05 for optimizer
current performance: -38.5828, best performance: -30.4698
Epoch: 0140 | TRAIN: 2.8746 0.0894 0.2351 | 0.7804 0.7804 0.3670 | 0.2713 39.5982 38.2989 0.0601 0.2164 0.3465 TEST: 3.7244 0.0554 0.1089 | 0.8797 0.8611 1.2271 | 0.2527 37.7000 42.3699 8.4603 25.2896 38.0468
lr at 141th epoch is 5e-05 for optimizer
current performance: -35.7873, best performance: -30.4698
Epoch: 0141 | TRAIN: 2.8857 0.0915 0.2346 | 0.8202 0.8202 0.3897 | 0.2671 39.2291 37.8433 0.0621 0.2206 0.3523 TEST: 3.0581 0.0832 0.1636 | 0.8775 0.8588 1.2280 | 0.2583 38.4715 42.8166 6.5659 22.8966 36.1333
lr at 142th epoch is 5e-05 for optimizer
current performance: -31.7840, best performance: -30.4698
Epoch: 0142 | TRAIN: 2.9670 0.0895 0.2329 | 0.8075 0.8075 0.3884 | 0.2698 39.4684 38.2014 0.0615 0.2181 0.3468 TEST: 2.7839 0.1071 0.2178 | 0.8449 0.8268 1.1803 | 0.2624 38.8568 43.1532 6.5110 22.1336 34.9123
lr at 143th epoch is 5e-05 for optimizer
current performance: -35.8088, best performance: -30.4698
Epoch: 0143 | TRAIN: 3.0230 0.0876 0.2358 | 0.8052 0.8052 0.3946 | 0.2699 39.4920 38.2663 0.0610 0.2171 0.3470 TEST: 2.9662 0.0848 0.1732 | 0.8799 0.8612 1.2322 | 0.2594 38.5775 42.9234 6.5398 22.6568 35.7654
lr at 144th epoch is 5e-05 for optimizer
current performance: -35.9044, best performance: -30.4698
Epoch: 0144 | TRAIN: 3.1711 0.0891 0.2269 | 0.7832 0.7832 0.3777 | 0.2725 39.7650 38.5218 0.0571 0.2109 0.3416 TEST: 3.2852 0.0787 0.1650 | 0.8675 0.8490 1.2129 | 0.2577 38.4419 42.7859 6.4838 22.8833 36.1623
lr at 145th epoch is 5e-05 for optimizer
current performance: -39.3358, best performance: -30.4698
Epoch: 0145 | TRAIN: 3.1452 0.0899 0.2300 | 0.8051 0.8051 0.3902 | 0.2747 39.9844 38.7023 0.0543 0.2054 0.3357 TEST: 3.7629 0.0613 0.1281 | 0.9003 0.8817 1.2582 | 0.2569 38.2475 42.7143 7.4997 23.5418 36.4161
lr at 146th epoch is 5e-05 for optimizer
current performance: -34.4804, best performance: -30.4698
Epoch: 0146 | TRAIN: 3.0997 0.0868 0.2252 | 0.7965 0.7965 0.3814 | 0.2730 39.7890 38.7028 0.0583 0.2122 0.3401 TEST: 2.8424 0.0918 0.1926 | 0.8682 0.8496 1.2167 | 0.2606 38.6342 43.0254 6.8787 22.7853 35.6169
lr at 147th epoch is 5e-05 for optimizer
current performance: -37.7705, best performance: -30.4698
Epoch: 0147 | TRAIN: 3.0119 0.0897 0.2251 | 0.7987 0.7987 0.3802 | 0.2716 39.6417 38.4585 0.0607 0.2142 0.3420 TEST: 3.4496 0.0752 0.1494 | 0.8925 0.8738 1.2520 | 0.2607 38.7535 43.0111 6.1194 21.9500 35.1612
lr at 148th epoch is 5e-05 for optimizer
current performance: -37.7512, best performance: -30.4698
Epoch: 0148 | TRAIN: 3.1708 0.0925 0.2330 | 0.7814 0.7814 0.3775 | 0.2714 39.6429 38.4477 0.0595 0.2133 0.3418 TEST: 3.1531 0.0781 0.1481 | 0.9016 0.8826 1.2654 | 0.2602 38.7247 42.9693 6.1684 22.0237 35.1792
lr at 149th epoch is 5e-05 for optimizer
current performance: -36.0641, best performance: -30.4698
Epoch: 0149 | TRAIN: 3.0761 0.0912 0.2253 | 0.7874 0.7874 0.3734 | 0.2709 39.6068 38.4161 0.0591 0.2140 0.3430 TEST: 3.4772 0.0733 0.1439 | 0.8565 0.8380 1.1988 | 0.2577 38.3826 42.7554 7.0033 23.0748 36.1049
lr at 150th epoch is 5e-05 for optimizer
current performance: -37.4465, best performance: -30.4698
Epoch: 0150 | TRAIN: 2.9525 0.0906 0.2329 | 0.7872 0.7872 0.3758 | 0.2706 39.5776 38.3913 0.0605 0.2136 0.3422 TEST: 3.7173 0.0597 0.1151 | 0.8468 0.8283 1.1851 | 0.2574 38.4426 42.7177 6.6298 22.6032 35.7747
lr at 151th epoch is 5e-05 for optimizer
current performance: -33.7963, best performance: -30.4698
Epoch: 0151 | TRAIN: 3.0334 0.0938 0.2356 | 0.7813 0.7813 0.3752 | 0.2728 39.8076 38.6449 0.0590 0.2075 0.3361 TEST: 2.9992 0.0868 0.1635 | 0.8433 0.8251 1.1746 | 0.2599 38.4007 43.0066 7.5738 23.9441 36.6737
lr at 152th epoch is 5e-05 for optimizer
current performance: -34.4940, best performance: -30.4698
Epoch: 0152 | TRAIN: 2.9412 0.0905 0.2365 | 0.7952 0.7952 0.3832 | 0.2707 39.5816 38.3893 0.0598 0.2147 0.3440 TEST: 3.3104 0.0813 0.1537 | 0.8501 0.8316 1.1889 | 0.2550 38.1370 42.5240 7.0910 23.7002 36.7464
lr at 153th epoch is 5e-05 for optimizer
current performance: -36.7893, best performance: -30.4698
Epoch: 0153 | TRAIN: 2.8531 0.0961 0.2438 | 0.7991 0.7991 0.3844 | 0.2694 39.4874 38.2715 0.0603 0.2141 0.3436 TEST: 2.9952 0.0790 0.1544 | 0.8911 0.8723 1.2455 | 0.2582 38.3663 42.8188 7.2210 23.4136 36.3531
lr at 154th epoch is 5e-05 for optimizer
current performance: -35.6817, best performance: -30.4698
Epoch: 0154 | TRAIN: 2.9305 0.0932 0.2452 | 0.7869 0.7869 0.3731 | 0.2691 39.4200 38.2029 0.0629 0.2163 0.3458 TEST: 3.1020 0.0793 0.1548 | 0.8601 0.8412 1.2047 | 0.2608 38.6074 43.0685 6.8984 23.0657 35.9834
lr at 155th epoch is 5e-05 for optimizer
current performance: -34.2904, best performance: -30.4698
Epoch: 0155 | TRAIN: 3.0406 0.0896 0.2308 | 0.7760 0.7760 0.3721 | 0.2722 39.7592 38.4988 0.0577 0.2075 0.3376 TEST: 2.7635 0.0973 0.2157 | 0.8752 0.8565 1.2261 | 0.2613 38.8244 43.0654 6.3785 21.8021 34.6637
lr at 156th epoch is 5e-05 for optimizer
current performance: -38.4141, best performance: -30.4698
Epoch: 0156 | TRAIN: 3.0560 0.0987 0.2442 | 0.7863 0.7863 0.3743 | 0.2703 39.5727 38.3457 0.0594 0.2126 0.3423 TEST: 3.5694 0.0628 0.1294 | 0.8817 0.8628 1.2398 | 0.2571 38.3295 42.7335 6.8694 23.1917 36.3940
lr at 157th epoch is 5e-05 for optimizer
current performance: -38.4447, best performance: -30.4698
Epoch: 0157 | TRAIN: 3.2159 0.0937 0.2314 | 0.7955 0.7955 0.3757 | 0.2725 39.7924 38.5197 0.0570 0.2078 0.3367 TEST: 3.6644 0.0647 0.1304 | 0.9032 0.8847 1.2615 | 0.2541 37.7215 42.5282 8.5479 25.6377 38.5019
lr at 158th epoch is 5e-05 for optimizer
current performance: -34.7071, best performance: -30.4698
Epoch: 0158 | TRAIN: 3.0228 0.0936 0.2342 | 0.7996 0.7996 0.3824 | 0.2706 39.5850 38.3695 0.0600 0.2126 0.3407 TEST: 2.9335 0.0865 0.1726 | 0.8551 0.8367 1.1921 | 0.2600 38.7335 42.9613 6.1240 21.9770 35.1130
lr at 159th epoch is 5e-05 for optimizer
current performance: -33.1170, best performance: -30.4698
Epoch: 0159 | TRAIN: 2.9249 0.0956 0.2454 | 0.7999 0.7999 0.3866 | 0.2696 39.4684 38.2713 0.0616 0.2171 0.3440 TEST: 2.7584 0.1127 0.2183 | 0.8900 0.8713 1.2461 | 0.2631 38.9687 43.2326 6.3800 21.7480 34.6480
lr at 160th epoch is 5e-05 for optimizer
current performance: -37.3615, best performance: -30.4698
Epoch: 0160 | TRAIN: 2.9492 0.0995 0.2521 | 0.7933 0.7933 0.3685 | 0.2715 39.6940 38.5209 0.0589 0.2101 0.3381 TEST: 3.1355 0.0688 0.1439 | 0.8732 0.8545 1.2221 | 0.2578 38.3933 42.7706 6.9572 22.9877 35.9987
lr at 161th epoch is 5e-05 for optimizer
current performance: -31.1215, best performance: -30.4698
Epoch: 0161 | TRAIN: 3.0473 0.0941 0.2361 | 0.8062 0.8062 0.3869 | 0.2715 39.6505 38.4578 0.0613 0.2125 0.3388 TEST: 2.4735 0.1213 0.2687 | 0.8634 0.8449 1.2093 | 0.2642 39.1874 43.2843 5.6734 20.5683 33.6293
lr at 162th epoch is 5e-05 for optimizer
current performance: -30.1514, best performance: -30.4698
Epoch: 0162 | TRAIN: 2.9327 0.0968 0.2474 | 0.7962 0.7962 0.3787 | 0.2723 39.7526 38.5214 0.0581 0.2098 0.3388 TEST: 2.4898 0.1258 0.2804 | 0.8522 0.8338 1.1915 | 0.2664 39.2637 43.5178 5.9506 21.0075 34.1177
lr at 163th epoch is 5e-05 for optimizer
current performance: -39.9167, best performance: -30.1514
Epoch: 0163 | TRAIN: 3.0006 0.1046 0.2583 | 0.8055 0.8055 0.3886 | 0.2723 39.7641 38.5571 0.0577 0.2093 0.3380 TEST: 3.6261 0.0546 0.1196 | 0.9026 0.8837 1.2637 | 0.2544 37.9336 42.5180 7.6216 24.4040 37.6883
lr at 164th epoch is 5e-05 for optimizer
current performance: -33.4494, best performance: -30.1514
Epoch: 0164 | TRAIN: 3.1396 0.0943 0.2385 | 0.7958 0.7958 0.3839 | 0.2731 39.7865 38.5158 0.0590 0.2108 0.3400 TEST: 2.9456 0.1102 0.2082 | 0.8930 0.8740 1.2502 | 0.2620 38.8713 43.1026 6.2806 21.7342 34.8224
lr at 165th epoch is 5e-05 for optimizer
current performance: -32.1283, best performance: -30.1514
Epoch: 0165 | TRAIN: 3.1333 0.1006 0.2415 | 0.7928 0.7928 0.3731 | 0.2702 39.5350 38.3065 0.0608 0.2151 0.3435 TEST: 2.9538 0.1064 0.2101 | 0.8499 0.8315 1.1893 | 0.2620 38.9053 43.1020 6.2645 21.5007 34.4063
lr at 166th epoch is 5e-05 for optimizer
current performance: -39.2456, best performance: -30.1514
Epoch: 0166 | TRAIN: 3.1402 0.0975 0.2337 | 0.7880 0.7880 0.3721 | 0.2712 39.6473 38.3907 0.0603 0.2107 0.3390 TEST: 3.8720 0.0596 0.0945 | 0.8803 0.8615 1.2369 | 0.2619 38.7700 43.1534 6.5897 22.2927 35.3626
lr at 167th epoch is 5e-05 for optimizer
current performance: -34.7430, best performance: -30.1514
Epoch: 0167 | TRAIN: 3.1146 0.0977 0.2356 | 0.7924 0.7924 0.3724 | 0.2707 39.5939 38.5138 0.0607 0.2137 0.3404 TEST: 2.9889 0.0867 0.1638 | 0.8618 0.8433 1.2052 | 0.2581 38.5329 42.7884 6.4074 22.2363 35.3982
lr at 168th epoch is 5e-05 for optimizer
current performance: -34.1860, best performance: -30.1514
Epoch: 0168 | TRAIN: 3.1208 0.1015 0.2419 | 0.7911 0.7911 0.3822 | 0.2700 39.5723 38.3987 0.0585 0.2110 0.3406 TEST: 3.0440 0.0976 0.1719 | 0.8767 0.8580 1.2283 | 0.2598 38.7165 42.9110 6.2733 21.7973 34.8197
lr at 169th epoch is 5e-05 for optimizer
current performance: -34.3561, best performance: -30.1514
Epoch: 0169 | TRAIN: 3.1339 0.0962 0.2310 | 0.7856 0.7856 0.3772 | 0.2717 39.6913 38.4472 0.0591 0.2106 0.3389 TEST: 3.2788 0.0891 0.1797 | 0.8526 0.8342 1.1911 | 0.2613 38.8152 43.0579 6.2740 21.6796 34.7567
lr at 170th epoch is 5e-05 for optimizer
current performance: -38.2951, best performance: -30.1514
Epoch: 0170 | TRAIN: 3.1498 0.0970 0.2332 | 0.7908 0.7908 0.3842 | 0.2727 39.8118 38.6226 0.0582 0.2078 0.3344 TEST: 3.3938 0.0616 0.1191 | 0.8671 0.8487 1.2168 | 0.2586 38.6389 42.8174 6.0686 21.8376 35.1746
lr at 171th epoch is 5e-05 for optimizer
current performance: -33.6627, best performance: -30.1514
Epoch: 0171 | TRAIN: 3.1075 0.0940 0.2270 | 0.7930 0.7930 0.3731 | 0.2707 39.6224 38.4428 0.0590 0.2100 0.3401 TEST: 2.8255 0.0905 0.1740 | 0.8573 0.8388 1.1984 | 0.2562 38.1717 42.6508 7.4809 23.6697 36.4740
lr at 172th epoch is 5e-05 for optimizer
current performance: -39.1797, best performance: -30.1514
Epoch: 0172 | TRAIN: 3.0981 0.0998 0.2439 | 0.7845 0.7845 0.3750 | 0.2704 39.5787 38.3845 0.0605 0.2121 0.3400 TEST: 4.4114 0.0452 0.0735 | 0.8322 0.8143 1.1645 | 0.2621 38.8850 43.1492 6.1945 21.8300 34.7490
lr at 173th epoch is 5e-05 for optimizer
current performance: -36.0275, best performance: -30.1514
Epoch: 0173 | TRAIN: 3.0188 0.0967 0.2386 | 0.7994 0.7994 0.3820 | 0.2723 39.7461 38.5476 0.0595 0.2093 0.3385 TEST: 3.3225 0.0778 0.1327 | 0.8618 0.8434 1.2085 | 0.2595 38.6652 42.9029 6.3477 22.1486 35.0973
lr at 174th epoch is 5e-05 for optimizer
current performance: -33.3291, best performance: -30.1514
Epoch: 0174 | TRAIN: 2.9609 0.1014 0.2440 | 0.7883 0.7883 0.3664 | 0.2687 39.4628 38.2885 0.0594 0.2120 0.3415 TEST: 3.1961 0.0976 0.1749 | 0.8653 0.8469 1.2093 | 0.2581 38.3713 42.8176 6.9651 23.2196 36.3262
lr at 175th epoch is 5e-05 for optimizer
current performance: -36.3543, best performance: -30.1514
Epoch: 0175 | TRAIN: 3.1606 0.1040 0.2457 | 0.7845 0.7845 0.3792 | 0.2710 39.6469 38.3653 0.0581 0.2110 0.3399 TEST: 3.3937 0.0720 0.1258 | 0.8500 0.8316 1.1908 | 0.2610 38.7528 43.0468 6.3293 22.0249 35.1531
lr at 176th epoch is 5e-05 for optimizer
current performance: -36.8996, best performance: -30.1514
Epoch: 0176 | TRAIN: 3.0932 0.1009 0.2403 | 0.7851 0.7851 0.3792 | 0.2698 39.5599 38.3078 0.0588 0.2102 0.3413 TEST: 3.6890 0.0668 0.1346 | 0.8589 0.8402 1.2025 | 0.2565 38.3036 42.6646 6.8400 23.0731 36.2295
lr at 177th epoch is 5e-05 for optimizer
current performance: -34.8438, best performance: -30.1514
Epoch: 0177 | TRAIN: 3.2039 0.1053 0.2460 | 0.7936 0.7936 0.3766 | 0.2707 39.6509 38.5466 0.0585 0.2085 0.3376 TEST: 3.4758 0.0772 0.1316 | 0.8497 0.8314 1.1855 | 0.2544 37.9917 42.5135 7.4702 24.1433 37.3069
lr at 178th epoch is 5e-05 for optimizer
current performance: -35.5620, best performance: -30.1514
Epoch: 0178 | TRAIN: 3.0127 0.1065 0.2623 | 0.7759 0.7759 0.3802 | 0.2730 39.8478 38.6553 0.0565 0.2061 0.3341 TEST: 3.2948 0.0756 0.1536 | 0.8583 0.8399 1.2030 | 0.2550 38.1217 42.5276 7.2919 23.5756 36.5179
lr at 179th epoch is 5e-05 for optimizer
current performance: -33.6489, best performance: -30.1514
Epoch: 0179 | TRAIN: 3.0893 0.1030 0.2537 | 0.7823 0.7823 0.3777 | 0.2679 39.3462 38.1051 0.0624 0.2148 0.3437 TEST: 2.7982 0.0995 0.2057 | 0.8558 0.8371 1.2013 | 0.2648 39.2655 43.3535 5.4151 20.1670 33.4237
lr at 180th epoch is 5e-05 for optimizer
current performance: -36.8902, best performance: -30.1514
Epoch: 0180 | TRAIN: 2.9404 0.1041 0.2546 | 0.7931 0.7931 0.3841 | 0.2701 39.5963 38.3856 0.0591 0.2096 0.3378 TEST: 3.1493 0.0710 0.1527 | 0.8581 0.8396 1.2001 | 0.2601 38.8082 42.9455 5.7409 21.2308 34.6936
lr at 181th epoch is 5e-05 for optimizer
current performance: -35.5505, best performance: -30.1514
Epoch: 0181 | TRAIN: 3.0039 0.1070 0.2564 | 0.8039 0.8039 0.3927 | 0.2707 39.6633 38.5695 0.0595 0.2068 0.3356 TEST: 3.1314 0.0718 0.1539 | 0.8435 0.8252 1.1782 | 0.2553 38.2535 42.5396 6.7201 22.8016 35.9624
lr at 182th epoch is 5e-05 for optimizer
current performance: -35.6737, best performance: -30.1514
Epoch: 0182 | TRAIN: 3.0619 0.1074 0.2577 | 0.7949 0.7949 0.3885 | 0.2733 39.9003 38.8703 0.0581 0.2043 0.3301 TEST: 3.0901 0.0756 0.1838 | 0.8574 0.8388 1.2029 | 0.2559 38.2714 42.6102 6.9198 22.8654 35.9839
lr at 183th epoch is 5e-05 for optimizer
current performance: -34.1333, best performance: -30.1514
Epoch: 0183 | TRAIN: 3.2650 0.1058 0.2489 | 0.7763 0.7763 0.3766 | 0.2701 39.6368 38.4137 0.0574 0.2056 0.3351 TEST: 2.9906 0.0885 0.1762 | 0.8689 0.8503 1.2160 | 0.2538 37.9153 42.4591 7.8217 24.2827 37.1910
lr at 184th epoch is 5e-05 for optimizer
current performance: -31.0325, best performance: -30.1514
Epoch: 0184 | TRAIN: 3.3844 0.1063 0.2472 | 0.7769 0.7769 0.3717 | 0.2676 39.3686 38.1544 0.0613 0.2135 0.3418 TEST: 2.7548 0.1162 0.2241 | 0.8549 0.8366 1.1947 | 0.2614 38.8448 43.0667 6.5474 21.6131 34.3809
lr at 185th epoch is 5e-05 for optimizer
current performance: -38.3522, best performance: -30.1514
Epoch: 0185 | TRAIN: 3.1501 0.1046 0.2469 | 0.7904 0.7904 0.3831 | 0.2715 39.7229 38.6302 0.0602 0.2075 0.3337 TEST: 3.5395 0.0507 0.1156 | 0.8449 0.8264 1.1810 | 0.2560 38.3055 42.6071 6.8493 22.8443 35.8552
lr at 186th epoch is 5e-05 for optimizer
current performance: -36.7211, best performance: -30.1514
Epoch: 0186 | TRAIN: 3.2043 0.1082 0.2521 | 0.7876 0.7876 0.3814 | 0.2710 39.6819 38.6726 0.0605 0.2087 0.3342 TEST: 3.2822 0.0625 0.1327 | 0.8490 0.8306 1.1894 | 0.2530 38.0226 42.3457 6.9340 23.2044 36.5915
lr at 187th epoch is 5e-05 for optimizer
current performance: -38.8194, best performance: -30.1514
Epoch: 0187 | TRAIN: 3.1478 0.1059 0.2503 | 0.7970 0.7970 0.3831 | 0.2699 39.5624 38.4489 0.0600 0.2114 0.3389 TEST: 4.0594 0.0409 0.0690 | 0.8415 0.8230 1.1818 | 0.2511 37.7332 42.2104 7.6050 24.4370 37.5731
lr at 188th epoch is 5e-05 for optimizer
current performance: -35.0106, best performance: -30.1514
Epoch: 0188 | TRAIN: 3.1806 0.1039 0.2548 | 0.7801 0.7801 0.3828 | 0.2698 39.5703 38.4009 0.0587 0.2100 0.3384 TEST: 3.6716 0.0772 0.1579 | 0.8611 0.8426 1.2087 | 0.2524 37.7117 42.3766 8.1178 25.0688 38.1195
lr at 189th epoch is 5e-05 for optimizer
current performance: -35.0239, best performance: -30.1514
Epoch: 0189 | TRAIN: 3.1785 0.1158 0.2738 | 0.7855 0.7855 0.3778 | 0.2699 39.5426 38.4461 0.0612 0.2127 0.3401 TEST: 3.0234 0.0926 0.1963 | 0.8854 0.8667 1.2383 | 0.2597 38.5542 42.9644 6.9155 22.6301 35.6997
lr at 190th epoch is 5e-05 for optimizer
current performance: -34.1927, best performance: -30.1514
Epoch: 0190 | TRAIN: 3.1997 0.1130 0.2644 | 0.7808 0.7808 0.3715 | 0.2709 39.6213 38.4418 0.0607 0.2112 0.3387 TEST: 3.4297 0.0815 0.1664 | 0.8218 0.8040 1.1483 | 0.2617 38.9636 43.0887 6.0223 20.9636 33.9627
lr at 191th epoch is 5e-05 for optimizer
current performance: -34.4258, best performance: -30.1514
Epoch: 0191 | TRAIN: 3.1774 0.1082 0.2593 | 0.7736 0.7736 0.3791 | 0.2692 39.5192 38.2488 0.0592 0.2098 0.3383 TEST: 3.0828 0.0821 0.1619 | 0.8305 0.8125 1.1605 | 0.2615 38.9240 43.0700 6.0205 21.0835 34.2097
lr at 192th epoch is 5e-05 for optimizer
current performance: -36.6031, best performance: -30.1514
Epoch: 0192 | TRAIN: 3.1394 0.1082 0.2618 | 0.7768 0.7768 0.3821 | 0.2706 39.6441 38.4603 0.0585 0.2082 0.3362 TEST: 3.4708 0.0722 0.1414 | 0.8610 0.8425 1.2087 | 0.2581 38.5692 42.7996 6.1535 21.8711 35.3899
lr at 193th epoch is 5e-05 for optimizer
current performance: -36.6266, best performance: -30.1514
Epoch: 0193 | TRAIN: 3.2764 0.1077 0.2547 | 0.7955 0.7955 0.3927 | 0.2690 39.4728 38.2945 0.0602 0.2129 0.3412 TEST: 3.2704 0.0712 0.1474 | 0.8526 0.8342 1.1941 | 0.2604 38.8055 43.0073 6.0026 21.4432 34.8570
lr at 194th epoch is 5e-05 for optimizer
current performance: -35.9852, best performance: -30.1514
Epoch: 0194 | TRAIN: 3.2263 0.1101 0.2590 | 0.7811 0.7811 0.3730 | 0.2714 39.7440 38.6021 0.0578 0.2052 0.3331 TEST: 3.2240 0.0810 0.1611 | 0.8426 0.8244 1.1804 | 0.2689 39.7361 43.6786 5.0742 19.0400 31.9004
lr at 195th epoch is 5e-05 for optimizer
current performance: -31.7065, best performance: -30.1514
Epoch: 0195 | TRAIN: 3.0417 0.1085 0.2526 | 0.7651 0.7651 0.3740 | 0.2718 39.7532 38.7761 0.0586 0.2085 0.3352 TEST: 2.9295 0.1100 0.2288 | 0.8565 0.8381 1.2002 | 0.2603 38.6797 42.9881 6.9227 22.2293 34.8452
lr at 196th epoch is 5e-05 for optimizer
current performance: -37.0199, best performance: -30.1514
Epoch: 0196 | TRAIN: 3.1815 0.1152 0.2686 | 0.7811 0.7811 0.3756 | 0.2696 39.5429 38.4434 0.0603 0.2114 0.3383 TEST: 4.0211 0.0536 0.1179 | 0.8181 0.8003 1.1373 | 0.2580 38.4485 42.7948 6.5698 22.7618 36.0278
lr at 197th epoch is 5e-05 for optimizer
current performance: -32.2342, best performance: -30.1514
Epoch: 0197 | TRAIN: 3.2032 0.1127 0.2578 | 0.7821 0.7821 0.3828 | 0.2688 39.4432 38.2765 0.0614 0.2138 0.3420 TEST: 2.7314 0.1133 0.2536 | 0.8599 0.8414 1.2014 | 0.2658 39.4101 43.4240 5.4823 19.8747 32.7030
lr at 198th epoch is 5e-05 for optimizer
current performance: -34.5439, best performance: -30.1514
Epoch: 0198 | TRAIN: 3.1271 0.1139 0.2623 | 0.7758 0.7758 0.3859 | 0.2706 39.6850 38.4181 0.0564 0.2055 0.3351 TEST: 2.9724 0.0857 0.1848 | 0.8588 0.8402 1.2033 | 0.2574 38.3604 42.7557 6.8073 22.9780 36.1896
lr at 199th epoch is 5e-05 for optimizer
current performance: -38.1973, best performance: -30.1514
Epoch: 0199 | TRAIN: 3.1184 0.1109 0.2583 | 0.7834 0.7834 0.3858 | 0.2714 39.6879 38.4939 0.0593 0.2101 0.3370 TEST: 3.1978 0.0646 0.1357 | 0.8647 0.8462 1.2120 | 0.2619 38.9906 43.1099 5.7327 20.7809 34.0300
Epoch: 0162 | TRAIN: 2.9327 0.0968 0.2474 | 0.7962 0.7962 0.3787 | 0.2723 39.7526 38.5214 0.0581 0.2098 0.3388 TEST: 2.4898 0.1258 0.2804 | 0.8522 0.8338 1.1915 | 0.2664 39.2637 43.5178 5.9506 21.0075 34.1177
