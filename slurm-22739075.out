
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/scratch_tmp/grp/grv_shi/k21220263/MTPSL/nyu_mtl_xtc.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  labels_weights = torch.load('{}onelabel.pth'.format(opt.labelroot))['labels_weights'].float().cuda()
Parameter Space: ABS: 42884943.0, REL: 1.7167

LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR ROOT_MSE | NORMAL_LOSS MEAN MED <11.25 <22.5 <30

lr at 0th epoch is 0.0001 for optimizer
current performance: -52.8278, best performance: -100.0000
Epoch: 0000 | TRAIN: 1.6494 0.0184 0.0819 | 1.4968 1.4968 0.7607 | 0.3560 46.5872 45.6218 0.0330 0.1373 0.2388 TEST: 2.7986 0.0053 0.0570 | 0.8888 0.8740 1.1830 | 0.3237 44.2739 48.2826 4.1486 14.5003 23.9008
lr at 1th epoch is 0.0001 for optimizer
current performance: -49.3533, best performance: -52.8278
Epoch: 0001 | TRAIN: 1.3871 0.0205 0.0805 | 1.0243 1.0243 0.5092 | 0.3325 44.6590 43.4934 0.0413 0.1559 0.2632 TEST: 2.6054 0.0058 0.0584 | 0.8363 0.8205 1.1222 | 0.3146 43.2856 47.7104 4.1512 16.2283 27.8740
lr at 2th epoch is 0.0001 for optimizer
current performance: -55.2044, best performance: -49.3533
Epoch: 0002 | TRAIN: 1.2237 0.0185 0.0727 | 0.9462 0.9462 0.4652 | 0.3262 44.1801 43.1636 0.0424 0.1599 0.2705 TEST: 2.9625 0.0052 0.0583 | 0.9754 0.9569 1.3500 | 0.3097 43.1768 47.1380 4.1349 14.7713 25.4042
lr at 3th epoch is 0.0001 for optimizer
current performance: -51.5521, best performance: -49.3533
Epoch: 0003 | TRAIN: 1.2293 0.0193 0.0749 | 0.9247 0.9247 0.4568 | 0.3228 43.9131 42.6490 0.0412 0.1615 0.2748 TEST: 3.1126 0.0042 0.0551 | 0.8909 0.8742 1.1882 | 0.3094 42.9970 47.2222 3.7044 15.1909 27.2751
lr at 4th epoch is 0.0001 for optimizer
current performance: -49.1981, best performance: -49.3533
Epoch: 0004 | TRAIN: 1.2146 0.0202 0.0774 | 0.9255 0.9255 0.4614 | 0.3211 43.6824 42.3195 0.0449 0.1679 0.2824 TEST: 3.5839 0.0042 0.0551 | 0.8547 0.8377 1.1661 | 0.3132 42.2933 47.8517 6.2328 22.0167 34.1138
lr at 5th epoch is 0.0001 for optimizer
current performance: -53.8548, best performance: -49.1981
Epoch: 0005 | TRAIN: 1.2073 0.0212 0.0816 | 0.9035 0.9035 0.4394 | 0.3168 43.3264 42.0175 0.0461 0.1729 0.2887 TEST: 2.4473 0.0043 0.0553 | 0.9434 0.9267 1.3067 | 0.3095 43.0348 47.1547 4.6557 15.9551 26.6922
lr at 6th epoch is 0.0001 for optimizer
current performance: -50.4396, best performance: -49.1981
Epoch: 0006 | TRAIN: 1.2056 0.0229 0.0847 | 0.8916 0.8916 0.4300 | 0.3190 43.5079 42.0281 0.0435 0.1703 0.2879 TEST: 2.5076 0.0058 0.0578 | 0.8846 0.8675 1.2395 | 0.3028 42.4303 46.6159 4.6300 16.7071 28.2211
lr at 7th epoch is 0.0001 for optimizer
current performance: -50.2385, best performance: -49.1981
Epoch: 0007 | TRAIN: 1.1869 0.0198 0.0746 | 0.8934 0.8934 0.4350 | 0.3124 42.9372 41.6773 0.0487 0.1804 0.2966 TEST: 4.5037 0.0042 0.0551 | 0.8491 0.8358 1.1084 | 0.3138 43.3077 47.4864 4.9217 16.3170 26.0186
lr at 8th epoch is 0.0001 for optimizer
current performance: -47.1013, best performance: -49.1981
Epoch: 0008 | TRAIN: 1.1746 0.0193 0.0748 | 0.8514 0.8514 0.4110 | 0.3080 42.4916 41.0302 0.0505 0.1903 0.3100 TEST: 2.5574 0.0060 0.0604 | 0.8555 0.8386 1.1715 | 0.2892 40.5723 45.6933 6.4501 23.1910 35.5564
lr at 9th epoch is 0.0001 for optimizer
current performance: -48.2160, best performance: -47.1013
Epoch: 0009 | TRAIN: 1.1693 0.0239 0.0871 | 0.8565 0.8565 0.4246 | 0.3069 42.4258 40.8826 0.0509 0.1884 0.3079 TEST: 2.6078 0.0052 0.0583 | 0.8708 0.8534 1.2079 | 0.2887 40.9088 45.5535 5.2739 20.4523 33.3900
lr at 10th epoch is 0.0001 for optimizer
current performance: -51.9456, best performance: -47.1013
Epoch: 0010 | TRAIN: 1.1533 0.0195 0.0739 | 0.8310 0.8310 0.4027 | 0.3016 41.8883 40.2865 0.0548 0.2001 0.3226 TEST: 2.4944 0.0256 0.0936 | 1.0321 1.0172 1.3855 | 0.2882 40.2425 45.6787 7.7638 24.2450 36.6606
lr at 11th epoch is 0.0001 for optimizer
current performance: -46.3794, best performance: -47.1013
Epoch: 0011 | TRAIN: 1.1709 0.0263 0.0885 | 0.8409 0.8409 0.4127 | 0.2974 41.5109 39.7996 0.0573 0.2068 0.3292 TEST: 2.8544 0.0063 0.0594 | 0.8460 0.8300 1.1557 | 0.2821 40.2911 45.0259 5.4190 21.2173 34.7428
lr at 12th epoch is 0.0001 for optimizer
current performance: -45.0618, best performance: -46.3794
Epoch: 0012 | TRAIN: 1.1804 0.0254 0.0877 | 0.8128 0.8128 0.4009 | 0.2913 40.9333 38.9725 0.0609 0.2172 0.3429 TEST: 2.8650 0.0043 0.0551 | 0.8353 0.8187 1.1467 | 0.2723 39.3054 44.1716 7.2453 23.7726 36.2893
lr at 13th epoch is 0.0001 for optimizer
current performance: -44.7129, best performance: -45.0618
Epoch: 0013 | TRAIN: 1.1625 0.0261 0.0855 | 0.8039 0.8039 0.3896 | 0.2884 40.5989 38.6049 0.0647 0.2270 0.3533 TEST: 2.8779 0.0045 0.0555 | 0.8064 0.7986 1.0555 | 0.2753 39.8065 44.3543 6.2309 21.6898 34.4759
lr at 14th epoch is 0.0001 for optimizer
current performance: -40.9332, best performance: -44.7129
Epoch: 0014 | TRAIN: 1.1100 0.0225 0.0814 | 0.7668 0.7668 0.3660 | 0.2814 39.9519 37.9768 0.0706 0.2376 0.3651 TEST: 2.3997 0.0051 0.0575 | 0.7629 0.7491 1.0256 | 0.2618 38.3962 43.2180 7.8565 25.1978 37.9017
lr at 15th epoch is 0.0001 for optimizer
current performance: -34.6835, best performance: -40.9332
Epoch: 0015 | TRAIN: 1.1185 0.0218 0.0764 | 0.7531 0.7531 0.3660 | 0.2773 39.5767 37.6436 0.0744 0.2453 0.3714 TEST: 2.0739 0.0768 0.2181 | 0.8514 0.8362 1.1555 | 0.2579 37.6157 43.0288 9.7459 28.1703 40.8608
lr at 16th epoch is 0.0001 for optimizer
current performance: -38.0666, best performance: -34.6835
Epoch: 0016 | TRAIN: 1.1246 0.0281 0.0904 | 0.7276 0.7276 0.3550 | 0.2729 39.1096 36.9723 0.0789 0.2546 0.3823 TEST: 2.4829 0.0097 0.0679 | 0.7235 0.7085 1.0079 | 0.2592 37.9124 43.0862 8.9908 27.0829 39.6756
lr at 17th epoch is 0.0001 for optimizer
current performance: -50.4820, best performance: -34.6835
Epoch: 0017 | TRAIN: 1.1031 0.0300 0.0945 | 0.7194 0.7194 0.3444 | 0.2672 38.5761 36.3358 0.0843 0.2648 0.3923 TEST: 2.8013 0.0249 0.1264 | 0.9542 0.9491 1.1584 | 0.2961 41.4887 46.2093 5.3039 19.5430 32.2694
lr at 18th epoch is 0.0001 for optimizer
current performance: -35.7083, best performance: -34.6835
Epoch: 0018 | TRAIN: 1.0871 0.0300 0.0911 | 0.6949 0.6949 0.3380 | 0.2676 38.5711 36.2933 0.0859 0.2661 0.3937 TEST: 2.6738 0.0074 0.0593 | 0.6816 0.6679 0.9458 | 0.2518 37.1139 42.4331 10.3030 28.6735 41.1322
lr at 19th epoch is 0.0001 for optimizer
current performance: -43.2245, best performance: -34.6835
Epoch: 0019 | TRAIN: 1.0973 0.0286 0.0919 | 0.6755 0.6755 0.3234 | 0.2633 38.1982 35.8414 0.0882 0.2703 0.4007 TEST: 2.8878 0.0043 0.0553 | 0.8314 0.8184 1.1038 | 0.2604 37.6718 43.2878 10.4018 28.4367 41.0539
lr at 20th epoch is 0.0001 for optimizer
current performance: -36.0538, best performance: -34.6835
Epoch: 0020 | TRAIN: 1.0925 0.0334 0.0987 | 0.6635 0.6635 0.3180 | 0.2622 38.0231 35.4042 0.0903 0.2772 0.4077 TEST: 3.1417 0.0048 0.0552 | 0.6787 0.6663 0.9509 | 0.2485 37.1856 42.0952 8.3624 27.1778 40.6009
lr at 21th epoch is 0.0001 for optimizer
current performance: -35.8077, best performance: -34.6835
Epoch: 0021 | TRAIN: 1.0846 0.0337 0.0972 | 0.6344 0.6344 0.3086 | 0.2534 37.2220 34.6595 0.0974 0.2898 0.4217 TEST: 2.6513 0.0243 0.1206 | 0.7264 0.7141 1.0256 | 0.2544 37.3453 42.7570 9.0884 28.6153 41.7693
lr at 22th epoch is 0.0001 for optimizer
current performance: -41.0320, best performance: -34.6835
Epoch: 0022 | TRAIN: 1.0538 0.0352 0.0983 | 0.6223 0.6223 0.3024 | 0.2509 37.0227 34.4395 0.0986 0.2917 0.4231 TEST: 2.7633 0.0060 0.0585 | 0.8326 0.8184 1.1491 | 0.2390 35.8822 41.3305 10.9419 31.0072 44.0799
lr at 23th epoch is 0.0001 for optimizer
current performance: -27.2870, best performance: -34.6835
Epoch: 0023 | TRAIN: 1.0339 0.0360 0.1024 | 0.6327 0.6327 0.3065 | 0.2468 36.5237 33.6678 0.1060 0.3049 0.4386 TEST: 2.3382 0.0505 0.1156 | 0.6485 0.6381 0.8949 | 0.2366 35.6393 41.1261 11.8979 31.7797 44.3555
lr at 24th epoch is 0.0001 for optimizer
current performance: -32.2494, best performance: -27.2870
Epoch: 0024 | TRAIN: 1.0322 0.0372 0.1014 | 0.6057 0.6057 0.2891 | 0.2416 36.0804 33.2520 0.1078 0.3099 0.4451 TEST: 2.4653 0.0576 0.1187 | 0.8006 0.7895 1.0587 | 0.2323 35.0227 40.8666 11.5793 34.0661 47.2141
lr at 25th epoch is 0.0001 for optimizer
current performance: -31.1163, best performance: -27.2870
Epoch: 0025 | TRAIN: 1.0348 0.0374 0.1019 | 0.5801 0.5801 0.2741 | 0.2405 35.8914 32.8781 0.1136 0.3179 0.4505 TEST: 2.5579 0.0106 0.0661 | 0.6413 0.6338 0.8631 | 0.2284 34.6684 40.4551 12.8396 34.2372 47.1847
lr at 26th epoch is 0.0001 for optimizer
current performance: -29.5758, best performance: -27.2870
Epoch: 0026 | TRAIN: 1.0266 0.0382 0.1045 | 0.5707 0.5707 0.2736 | 0.2401 35.8808 32.7974 0.1111 0.3184 0.4511 TEST: 2.6640 0.0213 0.0949 | 0.6264 0.6187 0.8446 | 0.2335 35.0898 40.8975 12.2312 33.6028 46.8080
lr at 27th epoch is 0.0001 for optimizer
current performance: -26.7585, best performance: -27.2870
Epoch: 0027 | TRAIN: 1.0239 0.0403 0.1042 | 0.5420 0.5420 0.2598 | 0.2334 35.2244 32.2584 0.1200 0.3299 0.4631 TEST: 2.2155 0.0609 0.1108 | 0.7044 0.6913 0.9639 | 0.2217 34.2812 39.7099 12.7509 33.4433 46.7058
lr at 28th epoch is 0.0001 for optimizer
current performance: -26.8177, best performance: -26.7585
Epoch: 0028 | TRAIN: 1.0073 0.0414 0.1093 | 0.5395 0.5395 0.2635 | 0.2314 35.0289 31.9266 0.1207 0.3318 0.4681 TEST: 2.4417 0.0318 0.1000 | 0.6274 0.6182 0.8604 | 0.2205 33.8362 39.7037 14.7434 35.4932 48.2983
lr at 29th epoch is 0.0001 for optimizer
current performance: -25.1823, best performance: -26.7585
Epoch: 0029 | TRAIN: 1.0027 0.0451 0.1182 | 0.5279 0.5279 0.2570 | 0.2279 34.6000 31.3323 0.1298 0.3455 0.4775 TEST: 2.4947 0.0244 0.0677 | 0.5890 0.5798 0.8239 | 0.2134 33.0001 39.0859 16.1200 37.4677 50.2935
lr at 30th epoch is 0.0001 for optimizer
current performance: -23.4286, best performance: -25.1823
Epoch: 0030 | TRAIN: 0.9752 0.0488 0.1209 | 0.5202 0.5202 0.2530 | 0.2238 34.1778 30.7517 0.1334 0.3549 0.4888 TEST: 2.4489 0.0353 0.0885 | 0.5715 0.5640 0.7963 | 0.2100 33.2982 38.5988 12.4428 35.1346 49.1818
lr at 31th epoch is 0.0001 for optimizer
current performance: -22.7800, best performance: -23.4286
Epoch: 0031 | TRAIN: 0.9808 0.0468 0.1163 | 0.5113 0.5113 0.2464 | 0.2193 33.8724 30.5456 0.1318 0.3534 0.4912 TEST: 2.3881 0.0435 0.0931 | 0.6055 0.5978 0.8308 | 0.2060 32.3386 38.3518 16.1683 38.7206 51.9052
lr at 32th epoch is 0.0001 for optimizer
current performance: -21.8896, best performance: -22.7800
Epoch: 0032 | TRAIN: 0.9642 0.0496 0.1234 | 0.5072 0.5072 0.2441 | 0.2210 33.9871 30.5031 0.1303 0.3554 0.4917 TEST: 2.2293 0.0635 0.1774 | 0.6410 0.6316 0.8893 | 0.2084 32.5171 38.6337 15.7018 38.9715 52.0504
lr at 33th epoch is 0.0001 for optimizer
current performance: -25.7788, best performance: -21.8896
Epoch: 0033 | TRAIN: 0.9366 0.0559 0.1371 | 0.4837 0.4837 0.2305 | 0.2176 33.5954 30.0382 0.1388 0.3626 0.4998 TEST: 3.1573 0.0087 0.0568 | 0.5651 0.5575 0.7908 | 0.2077 32.6015 38.4749 15.8976 37.6826 50.7905
lr at 34th epoch is 0.0001 for optimizer
current performance: -16.3646, best performance: -21.8896
Epoch: 0034 | TRAIN: 0.9260 0.0552 0.1353 | 0.4682 0.4682 0.2212 | 0.2120 33.0546 29.3441 0.1433 0.3744 0.5124 TEST: 2.2544 0.0900 0.1810 | 0.5879 0.5811 0.8089 | 0.2096 32.5465 38.7745 15.9906 39.3722 52.1321
lr at 35th epoch is 0.0001 for optimizer
current performance: -10.5080, best performance: -16.3646
Epoch: 0035 | TRAIN: 0.9171 0.0611 0.1459 | 0.4829 0.4829 0.2324 | 0.2115 33.0298 29.2650 0.1417 0.3738 0.5117 TEST: 2.2079 0.1295 0.2252 | 0.5874 0.5802 0.8055 | 0.2014 31.8587 37.9053 16.7848 39.8329 52.9474
lr at 36th epoch is 0.0001 for optimizer
current performance: -7.6905, best performance: -10.5080
Epoch: 0036 | TRAIN: 0.9124 0.0620 0.1460 | 0.4749 0.4749 0.2271 | 0.2120 33.0094 29.3335 0.1464 0.3765 0.5114 TEST: 1.9863 0.1518 0.2501 | 0.5881 0.5819 0.7996 | 0.2023 31.8095 38.0496 16.9312 40.6936 53.5702
lr at 37th epoch is 0.0001 for optimizer
current performance: -5.3103, best performance: -7.6905
Epoch: 0037 | TRAIN: 0.8751 0.0663 0.1557 | 0.4733 0.4733 0.2282 | 0.2085 32.6496 28.8981 0.1504 0.3846 0.5215 TEST: 1.8985 0.1653 0.2726 | 0.5685 0.5600 0.8040 | 0.2029 32.0795 38.0359 15.9582 39.2474 52.5798
lr at 38th epoch is 0.0001 for optimizer
current performance: -18.0628, best performance: -5.3103
Epoch: 0038 | TRAIN: 0.8545 0.0657 0.1570 | 0.4677 0.4677 0.2208 | 0.2085 32.6534 28.9430 0.1511 0.3843 0.5201 TEST: 2.1228 0.0860 0.1929 | 0.6282 0.6213 0.8281 | 0.2014 32.0531 37.8882 14.8981 39.2035 52.7766
lr at 39th epoch is 0.0001 for optimizer
current performance: -18.8947, best performance: -5.3103
Epoch: 0039 | TRAIN: 0.8356 0.0730 0.1719 | 0.4622 0.4622 0.2210 | 0.2082 32.6676 28.9582 0.1468 0.3822 0.5209 TEST: 2.7153 0.0671 0.1238 | 0.5904 0.5831 0.7963 | 0.2025 32.1197 38.0099 15.6533 38.9353 52.4520
lr at 40th epoch is 0.0001 for optimizer
current performance: -18.3776, best performance: -5.3103
Epoch: 0040 | TRAIN: 0.7954 0.0710 0.1730 | 0.4437 0.4437 0.2092 | 0.2067 32.4649 28.5230 0.1509 0.3886 0.5270 TEST: 2.4684 0.0769 0.1759 | 0.6166 0.6072 0.8628 | 0.2005 31.8391 37.7930 16.4586 39.6571 52.9521
lr at 41th epoch is 0.0001 for optimizer
current performance: -17.9438, best performance: -5.3103
Epoch: 0041 | TRAIN: 0.7947 0.0785 0.1876 | 0.4471 0.4471 0.2167 | 0.2059 32.3975 28.6036 0.1525 0.3883 0.5265 TEST: 2.6687 0.0736 0.1597 | 0.5950 0.5846 0.8456 | 0.2020 31.9523 37.9404 16.7281 39.5703 52.5275
lr at 42th epoch is 0.0001 for optimizer
current performance: -20.7645, best performance: -5.3103
Epoch: 0042 | TRAIN: 0.7322 0.0799 0.1966 | 0.4481 0.4481 0.2099 | 0.2049 32.3165 28.5663 0.1539 0.3888 0.5263 TEST: 2.9945 0.0425 0.1112 | 0.5644 0.5549 0.7879 | 0.2057 32.0705 38.4373 16.4865 40.5836 53.5348
lr at 43th epoch is 0.0001 for optimizer
current performance: -21.3413, best performance: -5.3103
Epoch: 0043 | TRAIN: 0.7067 0.0827 0.1998 | 0.4467 0.4467 0.2154 | 0.2087 32.6512 28.8428 0.1507 0.3843 0.5219 TEST: 3.0615 0.0444 0.1112 | 0.5873 0.5791 0.8016 | 0.2010 31.8655 37.8567 16.6766 39.6305 52.7371
lr at 44th epoch is 0.0001 for optimizer
current performance: -19.7152, best performance: -5.3103
Epoch: 0044 | TRAIN: 0.6919 0.0859 0.2074 | 0.4370 0.4370 0.2074 | 0.2050 32.3739 28.6854 0.1509 0.3857 0.5253 TEST: 2.7096 0.0550 0.1465 | 0.5693 0.5597 0.8073 | 0.2045 32.3773 38.1625 14.7100 38.1939 51.9662
lr at 45th epoch is 0.0001 for optimizer
current performance: -19.8084, best performance: -5.3103
Epoch: 0045 | TRAIN: 0.6821 0.0886 0.2117 | 0.4269 0.4269 0.2052 | 0.2014 31.9925 28.1363 0.1548 0.3935 0.5346 TEST: 3.0974 0.0486 0.1156 | 0.5736 0.5647 0.7888 | 0.1969 31.5263 37.4361 16.5461 39.8712 53.5444
lr at 46th epoch is 0.0001 for optimizer
current performance: -15.4807, best performance: -5.3103
Epoch: 0046 | TRAIN: 0.5961 0.0955 0.2315 | 0.4286 0.4286 0.2045 | 0.2051 32.3420 28.5040 0.1519 0.3863 0.5278 TEST: 2.5459 0.0793 0.1710 | 0.5498 0.5423 0.7649 | 0.2012 32.0320 37.8127 15.9660 38.6434 52.0254
lr at 47th epoch is 0.0001 for optimizer
current performance: -17.3877, best performance: -5.3103
Epoch: 0047 | TRAIN: 0.6006 0.0935 0.2269 | 0.4269 0.4269 0.2020 | 0.2023 32.0460 28.1125 0.1546 0.3953 0.5355 TEST: 3.5034 0.0619 0.1409 | 0.5523 0.5453 0.7598 | 0.1978 31.6304 37.5181 16.3168 39.7883 53.2426
lr at 48th epoch is 0.0001 for optimizer
current performance: -23.3667, best performance: -5.3103
Epoch: 0048 | TRAIN: 0.6100 0.0952 0.2291 | 0.4222 0.4222 0.2023 | 0.2011 31.8948 27.9812 0.1606 0.3983 0.5357 TEST: 3.8601 0.0195 0.0770 | 0.5699 0.5615 0.7842 | 0.1981 31.5163 37.5846 17.0322 40.2982 53.7950
lr at 49th epoch is 0.0001 for optimizer
current performance: -12.2288, best performance: -5.3103
Epoch: 0049 | TRAIN: 0.5938 0.0961 0.2296 | 0.4174 0.4174 0.2008 | 0.2024 32.0582 28.0528 0.1538 0.3962 0.5363 TEST: 3.1388 0.1035 0.1998 | 0.5547 0.5473 0.7718 | 0.2004 31.6946 37.8612 16.4565 40.7553 54.1462
lr at 50th epoch is 0.0001 for optimizer
current performance: -17.7007, best performance: -5.3103
Epoch: 0050 | TRAIN: 0.5367 0.1014 0.2383 | 0.4157 0.4157 0.1966 | 0.2004 31.8565 27.9160 0.1588 0.3987 0.5377 TEST: 3.3069 0.0589 0.1486 | 0.5541 0.5446 0.7832 | 0.1987 31.6024 37.6102 16.7160 39.9710 53.5766
lr at 51th epoch is 0.0001 for optimizer
current performance: -13.8591, best performance: -5.3103
Epoch: 0051 | TRAIN: 0.5335 0.1032 0.2441 | 0.4162 0.4162 0.2021 | 0.2016 31.9591 28.0130 0.1575 0.3982 0.5369 TEST: 3.4147 0.0935 0.1696 | 0.5791 0.5723 0.7835 | 0.1947 31.0444 37.2757 18.1585 41.7637 55.0093
lr at 52th epoch is 0.0001 for optimizer
current performance: -24.0694, best performance: -5.3103
Epoch: 0052 | TRAIN: 0.5137 0.1073 0.2466 | 0.4198 0.4198 0.2039 | 0.1999 31.7768 27.8761 0.1619 0.4003 0.5387 TEST: 4.9516 0.0291 0.0938 | 0.6070 0.5995 0.8254 | 0.2026 31.7762 38.1424 16.8154 40.7548 54.2233
lr at 53th epoch is 0.0001 for optimizer
current performance: -19.4610, best performance: -5.3103
Epoch: 0053 | TRAIN: 0.5085 0.1074 0.2520 | 0.4125 0.4125 0.2003 | 0.2006 31.7761 27.6917 0.1641 0.4035 0.5411 TEST: 4.0024 0.0497 0.1184 | 0.5695 0.5627 0.7844 | 0.1974 31.4246 37.5133 17.5826 40.4606 53.7967
lr at 54th epoch is 0.0001 for optimizer
current performance: -11.6652, best performance: -5.3103
Epoch: 0054 | TRAIN: 0.4999 0.1055 0.2461 | 0.3945 0.3945 0.1860 | 0.1967 31.4577 27.4011 0.1644 0.4079 0.5466 TEST: 3.2329 0.0924 0.1952 | 0.5279 0.5201 0.7384 | 0.1930 30.9687 37.1007 17.7449 41.8533 55.2630
lr at 55th epoch is 0.0001 for optimizer
current performance: -11.8865, best performance: -5.3103
Epoch: 0055 | TRAIN: 0.4833 0.1043 0.2529 | 0.4083 0.4083 0.1945 | 0.1980 31.5071 27.3938 0.1665 0.4093 0.5476 TEST: 3.0773 0.1072 0.2055 | 0.5644 0.5576 0.7743 | 0.1966 31.4112 37.4533 16.9114 40.4911 54.0829
lr at 56th epoch is 0.0001 for optimizer
current performance: -13.2380, best performance: -5.3103
Epoch: 0056 | TRAIN: 0.4535 0.1112 0.2571 | 0.4071 0.4071 0.1956 | 0.1991 31.6610 27.5861 0.1615 0.4062 0.5449 TEST: 3.6565 0.0958 0.2042 | 0.5642 0.5552 0.7871 | 0.1968 31.4159 37.4684 16.3106 41.1461 54.6073
lr at 57th epoch is 0.0001 for optimizer
current performance: -20.2952, best performance: -5.3103
Epoch: 0057 | TRAIN: 0.4487 0.1079 0.2582 | 0.3940 0.3940 0.1860 | 0.1973 31.4539 27.2999 0.1660 0.4112 0.5493 TEST: 5.5336 0.0269 0.0859 | 0.5294 0.5215 0.7360 | 0.1937 31.1507 37.1450 16.8514 41.1109 54.7481
lr at 58th epoch is 0.0001 for optimizer
current performance: -14.4233, best performance: -5.3103
Epoch: 0058 | TRAIN: 0.4389 0.1131 0.2642 | 0.4040 0.4040 0.1902 | 0.1968 31.4275 27.2575 0.1641 0.4109 0.5496 TEST: 3.6012 0.0804 0.1721 | 0.5536 0.5449 0.7817 | 0.1932 31.1006 37.0725 16.8130 41.1479 54.8956
lr at 59th epoch is 0.0001 for optimizer
current performance: -22.5955, best performance: -5.3103
Epoch: 0059 | TRAIN: 0.4081 0.1155 0.2618 | 0.3963 0.3963 0.1893 | 0.1967 31.4355 27.4643 0.1653 0.4093 0.5475 TEST: 6.1689 0.0155 0.0707 | 0.5435 0.5353 0.7569 | 0.1963 31.3787 37.3873 17.3061 40.5977 53.8589
lr at 60th epoch is 0.0001 for optimizer
current performance: -17.2895, best performance: -5.3103
Epoch: 0060 | TRAIN: 0.4151 0.1140 0.2694 | 0.3938 0.3938 0.1882 | 0.1967 31.4325 27.3755 0.1655 0.4093 0.5471 TEST: 5.2789 0.0516 0.1098 | 0.5388 0.5311 0.7451 | 0.1924 30.9153 37.0311 17.8525 41.8150 55.2535
lr at 61th epoch is 0.0001 for optimizer
current performance: -11.2464, best performance: -5.3103
Epoch: 0061 | TRAIN: 0.4051 0.1168 0.2650 | 0.3865 0.3865 0.1815 | 0.1951 31.2368 27.1315 0.1690 0.4141 0.5537 TEST: 4.2185 0.0952 0.1805 | 0.5299 0.5219 0.7413 | 0.1925 30.8374 37.1264 17.6234 42.8561 56.2315
lr at 62th epoch is 0.0001 for optimizer
current performance: -16.5611, best performance: -5.3103
Epoch: 0062 | TRAIN: 0.4155 0.1164 0.2669 | 0.3828 0.3828 0.1842 | 0.1950 31.2444 27.2408 0.1695 0.4129 0.5512 TEST: 4.8841 0.0539 0.1102 | 0.5326 0.5251 0.7379 | 0.1922 30.7543 37.0438 18.8021 42.5905 55.5313
lr at 63th epoch is 0.0001 for optimizer
current performance: -18.3174, best performance: -5.3103
Epoch: 0063 | TRAIN: 0.3606 0.1213 0.2729 | 0.3825 0.3825 0.1818 | 0.1929 30.9760 26.7583 0.1739 0.4215 0.5586 TEST: 5.9173 0.0550 0.1104 | 0.5513 0.5433 0.7652 | 0.1988 31.7565 37.6364 15.6459 39.4883 53.5489
lr at 64th epoch is 0.0001 for optimizer
current performance: -3.6138, best performance: -5.3103
Epoch: 0064 | TRAIN: 0.3903 0.1184 0.2706 | 0.3868 0.3868 0.1834 | 0.1925 30.9927 26.8258 0.1713 0.4195 0.5565 TEST: 3.0098 0.1515 0.2564 | 0.5234 0.5159 0.7356 | 0.1893 30.6716 36.7259 17.5877 42.3058 55.9126
lr at 65th epoch is 0.0001 for optimizer
current performance: -9.2120, best performance: -3.6138
Epoch: 0065 | TRAIN: 0.3948 0.1167 0.2700 | 0.3785 0.3785 0.1826 | 0.1942 31.0653 26.7519 0.1741 0.4225 0.5585 TEST: 3.7831 0.1151 0.2091 | 0.5390 0.5298 0.7655 | 0.1938 30.9903 37.1773 18.0630 41.6175 55.0316
lr at 66th epoch is 0.0001 for optimizer
current performance: -10.8804, best performance: -3.6138
Epoch: 0066 | TRAIN: 0.4225 0.1154 0.2691 | 0.3904 0.3904 0.1830 | 0.1940 31.1571 27.0480 0.1687 0.4152 0.5530 TEST: 3.7216 0.1007 0.1842 | 0.5308 0.5234 0.7395 | 0.1973 31.0801 37.6750 17.5471 43.3335 56.6003
lr at 67th epoch is 0.0001 for optimizer
current performance: -17.6231, best performance: -3.6138
Epoch: 0067 | TRAIN: 0.3607 0.1197 0.2757 | 0.3773 0.3773 0.1827 | 0.1943 31.1343 27.0507 0.1713 0.4178 0.5549 TEST: 5.4117 0.0421 0.1215 | 0.5215 0.5141 0.7327 | 0.1907 30.7864 36.8570 17.7020 41.7094 55.4784
lr at 68th epoch is 0.0001 for optimizer
current performance: -8.3616, best performance: -3.6138
Epoch: 0068 | TRAIN: 0.3631 0.1230 0.2759 | 0.3690 0.3690 0.1774 | 0.1940 31.1007 26.9885 0.1731 0.4175 0.5546 TEST: 3.3253 0.1233 0.2641 | 0.5417 0.5352 0.7535 | 0.1940 30.9606 37.3035 17.4768 42.4480 56.0901
lr at 69th epoch is 0.0001 for optimizer
current performance: -13.2171, best performance: -3.6138
Epoch: 0069 | TRAIN: 0.3387 0.1243 0.2785 | 0.3675 0.3675 0.1774 | 0.1908 30.7625 26.5641 0.1774 0.4251 0.5628 TEST: 4.6673 0.0762 0.1448 | 0.5274 0.5204 0.7360 | 0.1894 30.4898 36.7885 18.5474 43.2947 56.6841
lr at 70th epoch is 0.0001 for optimizer
current performance: -8.2015, best performance: -3.6138
Epoch: 0070 | TRAIN: 0.3476 0.1285 0.2778 | 0.3712 0.3712 0.1768 | 0.1909 30.7532 26.5040 0.1782 0.4258 0.5636 TEST: 3.4951 0.1232 0.2119 | 0.5404 0.5329 0.7438 | 0.1920 30.8862 36.9922 17.5489 41.6331 55.4707
lr at 71th epoch is 0.0001 for optimizer
current performance: -13.6591, best performance: -3.6138
Epoch: 0071 | TRAIN: 0.3310 0.1248 0.2801 | 0.3658 0.3658 0.1724 | 0.1902 30.6587 26.3998 0.1804 0.4282 0.5658 TEST: 4.7370 0.0793 0.1699 | 0.5465 0.5406 0.7512 | 0.1894 30.4611 36.7812 18.9720 43.3121 56.5880
lr at 72th epoch is 0.0001 for optimizer
current performance: -0.5338, best performance: -3.6138
Epoch: 0072 | TRAIN: 0.3258 0.1305 0.2850 | 0.3668 0.3668 0.1740 | 0.1874 30.3571 25.9669 0.1833 0.4368 0.5736 TEST: 2.8136 0.1887 0.3096 | 0.5570 0.5498 0.7612 | 0.1947 30.8520 37.3364 19.2510 42.8356 55.7709
lr at 73th epoch is 0.0001 for optimizer
current performance: -11.6807, best performance: -0.5338
Epoch: 0073 | TRAIN: 0.3500 0.1242 0.2795 | 0.3660 0.3660 0.1714 | 0.1893 30.5962 26.2864 0.1797 0.4290 0.5663 TEST: 3.7711 0.0901 0.1796 | 0.5397 0.5311 0.7726 | 0.1866 30.2835 36.4681 19.2141 43.0828 56.3124
lr at 74th epoch is 0.0001 for optimizer
current performance: -12.2014, best performance: -0.5338
Epoch: 0074 | TRAIN: 0.2891 0.1343 0.2930 | 0.3601 0.3601 0.1699 | 0.1873 30.3280 25.8970 0.1851 0.4375 0.5741 TEST: 4.7367 0.0977 0.1716 | 0.5606 0.5524 0.7841 | 0.1927 30.8028 37.1565 17.9763 42.8317 56.4100
lr at 75th epoch is 0.0001 for optimizer
current performance: -7.7246, best performance: -0.5338
Epoch: 0075 | TRAIN: 0.3254 0.1295 0.2857 | 0.3626 0.3626 0.1719 | 0.1874 30.3872 26.0302 0.1828 0.4347 0.5719 TEST: 3.9584 0.1104 0.1948 | 0.5138 0.5067 0.7225 | 0.1858 30.0104 36.4483 19.8075 44.4185 57.5819
lr at 76th epoch is 0.0001 for optimizer
current performance: -12.8223, best performance: -0.5338
Epoch: 0076 | TRAIN: 0.3222 0.1279 0.2818 | 0.3628 0.3628 0.1760 | 0.1871 30.3481 25.9671 0.1821 0.4356 0.5731 TEST: 5.0879 0.0784 0.1507 | 0.5287 0.5213 0.7369 | 0.1872 30.3489 36.5088 18.8995 42.9750 56.3199
lr at 77th epoch is 0.0001 for optimizer
current performance: -18.4630, best performance: -0.5338
Epoch: 0077 | TRAIN: 0.2932 0.1384 0.2919 | 0.3603 0.3603 0.1700 | 0.1835 29.9468 25.4546 0.1904 0.4460 0.5816 TEST: 7.2359 0.0380 0.0987 | 0.5453 0.5362 0.7712 | 0.1869 30.2059 36.5016 19.2687 43.6882 57.0034
lr at 78th epoch is 0.0001 for optimizer
current performance: -14.7099, best performance: -0.5338
Epoch: 0078 | TRAIN: 0.3060 0.1309 0.2845 | 0.3625 0.3625 0.1723 | 0.1879 30.4022 26.0123 0.1841 0.4353 0.5723 TEST: 4.7393 0.0789 0.1499 | 0.5504 0.5438 0.7574 | 0.1959 31.2379 37.4113 17.7588 41.1331 54.5141
lr at 79th epoch is 0.0001 for optimizer
current performance: -16.4036, best performance: -0.5338
Epoch: 0079 | TRAIN: 0.2952 0.1299 0.2881 | 0.3609 0.3609 0.1733 | 0.1882 30.4792 26.1504 0.1809 0.4326 0.5704 TEST: 5.4239 0.0601 0.1354 | 0.5596 0.5520 0.7716 | 0.1868 30.2838 36.5010 18.5646 43.4064 56.9468
lr at 80th epoch is 0.0001 for optimizer
current performance: -16.4141, best performance: -0.5338
Epoch: 0080 | TRAIN: 0.2845 0.1341 0.2916 | 0.3475 0.3475 0.1658 | 0.1840 29.9693 25.3903 0.1901 0.4463 0.5837 TEST: 5.8976 0.0502 0.1060 | 0.5350 0.5264 0.7488 | 0.1863 30.1463 36.4882 18.9603 44.0816 57.4975
lr at 81th epoch is 0.0001 for optimizer
current performance: -12.2172, best performance: -0.5338
Epoch: 0081 | TRAIN: 0.3096 0.1353 0.2902 | 0.3511 0.3511 0.1665 | 0.1848 30.0708 25.5680 0.1866 0.4442 0.5810 TEST: 4.4873 0.0949 0.1693 | 0.5682 0.5591 0.7815 | 0.1870 30.2293 36.5186 19.2853 43.4914 56.8677
lr at 82th epoch is 0.0001 for optimizer
current performance: -8.5943, best performance: -0.5338
Epoch: 0082 | TRAIN: 0.2433 0.1368 0.2927 | 0.3453 0.3453 0.1629 | 0.1847 30.0740 25.6665 0.1886 0.4428 0.5789 TEST: 5.1183 0.1101 0.1843 | 0.5298 0.5220 0.7361 | 0.1860 30.1636 36.4322 18.7297 43.9711 57.3972
lr at 83th epoch is 0.0001 for optimizer
current performance: -2.7914, best performance: -0.5338
Epoch: 0083 | TRAIN: 0.2999 0.1346 0.2872 | 0.3529 0.3529 0.1703 | 0.1853 30.0979 25.5692 0.1877 0.4445 0.5804 TEST: 3.2195 0.1596 0.2930 | 0.5263 0.5191 0.7314 | 0.1907 30.7438 36.8660 17.7062 42.3203 55.8998
lr at 84th epoch is 0.0001 for optimizer
current performance: -4.5596, best performance: -0.5338
Epoch: 0084 | TRAIN: 0.2980 0.1323 0.2915 | 0.3538 0.3538 0.1689 | 0.1855 30.1151 25.6443 0.1900 0.4423 0.5784 TEST: 3.4376 0.1501 0.2614 | 0.5499 0.5438 0.7527 | 0.1866 30.2736 36.5002 18.9870 43.2023 56.6721
lr at 85th epoch is 0.0001 for optimizer
current performance: -8.4414, best performance: -0.5338
Epoch: 0085 | TRAIN: 0.2514 0.1417 0.3007 | 0.3419 0.3419 0.1621 | 0.1827 29.8804 25.4845 0.1914 0.4446 0.5822 TEST: 4.2596 0.1071 0.1966 | 0.5174 0.5094 0.7272 | 0.1859 30.1650 36.4053 18.7343 43.4824 57.2365
lr at 86th epoch is 0.0001 for optimizer
current performance: -8.7192, best performance: -0.5338
Epoch: 0086 | TRAIN: 0.2960 0.1377 0.2935 | 0.3416 0.3416 0.1621 | 0.1833 29.9083 25.4062 0.1905 0.4475 0.5843 TEST: 4.3994 0.1059 0.1805 | 0.5250 0.5165 0.7401 | 0.1854 30.0028 36.4094 19.7732 44.4766 57.5745
lr at 87th epoch is 0.0001 for optimizer
current performance: -15.1182, best performance: -0.5338
Epoch: 0087 | TRAIN: 0.2286 0.1488 0.3018 | 0.3386 0.3386 0.1612 | 0.1794 29.4489 24.8904 0.2010 0.4571 0.5916 TEST: 5.8348 0.0633 0.1149 | 0.5303 0.5227 0.7315 | 0.1916 30.6258 36.9942 19.1282 42.8426 56.0879
lr at 88th epoch is 0.0001 for optimizer
current performance: -12.8380, best performance: -0.5338
Epoch: 0088 | TRAIN: 0.2595 0.1437 0.2968 | 0.3536 0.3536 0.1701 | 0.1817 29.7194 25.1599 0.1945 0.4510 0.5877 TEST: 5.4858 0.0768 0.1489 | 0.5362 0.5273 0.7569 | 0.1849 29.9472 36.3584 19.3583 44.9258 58.1463
lr at 89th epoch is 0.0001 for optimizer
current performance: -14.3332, best performance: -0.5338
Epoch: 0089 | TRAIN: 0.2794 0.1349 0.2888 | 0.3443 0.3443 0.1634 | 0.1833 29.8818 25.4536 0.1939 0.4474 0.5833 TEST: 5.9347 0.0723 0.1426 | 0.5450 0.5368 0.7565 | 0.1903 30.4037 36.9470 19.3702 44.1081 57.2184
lr at 90th epoch is 0.0001 for optimizer
current performance: -16.6472, best performance: -0.5338
Epoch: 0090 | TRAIN: 0.2637 0.1407 0.2966 | 0.3438 0.3438 0.1618 | 0.1837 29.9343 25.4056 0.1911 0.4459 0.5827 TEST: 6.3270 0.0410 0.1105 | 0.5169 0.5086 0.7298 | 0.1850 29.9959 36.3293 19.4861 44.3928 57.6401
lr at 91th epoch is 0.0001 for optimizer
current performance: -12.2074, best performance: -0.5338
Epoch: 0091 | TRAIN: 0.2791 0.1404 0.2956 | 0.3475 0.3475 0.1625 | 0.1838 29.9877 25.6109 0.1886 0.4436 0.5805 TEST: 4.7751 0.0810 0.1886 | 0.5299 0.5213 0.7480 | 0.1850 30.1021 36.2896 19.1162 43.5277 57.0132
lr at 92th epoch is 0.0001 for optimizer
current performance: -12.2538, best performance: -0.5338
Epoch: 0092 | TRAIN: 0.2212 0.1460 0.3018 | 0.3387 0.3387 0.1610 | 0.1806 29.6031 25.0286 0.1971 0.4533 0.5891 TEST: 5.1940 0.0777 0.1720 | 0.5247 0.5180 0.7396 | 0.1858 29.8883 36.5038 19.9615 45.3848 58.5584
lr at 93th epoch is 0.0001 for optimizer
current performance: -5.4958, best performance: -0.5338
Epoch: 0093 | TRAIN: 0.2566 0.1385 0.2963 | 0.3454 0.3454 0.1659 | 0.1807 29.6326 25.1260 0.1956 0.4516 0.5882 TEST: 3.8442 0.1235 0.2460 | 0.5057 0.4989 0.7140 | 0.1836 29.8017 36.2036 20.0231 44.8012 58.0875
lr at 94th epoch is 0.0001 for optimizer
current performance: -11.6308, best performance: -0.5338
Epoch: 0094 | TRAIN: 0.2542 0.1452 0.2978 | 0.3343 0.3343 0.1587 | 0.1809 29.6233 25.0520 0.1966 0.4542 0.5892 TEST: 4.6311 0.0801 0.1673 | 0.5176 0.5101 0.7206 | 0.1843 29.9114 36.2549 19.7154 44.4292 57.8158
lr at 95th epoch is 0.0001 for optimizer
current performance: -5.7249, best performance: -0.5338
Epoch: 0095 | TRAIN: 0.2165 0.1505 0.3044 | 0.3252 0.3252 0.1497 | 0.1751 28.9953 24.3905 0.2078 0.4668 0.6013 TEST: 3.8396 0.1204 0.2279 | 0.5065 0.4989 0.7174 | 0.1812 29.6549 35.9257 19.9279 44.7066 58.0544
lr at 96th epoch is 0.0001 for optimizer
current performance: -15.9579, best performance: -0.5338
Epoch: 0096 | TRAIN: 0.1915 0.1537 0.3102 | 0.3236 0.3236 0.1538 | 0.1761 29.0753 24.4174 0.2076 0.4669 0.6007 TEST: 7.2853 0.0433 0.1035 | 0.5172 0.5104 0.7205 | 0.1817 29.5586 36.0298 20.8273 45.4230 58.4845
lr at 97th epoch is 0.0001 for optimizer
current performance: -9.6850, best performance: -0.5338
Epoch: 0097 | TRAIN: 0.3298 0.1360 0.2913 | 0.3465 0.3465 0.1652 | 0.1816 29.7209 25.1865 0.1937 0.4516 0.5882 TEST: 4.7531 0.0957 0.1765 | 0.5180 0.5100 0.7330 | 0.1849 29.9554 36.3529 19.2649 44.8535 58.1368
lr at 98th epoch is 0.0001 for optimizer
current performance: -6.6691, best performance: -0.5338
Epoch: 0098 | TRAIN: 0.2200 0.1503 0.3026 | 0.3205 0.3205 0.1514 | 0.1775 29.2635 24.5774 0.2021 0.4620 0.5974 TEST: 4.1026 0.1125 0.2164 | 0.5121 0.5035 0.7210 | 0.1802 29.4246 35.8626 20.7848 45.7204 58.8208
lr at 99th epoch is 0.0001 for optimizer
current performance: -8.1989, best performance: -0.5338
Epoch: 0099 | TRAIN: 0.2599 0.1408 0.2979 | 0.3301 0.3301 0.1567 | 0.1783 29.3235 24.6899 0.2017 0.4612 0.5963 TEST: 4.5205 0.1045 0.2043 | 0.5196 0.5113 0.7406 | 0.1823 29.5801 36.1157 20.5205 45.7945 58.9063
lr at 100th epoch is 5e-05 for optimizer
current performance: -9.0628, best performance: -0.5338
Epoch: 0100 | TRAIN: 0.1945 0.1581 0.3090 | 0.3036 0.3036 0.1417 | 0.1736 28.7518 23.9390 0.2146 0.4761 0.6085 TEST: 5.1148 0.0850 0.1650 | 0.4908 0.4834 0.7002 | 0.1789 29.1996 35.7735 21.2135 46.8282 59.6789
lr at 101th epoch is 5e-05 for optimizer
current performance: -10.5515, best performance: -0.5338
Epoch: 0101 | TRAIN: 0.1869 0.1592 0.3107 | 0.2928 0.2928 0.1372 | 0.1733 28.6764 23.8379 0.2182 0.4777 0.6105 TEST: 5.5860 0.0749 0.1452 | 0.4973 0.4885 0.7085 | 0.1789 29.1789 35.7504 21.5685 46.5994 59.5191
lr at 102th epoch is 5e-05 for optimizer
current performance: -9.8468, best performance: -0.5338
Epoch: 0102 | TRAIN: 0.1613 0.1654 0.3158 | 0.2900 0.2900 0.1373 | 0.1706 28.3768 23.4836 0.2231 0.4860 0.6170 TEST: 5.5604 0.0812 0.1533 | 0.4960 0.4883 0.6968 | 0.1797 29.2747 35.8319 21.4256 46.4079 59.2674
lr at 103th epoch is 5e-05 for optimizer
current performance: -9.5966, best performance: -0.5338
Epoch: 0103 | TRAIN: 0.1405 0.1710 0.3193 | 0.2849 0.2849 0.1339 | 0.1682 28.1717 23.3545 0.2248 0.4867 0.6199 TEST: 5.8228 0.0802 0.1628 | 0.4943 0.4867 0.6988 | 0.1774 28.9973 35.6104 21.9522 47.0724 59.9484
lr at 104th epoch is 5e-05 for optimizer
current performance: -5.3812, best performance: -0.5338
Epoch: 0104 | TRAIN: 0.1395 0.1680 0.3185 | 0.2835 0.2835 0.1349 | 0.1663 27.9206 22.8926 0.2293 0.4960 0.6271 TEST: 5.0428 0.1123 0.1895 | 0.4932 0.4850 0.7059 | 0.1767 28.9587 35.5399 21.6720 47.1531 60.1242
lr at 105th epoch is 5e-05 for optimizer
current performance: -3.2401, best performance: -0.5338
Epoch: 0105 | TRAIN: 0.1445 0.1673 0.3195 | 0.2794 0.2794 0.1326 | 0.1690 28.2127 23.2348 0.2244 0.4897 0.6211 TEST: 4.8655 0.1320 0.2089 | 0.5014 0.4928 0.7187 | 0.1768 28.9941 35.5371 21.6370 46.9571 59.9327
lr at 106th epoch is 5e-05 for optimizer
current performance: -7.9285, best performance: -0.5338
Epoch: 0106 | TRAIN: 0.1414 0.1712 0.3223 | 0.2775 0.2775 0.1326 | 0.1676 28.0673 23.1680 0.2278 0.4919 0.6229 TEST: 5.5199 0.0921 0.1696 | 0.4918 0.4842 0.6995 | 0.1762 28.9660 35.4647 21.2266 47.1289 60.1466
lr at 107th epoch is 5e-05 for optimizer
current performance: -10.5054, best performance: -0.5338
Epoch: 0107 | TRAIN: 0.1490 0.1692 0.3204 | 0.2811 0.2811 0.1353 | 0.1683 28.0700 23.0453 0.2311 0.4938 0.6231 TEST: 6.2916 0.0731 0.1459 | 0.4996 0.4919 0.7061 | 0.1756 28.8004 35.4213 22.0044 47.7376 60.5789
lr at 108th epoch is 5e-05 for optimizer
current performance: -7.3360, best performance: -0.5338
Epoch: 0108 | TRAIN: 0.1328 0.1688 0.3183 | 0.2717 0.2717 0.1289 | 0.1651 27.7462 22.6964 0.2344 0.5012 0.6309 TEST: 5.9016 0.0949 0.1727 | 0.4909 0.4831 0.6972 | 0.1753 28.7891 35.3743 22.0810 47.5308 60.3960
lr at 109th epoch is 5e-05 for optimizer
current performance: -10.6547, best performance: -0.5338
Epoch: 0109 | TRAIN: 0.1522 0.1707 0.3191 | 0.2779 0.2779 0.1311 | 0.1663 27.8815 22.8351 0.2322 0.4974 0.6284 TEST: 6.0774 0.0727 0.1585 | 0.4987 0.4925 0.6984 | 0.1755 28.8606 35.3872 21.8893 47.1985 60.0614
lr at 110th epoch is 5e-05 for optimizer
current performance: -2.9917, best performance: -0.5338
Epoch: 0110 | TRAIN: 0.1433 0.1685 0.3194 | 0.2788 0.2788 0.1304 | 0.1661 27.8698 22.9233 0.2325 0.4973 0.6278 TEST: 4.5970 0.1315 0.2320 | 0.4939 0.4865 0.6945 | 0.1769 28.9565 35.5653 22.2192 47.1174 59.8334
lr at 111th epoch is 5e-05 for optimizer
current performance: -6.3779, best performance: -0.5338
Epoch: 0111 | TRAIN: 0.1422 0.1727 0.3222 | 0.2785 0.2785 0.1315 | 0.1660 27.8335 22.8149 0.2337 0.4989 0.6287 TEST: 5.2190 0.1064 0.1995 | 0.4976 0.4895 0.7106 | 0.1777 28.9966 35.6643 21.9076 47.3411 60.1805
lr at 112th epoch is 5e-05 for optimizer
current performance: -6.1003, best performance: -0.5338
Epoch: 0112 | TRAIN: 0.1592 0.1702 0.3212 | 0.2741 0.2741 0.1293 | 0.1669 27.9268 22.8932 0.2325 0.4960 0.6269 TEST: 5.8986 0.1018 0.1600 | 0.4830 0.4756 0.6909 | 0.1759 28.7589 35.4716 22.6838 47.8238 60.5306
lr at 113th epoch is 5e-05 for optimizer
current performance: -5.0131, best performance: -0.5338
Epoch: 0113 | TRAIN: 0.1423 0.1731 0.3212 | 0.2655 0.2655 0.1256 | 0.1642 27.6772 22.6808 0.2349 0.5013 0.6320 TEST: 5.2807 0.1127 0.1997 | 0.4870 0.4800 0.6872 | 0.1761 28.8621 35.4711 22.0835 47.4249 60.2909
lr at 114th epoch is 5e-05 for optimizer
current performance: -9.5786, best performance: -0.5338
Epoch: 0114 | TRAIN: 0.1381 0.1768 0.3243 | 0.2737 0.2737 0.1300 | 0.1656 27.7721 22.6695 0.2353 0.5024 0.6310 TEST: 6.3074 0.0762 0.1443 | 0.4893 0.4813 0.6986 | 0.1750 28.7247 35.3562 22.5896 47.5020 60.3547
lr at 115th epoch is 5e-05 for optimizer
current performance: -2.4916, best performance: -0.5338
Epoch: 0115 | TRAIN: 0.1231 0.1737 0.3244 | 0.2657 0.2657 0.1257 | 0.1643 27.6412 22.5279 0.2365 0.5040 0.6336 TEST: 4.9894 0.1288 0.2211 | 0.4851 0.4776 0.6983 | 0.1731 28.5449 35.1623 22.6149 48.0487 60.8613
lr at 116th epoch is 5e-05 for optimizer
current performance: -11.0695, best performance: -0.5338
Epoch: 0116 | TRAIN: 0.1244 0.1757 0.3236 | 0.2646 0.2646 0.1248 | 0.1632 27.4905 22.3276 0.2411 0.5076 0.6365 TEST: 6.8150 0.0698 0.1492 | 0.5082 0.4995 0.7229 | 0.1733 28.6258 35.1434 22.2103 47.5847 60.5788
lr at 117th epoch is 5e-05 for optimizer
current performance: -11.2624, best performance: -0.5338
Epoch: 0117 | TRAIN: 0.1212 0.1797 0.3258 | 0.2692 0.2692 0.1268 | 0.1625 27.4327 22.2498 0.2416 0.5082 0.6375 TEST: 7.1590 0.0619 0.1311 | 0.4872 0.4795 0.6921 | 0.1749 28.6713 35.3798 22.2267 48.3500 61.0561
lr at 118th epoch is 5e-05 for optimizer
current performance: -10.7282, best performance: -0.5338
Epoch: 0118 | TRAIN: 0.1268 0.1758 0.3238 | 0.2624 0.2624 0.1221 | 0.1627 27.5054 22.4094 0.2366 0.5060 0.6371 TEST: 6.9272 0.0653 0.1333 | 0.4893 0.4807 0.7007 | 0.1736 28.5353 35.2279 22.6766 48.4263 61.1473
lr at 119th epoch is 5e-05 for optimizer
current performance: -9.1322, best performance: -0.5338
Epoch: 0119 | TRAIN: 0.1221 0.1799 0.3271 | 0.2583 0.2583 0.1195 | 0.1593 27.1096 21.9871 0.2452 0.5156 0.6451 TEST: 6.2212 0.0793 0.1574 | 0.4893 0.4815 0.6958 | 0.1758 28.6786 35.4973 22.7784 48.3964 61.1246
lr at 120th epoch is 5e-05 for optimizer
current performance: -7.7737, best performance: -0.5338
Epoch: 0120 | TRAIN: 0.1315 0.1779 0.3223 | 0.2612 0.2612 0.1232 | 0.1630 27.4750 22.3970 0.2415 0.5068 0.6368 TEST: 5.8537 0.0924 0.1819 | 0.4981 0.4897 0.7167 | 0.1745 28.6441 35.3208 22.3390 48.2371 61.0345
lr at 121th epoch is 5e-05 for optimizer
current performance: -10.8508, best performance: -0.5338
Epoch: 0121 | TRAIN: 0.1125 0.1831 0.3270 | 0.2564 0.2564 0.1198 | 0.1597 27.0870 21.8525 0.2508 0.5169 0.6435 TEST: 7.2766 0.0622 0.1351 | 0.4850 0.4776 0.6871 | 0.1724 28.4051 35.1007 22.9963 48.6463 61.3155
lr at 122th epoch is 5e-05 for optimizer
current performance: -9.4934, best performance: -0.5338
Epoch: 0122 | TRAIN: 0.1144 0.1772 0.3240 | 0.2517 0.2517 0.1195 | 0.1597 27.1431 22.0069 0.2456 0.5141 0.6432 TEST: 6.6306 0.0714 0.1611 | 0.4799 0.4721 0.6831 | 0.1727 28.4667 35.1236 22.5882 48.4668 61.2906
lr at 123th epoch is 5e-05 for optimizer
current performance: -13.7473, best performance: -0.5338
Epoch: 0123 | TRAIN: 0.1421 0.1757 0.3232 | 0.2671 0.2671 0.1274 | 0.1614 27.3167 22.1502 0.2433 0.5112 0.6398 TEST: 8.4837 0.0384 0.1035 | 0.4814 0.4741 0.6826 | 0.1722 28.4121 35.0905 22.8386 48.6581 61.3428
lr at 124th epoch is 5e-05 for optimizer
current performance: -11.0607, best performance: -0.5338
Epoch: 0124 | TRAIN: 0.1501 0.1726 0.3212 | 0.2614 0.2614 0.1212 | 0.1602 27.1769 22.0817 0.2465 0.5137 0.6430 TEST: 6.8405 0.0589 0.1309 | 0.4818 0.4748 0.6828 | 0.1716 28.3317 34.9994 23.1094 48.6991 61.3327
lr at 125th epoch is 5e-05 for optimizer
current performance: -8.0283, best performance: -0.5338
Epoch: 0125 | TRAIN: 0.1166 0.1765 0.3276 | 0.2516 0.2516 0.1181 | 0.1599 27.1142 21.9489 0.2484 0.5166 0.6438 TEST: 6.3740 0.0834 0.1543 | 0.4849 0.4771 0.6891 | 0.1722 28.3279 35.0908 23.2970 49.0332 61.6055
lr at 126th epoch is 5e-05 for optimizer
current performance: -10.4587, best performance: -0.5338
Epoch: 0126 | TRAIN: 0.1108 0.1853 0.3268 | 0.2507 0.2507 0.1162 | 0.1570 26.8022 21.5945 0.2532 0.5241 0.6510 TEST: 7.7494 0.0644 0.1330 | 0.4847 0.4771 0.6895 | 0.1717 28.3264 35.0373 23.2414 48.7308 61.4341
lr at 127th epoch is 5e-05 for optimizer
current performance: -5.4889, best performance: -0.5338
Epoch: 0127 | TRAIN: 0.1131 0.1795 0.3245 | 0.2543 0.2543 0.1223 | 0.1616 27.2713 22.0489 0.2482 0.5141 0.6403 TEST: 6.2962 0.1038 0.1940 | 0.4848 0.4775 0.6870 | 0.1721 28.3613 35.0708 23.1640 48.6506 61.4177
lr at 128th epoch is 5e-05 for optimizer
current performance: -10.9937, best performance: -0.5338
Epoch: 0128 | TRAIN: 0.1404 0.1726 0.3246 | 0.2550 0.2550 0.1214 | 0.1615 27.2961 22.0781 0.2434 0.5127 0.6420 TEST: 7.5226 0.0551 0.1132 | 0.4730 0.4656 0.6757 | 0.1707 28.1897 34.9391 23.5852 49.0555 61.6819
lr at 129th epoch is 5e-05 for optimizer
current performance: -5.3628, best performance: -0.5338
Epoch: 0129 | TRAIN: 0.1153 0.1810 0.3262 | 0.2503 0.2503 0.1191 | 0.1590 27.0269 21.8096 0.2489 0.5184 0.6474 TEST: 5.5577 0.1014 0.1875 | 0.4790 0.4715 0.6808 | 0.1706 28.2168 34.9249 23.0566 49.1586 61.8942
lr at 130th epoch is 5e-05 for optimizer
current performance: -13.6646, best performance: -0.5338
Epoch: 0130 | TRAIN: 0.1062 0.1856 0.3280 | 0.2445 0.2445 0.1146 | 0.1583 26.9388 21.7622 0.2512 0.5201 0.6485 TEST: 9.3937 0.0356 0.0936 | 0.4770 0.4699 0.6807 | 0.1696 28.1794 34.7704 23.1537 48.6601 61.5565
lr at 131th epoch is 5e-05 for optimizer
current performance: -10.1591, best performance: -0.5338
Epoch: 0131 | TRAIN: 0.1071 0.1816 0.3294 | 0.2437 0.2437 0.1153 | 0.1575 26.8225 21.5306 0.2540 0.5245 0.6513 TEST: 7.6267 0.0644 0.1370 | 0.4798 0.4724 0.6856 | 0.1715 28.2404 35.0304 23.4787 49.2226 61.8032
lr at 132th epoch is 5e-05 for optimizer
current performance: -9.5093, best performance: -0.5338
Epoch: 0132 | TRAIN: 0.1180 0.1817 0.3257 | 0.2489 0.2489 0.1147 | 0.1576 26.8606 21.5562 0.2526 0.5227 0.6499 TEST: 6.1665 0.0702 0.1627 | 0.4830 0.4759 0.6833 | 0.1706 28.1916 34.9245 23.3535 49.2047 61.8364
lr at 133th epoch is 5e-05 for optimizer
current performance: -10.1798, best performance: -0.5338
Epoch: 0133 | TRAIN: 0.1204 0.1839 0.3258 | 0.2539 0.2539 0.1182 | 0.1585 26.9261 21.6173 0.2540 0.5223 0.6483 TEST: 7.2926 0.0621 0.1292 | 0.4721 0.4646 0.6765 | 0.1714 28.3001 35.0087 22.8491 49.0459 61.7733
lr at 134th epoch is 5e-05 for optimizer
current performance: -11.4725, best performance: -0.5338
Epoch: 0134 | TRAIN: 0.1158 0.1855 0.3274 | 0.2519 0.2519 0.1180 | 0.1573 26.8156 21.5458 0.2535 0.5242 0.6508 TEST: 7.5289 0.0517 0.1158 | 0.4740 0.4670 0.6707 | 0.1704 28.1769 34.8872 23.3484 48.9995 61.7462
lr at 135th epoch is 5e-05 for optimizer
current performance: -10.9007, best performance: -0.5338
Epoch: 0135 | TRAIN: 0.1101 0.1846 0.3280 | 0.2424 0.2424 0.1156 | 0.1570 26.7676 21.4667 0.2546 0.5261 0.6527 TEST: 7.3698 0.0604 0.1274 | 0.4859 0.4778 0.6954 | 0.1711 28.2439 34.9675 23.2085 49.1102 61.7223
lr at 136th epoch is 5e-05 for optimizer
current performance: -4.1959, best performance: -0.5338
Epoch: 0136 | TRAIN: 0.1155 0.1840 0.3278 | 0.2436 0.2436 0.1137 | 0.1556 26.6571 21.3694 0.2549 0.5265 0.6542 TEST: 5.5099 0.1125 0.2014 | 0.4814 0.4732 0.6893 | 0.1717 28.3681 35.0147 23.0526 48.4035 61.0956
lr at 137th epoch is 5e-05 for optimizer
current performance: -8.3807, best performance: -0.5338
Epoch: 0137 | TRAIN: 0.1170 0.1814 0.3275 | 0.2457 0.2457 0.1160 | 0.1557 26.6436 21.3135 0.2574 0.5270 0.6536 TEST: 6.5609 0.0738 0.1535 | 0.4709 0.4634 0.6709 | 0.1698 28.0719 34.8530 23.4598 49.7099 62.3265
lr at 138th epoch is 5e-05 for optimizer
current performance: -7.5737, best performance: -0.5338
Epoch: 0138 | TRAIN: 0.1030 0.1890 0.3306 | 0.2429 0.2429 0.1141 | 0.1549 26.5519 21.2580 0.2595 0.5294 0.6557 TEST: 6.6763 0.0827 0.1655 | 0.4788 0.4710 0.6875 | 0.1690 28.0678 34.7552 23.1083 49.5363 62.2600
lr at 139th epoch is 5e-05 for optimizer
current performance: -10.2474, best performance: -0.5338
Epoch: 0139 | TRAIN: 0.1158 0.1804 0.3290 | 0.2477 0.2477 0.1159 | 0.1548 26.5211 21.1308 0.2603 0.5317 0.6572 TEST: 7.6127 0.0610 0.1385 | 0.4718 0.4646 0.6732 | 0.1713 28.2299 35.0072 23.5764 49.1149 61.7299
lr at 140th epoch is 5e-05 for optimizer
current performance: -9.5923, best performance: -0.5338
Epoch: 0140 | TRAIN: 0.1252 0.1826 0.3258 | 0.2436 0.2436 0.1156 | 0.1583 26.8978 21.5745 0.2531 0.5238 0.6504 TEST: 7.7142 0.0667 0.1366 | 0.4742 0.4672 0.6759 | 0.1714 28.1997 35.0608 23.3736 49.6630 62.1681
lr at 141th epoch is 5e-05 for optimizer
current performance: -7.9776, best performance: -0.5338
Epoch: 0141 | TRAIN: 0.1181 0.1841 0.3291 | 0.2447 0.2447 0.1142 | 0.1538 26.4519 21.1320 0.2600 0.5312 0.6583 TEST: 6.6899 0.0877 0.1642 | 0.4980 0.4906 0.7203 | 0.1713 28.2512 34.9951 23.1131 49.1429 61.9191
lr at 142th epoch is 5e-05 for optimizer
current performance: -13.4749, best performance: -0.5338
Epoch: 0142 | TRAIN: 0.1295 0.1818 0.3283 | 0.2416 0.2416 0.1124 | 0.1545 26.4883 21.1232 0.2596 0.5328 0.6588 TEST: 8.2035 0.0349 0.0997 | 0.4769 0.4694 0.6811 | 0.1679 27.9543 34.6070 23.7359 49.3073 62.0462
lr at 143th epoch is 5e-05 for optimizer
current performance: -7.3330, best performance: -0.5338
Epoch: 0143 | TRAIN: 0.1077 0.1878 0.3292 | 0.2365 0.2365 0.1103 | 0.1531 26.3356 21.0388 0.2628 0.5345 0.6608 TEST: 6.3872 0.0805 0.1565 | 0.4681 0.4608 0.6728 | 0.1694 28.0028 34.8190 23.8875 49.7155 62.3413
lr at 144th epoch is 5e-05 for optimizer
current performance: -4.6596, best performance: -0.5338
Epoch: 0144 | TRAIN: 0.1004 0.1878 0.3296 | 0.2385 0.2385 0.1122 | 0.1540 26.4097 21.0430 0.2635 0.5337 0.6590 TEST: 5.7239 0.1042 0.1865 | 0.4743 0.4674 0.6740 | 0.1697 28.0527 34.8226 23.9358 49.4574 62.0096
lr at 145th epoch is 5e-05 for optimizer
current performance: -3.8039, best performance: -0.5338
Epoch: 0145 | TRAIN: 0.1194 0.1860 0.3299 | 0.2307 0.2307 0.1071 | 0.1526 26.2640 20.9088 0.2649 0.5368 0.6627 TEST: 4.9442 0.1098 0.2049 | 0.4747 0.4678 0.6733 | 0.1689 27.9204 34.7671 23.9440 50.0425 62.6359
lr at 146th epoch is 5e-05 for optimizer
current performance: -8.0798, best performance: -0.5338
Epoch: 0146 | TRAIN: 0.1092 0.1872 0.3309 | 0.2357 0.2357 0.1112 | 0.1531 26.3102 20.9287 0.2659 0.5354 0.6602 TEST: 6.5143 0.0769 0.1585 | 0.4794 0.4712 0.6986 | 0.1676 27.8513 34.6074 24.0533 49.8409 62.5099
lr at 147th epoch is 5e-05 for optimizer
current performance: -8.1738, best performance: -0.5338
Epoch: 0147 | TRAIN: 0.1233 0.1855 0.3296 | 0.2409 0.2409 0.1134 | 0.1545 26.5139 21.1774 0.2583 0.5312 0.6575 TEST: 6.2539 0.0767 0.1594 | 0.4742 0.4672 0.6774 | 0.1703 28.0728 34.9109 23.8756 49.6765 62.2029
lr at 148th epoch is 5e-05 for optimizer
current performance: -10.4161, best performance: -0.5338
Epoch: 0148 | TRAIN: 0.1081 0.1859 0.3307 | 0.2320 0.2320 0.1090 | 0.1532 26.3257 20.9334 0.2642 0.5356 0.6615 TEST: 7.0997 0.0570 0.1291 | 0.4717 0.4645 0.6754 | 0.1695 27.9297 34.8331 24.2723 50.0631 62.5341
lr at 149th epoch is 5e-05 for optimizer
current performance: -10.4610, best performance: -0.5338
Epoch: 0149 | TRAIN: 0.1062 0.1892 0.3311 | 0.2359 0.2359 0.1098 | 0.1534 26.3626 21.0369 0.2625 0.5346 0.6607 TEST: 7.1765 0.0576 0.1261 | 0.4738 0.4667 0.6831 | 0.1686 27.9593 34.7069 23.9132 49.6214 62.2018
lr at 150th epoch is 5e-05 for optimizer
current performance: -14.4371, best performance: -0.5338
Epoch: 0150 | TRAIN: 0.0915 0.1924 0.3334 | 0.2279 0.2279 0.1076 | 0.1522 26.2040 20.7855 0.2663 0.5388 0.6643 TEST: 9.0386 0.0268 0.0869 | 0.4729 0.4656 0.6781 | 0.1699 28.0401 34.8677 23.8853 49.7522 62.2892
lr at 151th epoch is 5e-05 for optimizer
current performance: -10.9668, best performance: -0.5338
Epoch: 0151 | TRAIN: 0.0867 0.1931 0.3346 | 0.2313 0.2313 0.1079 | 0.1509 26.0971 20.7514 0.2675 0.5400 0.6652 TEST: 7.8033 0.0504 0.1177 | 0.4669 0.4590 0.6742 | 0.1668 27.8772 34.4714 23.9090 49.1524 61.9122
lr at 152th epoch is 5e-05 for optimizer
current performance: -9.3085, best performance: -0.5338
Epoch: 0152 | TRAIN: 0.0957 0.1902 0.3320 | 0.2297 0.2297 0.1082 | 0.1520 26.1608 20.7003 0.2697 0.5395 0.6640 TEST: 6.7375 0.0661 0.1356 | 0.4737 0.4663 0.6783 | 0.1678 27.9062 34.6057 23.8490 49.5277 62.2761
lr at 153th epoch is 5e-05 for optimizer
current performance: -7.1060, best performance: -0.5338
Epoch: 0153 | TRAIN: 0.1035 0.1880 0.3305 | 0.2338 0.2338 0.1117 | 0.1530 26.2972 20.8816 0.2641 0.5378 0.6631 TEST: 6.9964 0.0827 0.1495 | 0.4745 0.4674 0.6726 | 0.1680 27.7953 34.6949 24.4817 50.3595 62.8327
lr at 154th epoch is 5e-05 for optimizer
current performance: -6.8363, best performance: -0.5338
Epoch: 0154 | TRAIN: 0.0912 0.1949 0.3334 | 0.2304 0.2304 0.1077 | 0.1516 26.1250 20.7104 0.2683 0.5406 0.6656 TEST: 7.0447 0.0836 0.1599 | 0.4729 0.4656 0.6770 | 0.1669 27.7226 34.5295 24.5618 50.2052 62.7023
lr at 155th epoch is 5e-05 for optimizer
current performance: -9.1516, best performance: -0.5338
Epoch: 0155 | TRAIN: 0.1176 0.1909 0.3322 | 0.2318 0.2318 0.1080 | 0.1516 26.1200 20.7207 0.2700 0.5408 0.6655 TEST: 6.4829 0.0646 0.1356 | 0.4667 0.4596 0.6677 | 0.1676 27.8530 34.5997 24.1746 49.7743 62.3861
lr at 156th epoch is 5e-05 for optimizer
current performance: -9.7429, best performance: -0.5338
Epoch: 0156 | TRAIN: 0.0865 0.1933 0.3344 | 0.2246 0.2246 0.1055 | 0.1503 25.9434 20.4174 0.2736 0.5467 0.6701 TEST: 7.9920 0.0588 0.1195 | 0.4674 0.4604 0.6695 | 0.1668 27.6890 34.5491 24.7622 50.4247 62.8348
lr at 157th epoch is 5e-05 for optimizer
current performance: -8.2187, best performance: -0.5338
Epoch: 0157 | TRAIN: 0.0890 0.1903 0.3337 | 0.2250 0.2250 0.1052 | 0.1479 25.6982 20.2428 0.2775 0.5509 0.6741 TEST: 6.9254 0.0744 0.1436 | 0.4745 0.4671 0.6853 | 0.1678 27.8517 34.6251 24.2388 49.8558 62.3655
lr at 158th epoch is 5e-05 for optimizer
current performance: -10.6156, best performance: -0.5338
Epoch: 0158 | TRAIN: 0.0946 0.1959 0.3319 | 0.2280 0.2280 0.1051 | 0.1496 25.8955 20.4872 0.2730 0.5458 0.6701 TEST: 8.1969 0.0525 0.1207 | 0.4698 0.4620 0.6779 | 0.1669 27.6869 34.5631 24.6921 50.5506 62.9909
lr at 159th epoch is 5e-05 for optimizer
current performance: -9.8953, best performance: -0.5338
Epoch: 0159 | TRAIN: 0.0850 0.1918 0.3317 | 0.2212 0.2212 0.1041 | 0.1484 25.7531 20.3247 0.2767 0.5499 0.6727 TEST: 7.8109 0.0575 0.1261 | 0.4693 0.4619 0.6756 | 0.1656 27.6163 34.3992 24.6490 50.2645 62.8725
lr at 160th epoch is 5e-05 for optimizer
current performance: -9.4828, best performance: -0.5338
Epoch: 0160 | TRAIN: 0.0864 0.1978 0.3356 | 0.2273 0.2273 0.1073 | 0.1493 25.8590 20.4018 0.2748 0.5470 0.6708 TEST: 8.0286 0.0628 0.1343 | 0.4739 0.4670 0.6785 | 0.1665 27.6585 34.5013 24.7095 50.3459 62.9750
lr at 161th epoch is 5e-05 for optimizer
current performance: -7.6705, best performance: -0.5338
Epoch: 0161 | TRAIN: 0.1153 0.1900 0.3363 | 0.2312 0.2312 0.1080 | 0.1499 25.9016 20.3957 0.2750 0.5464 0.6701 TEST: 6.6763 0.0805 0.1605 | 0.4785 0.4722 0.6781 | 0.1673 27.8606 34.5636 24.0421 49.6011 62.2528
lr at 162th epoch is 5e-05 for optimizer
current performance: -0.8294, best performance: -0.5338
Epoch: 0162 | TRAIN: 0.1019 0.1905 0.3302 | 0.2336 0.2336 0.1091 | 0.1505 25.9965 20.5367 0.2708 0.5449 0.6694 TEST: 5.4047 0.1323 0.2294 | 0.4783 0.4709 0.6845 | 0.1671 27.6997 34.5755 24.6062 50.4472 62.9558
lr at 163th epoch is 5e-05 for optimizer
current performance: -9.0464, best performance: -0.5338
Epoch: 0163 | TRAIN: 0.1249 0.1893 0.3304 | 0.2353 0.2353 0.1098 | 0.1494 25.9018 20.4744 0.2717 0.5459 0.6707 TEST: 7.1870 0.0697 0.1433 | 0.4813 0.4735 0.6918 | 0.1680 27.8067 34.6712 24.3236 50.2480 62.8319
lr at 164th epoch is 5e-05 for optimizer
current performance: -7.8983, best performance: -0.5338
Epoch: 0164 | TRAIN: 0.0838 0.1941 0.3364 | 0.2283 0.2283 0.1051 | 0.1475 25.6123 20.0803 0.2813 0.5535 0.6756 TEST: 7.0294 0.0734 0.1465 | 0.4714 0.4644 0.6769 | 0.1655 27.5524 34.4057 24.8061 50.6996 63.2058
lr at 165th epoch is 5e-05 for optimizer
current performance: -5.9811, best performance: -0.5338
Epoch: 0165 | TRAIN: 0.1034 0.1913 0.3346 | 0.2267 0.2267 0.1056 | 0.1470 25.6182 20.1875 0.2776 0.5529 0.6762 TEST: 6.5771 0.0876 0.1637 | 0.4683 0.4609 0.6772 | 0.1660 27.5891 34.4713 24.7002 50.8222 63.1907
lr at 166th epoch is 5e-05 for optimizer
current performance: -9.3446, best performance: -0.5338
Epoch: 0166 | TRAIN: 0.0864 0.1960 0.3345 | 0.2176 0.2176 0.1025 | 0.1473 25.6140 20.1309 0.2794 0.5537 0.6764 TEST: 7.7258 0.0610 0.1312 | 0.4635 0.4566 0.6692 | 0.1676 27.7278 34.6701 24.6834 50.5730 62.9900
lr at 167th epoch is 5e-05 for optimizer
current performance: -6.8737, best performance: -0.5338
Epoch: 0167 | TRAIN: 0.0875 0.1930 0.3331 | 0.2241 0.2241 0.1034 | 0.1477 25.6724 20.1914 0.2775 0.5517 0.6747 TEST: 7.1696 0.0823 0.1607 | 0.4717 0.4646 0.6740 | 0.1659 27.6453 34.4322 24.5751 50.3711 62.8617
lr at 168th epoch is 5e-05 for optimizer
current performance: -12.9882, best performance: -0.5338
Epoch: 0168 | TRAIN: 0.0874 0.1957 0.3353 | 0.2192 0.2192 0.1030 | 0.1470 25.5520 20.0371 0.2818 0.5559 0.6784 TEST: 9.3450 0.0384 0.0985 | 0.4834 0.4760 0.6892 | 0.1668 27.6609 34.5575 24.8154 50.5750 63.0233
lr at 169th epoch is 5e-05 for optimizer
current performance: -7.6025, best performance: -0.5338
Epoch: 0169 | TRAIN: 0.0921 0.1930 0.3339 | 0.2202 0.2202 0.1012 | 0.1467 25.5314 19.9611 0.2811 0.5569 0.6787 TEST: 7.5485 0.0742 0.1438 | 0.4699 0.4632 0.6707 | 0.1640 27.4253 34.2284 25.0266 50.7989 63.3016
lr at 170th epoch is 5e-05 for optimizer
current performance: -12.5481, best performance: -0.5338
Epoch: 0170 | TRAIN: 0.0903 0.1966 0.3364 | 0.2252 0.2252 0.1046 | 0.1455 25.3724 19.9016 0.2869 0.5586 0.6801 TEST: 9.6328 0.0357 0.0988 | 0.4658 0.4591 0.6674 | 0.1660 27.6111 34.4712 24.7641 50.5250 63.1414
lr at 171th epoch is 5e-05 for optimizer
current performance: -6.2160, best performance: -0.5338
Epoch: 0171 | TRAIN: 0.0838 0.1979 0.3358 | 0.2175 0.2175 0.1013 | 0.1452 25.3509 19.8189 0.2870 0.5589 0.6809 TEST: 6.7770 0.0875 0.1669 | 0.4731 0.4666 0.6703 | 0.1659 27.5716 34.4532 24.9761 50.6939 63.1058
lr at 172th epoch is 5e-05 for optimizer
current performance: -12.5660, best performance: -0.5338
Epoch: 0172 | TRAIN: 0.0894 0.1972 0.3362 | 0.2192 0.2192 0.1025 | 0.1473 25.6209 20.1363 0.2781 0.5540 0.6770 TEST: 9.4223 0.0354 0.0935 | 0.4684 0.4605 0.6724 | 0.1647 27.5373 34.2825 24.6569 50.4539 63.0151
lr at 173th epoch is 5e-05 for optimizer
current performance: -9.4092, best performance: -0.5338
Epoch: 0173 | TRAIN: 0.1030 0.1907 0.3343 | 0.2227 0.2227 0.1045 | 0.1482 25.7490 20.2691 0.2751 0.5503 0.6738 TEST: 8.5535 0.0584 0.1314 | 0.4661 0.4592 0.6675 | 0.1634 27.3869 34.1656 25.0592 50.8683 63.2898
lr at 174th epoch is 5e-05 for optimizer
current performance: -8.4910, best performance: -0.5338
Epoch: 0174 | TRAIN: 0.1023 0.1949 0.3340 | 0.2247 0.2247 0.1045 | 0.1470 25.5951 20.0968 0.2797 0.5530 0.6762 TEST: 7.1581 0.0660 0.1391 | 0.4653 0.4580 0.6709 | 0.1647 27.4802 34.2978 25.0044 50.6962 63.1870
lr at 175th epoch is 5e-05 for optimizer
current performance: -6.9765, best performance: -0.5338
Epoch: 0175 | TRAIN: 0.0942 0.1918 0.3332 | 0.2217 0.2217 0.1038 | 0.1465 25.5246 20.1043 0.2820 0.5544 0.6776 TEST: 7.2064 0.0761 0.1539 | 0.4627 0.4549 0.6708 | 0.1647 27.4056 34.3349 25.3430 51.2148 63.5373
lr at 176th epoch is 5e-05 for optimizer
current performance: -11.3767, best performance: -0.5338
Epoch: 0176 | TRAIN: 0.0743 0.2002 0.3372 | 0.2152 0.2152 0.1005 | 0.1446 25.3094 19.8644 0.2850 0.5607 0.6833 TEST: 8.9967 0.0426 0.1095 | 0.4684 0.4604 0.6823 | 0.1633 27.2983 34.1541 25.4731 51.0741 63.5206
lr at 177th epoch is 5e-05 for optimizer
current performance: -6.0406, best performance: -0.5338
Epoch: 0177 | TRAIN: 0.0842 0.1985 0.3352 | 0.2128 0.2128 0.1008 | 0.1445 25.2817 19.7334 0.2869 0.5608 0.6830 TEST: 6.9288 0.0838 0.1694 | 0.4632 0.4561 0.6647 | 0.1651 27.4017 34.4232 25.3125 51.5480 63.8471
lr at 178th epoch is 5e-05 for optimizer
current performance: -6.9858, best performance: -0.5338
Epoch: 0178 | TRAIN: 0.0739 0.1979 0.3390 | 0.2107 0.2107 0.0994 | 0.1442 25.1799 19.5504 0.2923 0.5650 0.6851 TEST: 7.4292 0.0765 0.1586 | 0.4650 0.4577 0.6694 | 0.1638 27.3486 34.2344 25.1772 51.2960 63.6844
lr at 179th epoch is 5e-05 for optimizer
current performance: -10.8088, best performance: -0.5338
Epoch: 0179 | TRAIN: 0.0829 0.1959 0.3374 | 0.2160 0.2160 0.1017 | 0.1450 25.3414 19.8261 0.2852 0.5604 0.6825 TEST: 9.3315 0.0492 0.1093 | 0.4675 0.4602 0.6695 | 0.1649 27.5522 34.3371 24.7251 50.4645 62.9897
lr at 180th epoch is 5e-05 for optimizer
current performance: -5.6757, best performance: -0.5338
Epoch: 0180 | TRAIN: 0.0803 0.1987 0.3347 | 0.2163 0.2163 0.1000 | 0.1439 25.2124 19.7508 0.2884 0.5623 0.6842 TEST: 7.2393 0.0884 0.1692 | 0.4696 0.4618 0.6734 | 0.1635 27.3775 34.1764 25.1023 50.8647 63.3894
lr at 181th epoch is 5e-05 for optimizer
current performance: -0.6574, best performance: -0.5338
Epoch: 0181 | TRAIN: 0.0974 0.1907 0.3338 | 0.2261 0.2261 0.1058 | 0.1464 25.5273 20.0395 0.2806 0.5552 0.6781 TEST: 6.6512 0.1261 0.1988 | 0.4640 0.4566 0.6636 | 0.1636 27.3866 34.1709 25.2088 50.6631 63.2153
lr at 182th epoch is 5e-05 for optimizer
current performance: -6.0698, best performance: -0.5338
Epoch: 0182 | TRAIN: 0.0857 0.1952 0.3353 | 0.2149 0.2149 0.0995 | 0.1454 25.3599 19.8159 0.2861 0.5598 0.6817 TEST: 7.7828 0.0810 0.1582 | 0.4586 0.4511 0.6614 | 0.1637 27.2914 34.2363 25.4765 51.5290 63.8612
lr at 183th epoch is 5e-05 for optimizer
current performance: -11.4022, best performance: -0.5338
Epoch: 0183 | TRAIN: 0.0887 0.1960 0.3366 | 0.2136 0.2136 0.0991 | 0.1446 25.3198 19.8568 0.2847 0.5593 0.6822 TEST: 9.5709 0.0422 0.1114 | 0.4644 0.4569 0.6686 | 0.1662 27.4056 34.5669 25.5556 51.9349 64.2156
lr at 184th epoch is 5e-05 for optimizer
current performance: -8.7172, best performance: -0.5338
Epoch: 0184 | TRAIN: 0.0766 0.1958 0.3383 | 0.2124 0.2124 0.1012 | 0.1445 25.2621 19.6781 0.2896 0.5615 0.6825 TEST: 8.2903 0.0620 0.1363 | 0.4644 0.4564 0.6757 | 0.1626 27.2903 34.0735 25.3238 50.9507 63.4694
lr at 185th epoch is 5e-05 for optimizer
current performance: -10.6992, best performance: -0.5338
Epoch: 0185 | TRAIN: 0.0763 0.2022 0.3361 | 0.2094 0.2094 0.0977 | 0.1430 25.0331 19.3856 0.2949 0.5694 0.6884 TEST: 9.3971 0.0473 0.1140 | 0.4646 0.4573 0.6676 | 0.1631 27.3494 34.1177 25.0165 50.7661 63.3992
lr at 186th epoch is 5e-05 for optimizer
current performance: -4.6604, best performance: -0.5338
Epoch: 0186 | TRAIN: 0.0855 0.2011 0.3369 | 0.2159 0.2159 0.1025 | 0.1445 25.2485 19.6359 0.2887 0.5635 0.6842 TEST: 6.7795 0.0962 0.1681 | 0.4643 0.4569 0.6718 | 0.1653 27.5450 34.3783 24.8732 50.6484 63.1482
lr at 187th epoch is 5e-05 for optimizer
current performance: -6.9694, best performance: -0.5338
Epoch: 0187 | TRAIN: 0.1113 0.1946 0.3320 | 0.2192 0.2192 0.1021 | 0.1477 25.6054 20.0316 0.2821 0.5558 0.6769 TEST: 6.8359 0.0764 0.1522 | 0.4659 0.4582 0.6714 | 0.1639 27.3038 34.2455 25.6512 51.2350 63.6348
lr at 188th epoch is 5e-05 for optimizer
current performance: -9.5651, best performance: -0.5338
Epoch: 0188 | TRAIN: 0.0804 0.2001 0.3355 | 0.2087 0.2087 0.0978 | 0.1430 25.0886 19.4964 0.2915 0.5664 0.6871 TEST: 7.7320 0.0554 0.1345 | 0.4649 0.4571 0.6724 | 0.1631 27.2634 34.1488 25.5838 51.3129 63.7221
lr at 189th epoch is 5e-05 for optimizer
current performance: -0.0711, best performance: -0.5338
Epoch: 0189 | TRAIN: 0.0863 0.1998 0.3359 | 0.2132 0.2132 0.0988 | 0.1440 25.2520 19.7532 0.2864 0.5608 0.6841 TEST: 4.7703 0.1305 0.2401 | 0.4622 0.4545 0.6674 | 0.1649 27.4575 34.3729 24.9782 51.0339 63.6032
lr at 190th epoch is 5e-05 for optimizer
current performance: -9.0519, best performance: -0.0711
Epoch: 0190 | TRAIN: 0.0777 0.1994 0.3387 | 0.2089 0.2089 0.0980 | 0.1430 25.0531 19.4288 0.2945 0.5676 0.6882 TEST: 7.7753 0.0604 0.1310 | 0.4670 0.4597 0.6661 | 0.1630 27.2799 34.1305 25.4118 51.1946 63.6419
lr at 191th epoch is 5e-05 for optimizer
current performance: -6.5363, best performance: -0.0711
Epoch: 0191 | TRAIN: 0.0801 0.2018 0.3373 | 0.2071 0.2071 0.0956 | 0.1422 24.9985 19.3923 0.2927 0.5694 0.6899 TEST: 7.2929 0.0809 0.1452 | 0.4704 0.4630 0.6711 | 0.1626 27.2334 34.1061 25.3590 51.4305 63.8994
lr at 192th epoch is 5e-05 for optimizer
current performance: -4.0767, best performance: -0.0711
Epoch: 0192 | TRAIN: 0.0765 0.2026 0.3382 | 0.2065 0.2065 0.0948 | 0.1406 24.7930 19.1827 0.2988 0.5731 0.6930 TEST: 6.5681 0.1016 0.1835 | 0.4763 0.4680 0.6889 | 0.1629 27.2108 34.1484 25.5181 51.7066 64.0694
lr at 193th epoch is 5e-05 for optimizer
current performance: -12.0923, best performance: -0.0711
Epoch: 0193 | TRAIN: 0.0893 0.1961 0.3379 | 0.2144 0.2144 0.1000 | 0.1428 25.0788 19.4710 0.2909 0.5671 0.6883 TEST: 9.5510 0.0396 0.1038 | 0.4725 0.4649 0.6784 | 0.1647 27.4196 34.3216 25.3256 50.9971 63.3714
lr at 194th epoch is 5e-05 for optimizer
current performance: -9.0842, best performance: -0.0711
Epoch: 0194 | TRAIN: 0.0812 0.1997 0.3363 | 0.2135 0.2135 0.0989 | 0.1408 24.8048 19.1457 0.2993 0.5736 0.6918 TEST: 8.0446 0.0571 0.1360 | 0.4609 0.4539 0.6583 | 0.1624 27.1472 34.0849 25.8522 51.6058 64.0226
lr at 195th epoch is 5e-05 for optimizer
current performance: -6.1017, best performance: -0.0711
Epoch: 0195 | TRAIN: 0.0789 0.2038 0.3384 | 0.2099 0.2099 0.0967 | 0.1416 24.8955 19.2943 0.2972 0.5713 0.6913 TEST: 7.1109 0.0821 0.1595 | 0.4680 0.4610 0.6658 | 0.1609 27.0713 33.8854 25.6767 51.4707 63.9480
lr at 196th epoch is 5e-05 for optimizer
current performance: -5.0317, best performance: -0.0711
Epoch: 0196 | TRAIN: 0.0835 0.1970 0.3367 | 0.2085 0.2085 0.0982 | 0.1421 24.9257 19.3082 0.2992 0.5700 0.6897 TEST: 6.6818 0.0883 0.1716 | 0.4592 0.4517 0.6625 | 0.1624 27.1794 34.0768 25.6292 51.5533 63.9633
lr at 197th epoch is 5e-05 for optimizer
current performance: -9.2561, best performance: -0.0711
Epoch: 0197 | TRAIN: 0.0738 0.1999 0.3384 | 0.2124 0.2124 0.0986 | 0.1422 24.9639 19.3268 0.2939 0.5716 0.6909 TEST: 7.9797 0.0600 0.1405 | 0.4732 0.4649 0.6810 | 0.1620 27.2071 34.0027 25.4434 51.1446 63.6386
lr at 198th epoch is 5e-05 for optimizer
current performance: -8.5087, best performance: -0.0711
Epoch: 0198 | TRAIN: 0.0784 0.2009 0.3374 | 0.2070 0.2070 0.0968 | 0.1420 24.9948 19.4635 0.2930 0.5674 0.6887 TEST: 7.8649 0.0629 0.1386 | 0.4622 0.4545 0.6660 | 0.1631 27.2748 34.1631 25.2676 51.3350 63.8875
lr at 199th epoch is 5e-05 for optimizer
current performance: -2.5914, best performance: -0.0711
Epoch: 0199 | TRAIN: 0.0736 0.2051 0.3388 | 0.2056 0.2056 0.0959 | 0.1403 24.8097 19.2474 0.2948 0.5726 0.6932 TEST: 6.2172 0.1098 0.2086 | 0.4632 0.4554 0.6703 | 0.1627 27.3100 34.0689 25.1736 50.8659 63.3509
Epoch: 0189 | TRAIN: 0.0863 0.1998 0.3359 | 0.2132 0.2132 0.0988 | 0.1440 25.2520 19.7532 0.2864 0.5608 0.6841 TEST: 4.7703 0.1305 0.2401 | 0.4622 0.4545 0.6674 | 0.1649 27.4575 34.3729 24.9782 51.0339 63.6032
